Logic from Language

       Lawrence S. Moss
Indiana University, Bloomington

         August 2014
  stylistic points: the numbering uses roman numbers in theorem-environments, and
the exercises should be numbered in the chapters.




                                                                                      ng
                                                                                   uri
                                     F OL                                      h -T        first-order logic
                                                                            urc
                                                                          Ch
                                            F O2 + trans                                   F O2 + “R is trans”

                                                                          RCA† (opp)




                                                              RC † (tr)
                                 2                                                         FO2 = 2 variable FOL
                            FO
                                                       RC †
                                                                                           † adds full N -negation
                                                   †
                                                 R
                                                                          RCA(opp)         RC(tr) + opposites
                 Pe
                    a




                                                               RCA                         RC + (transitive)
                   no
                     -F




                                                                                                  comparative adjs
                       re
                        ge




                                                       RC                                  RC = R + relative clauses
                                        S    †                                             S + full N -negation
                            e
                        otl                      R                                         R = relational syllogistic
                   r ist
                 A                                                                         S ≥ adds |p| ≥ |q|
                         S≥
                                            S                                              S: all/some/no p are q

                                        A                                                  A: all p are q




                                                                                                               3
Contents

1 Introduction                                                                             7
  1.1 Examples of inferences treated . . . . . . . . . . . . . . . . . . . . . . . .       7

2 A: the logic of All p are q                                                              9
  2.1 Syntax and Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . .       9
  2.2 Proof theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .    11
  2.3 Preliminaries: graphs and preorders . . . . . . . . . . . . . . . . . . . . .       15
  2.4 Completeness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .    16
  2.5 Algorithmic analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .    17
  2.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   21

3 Additions to A                                                                          25
  3.1 Binary intersection terms . . . . . . . . . . . . . . . . . . . . . . . . . . .     25
  3.2 Verbs and relative clauses . . . . . . . . . . . . . . . . . . . . . . . . . . .    27
  3.3 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   35

4 S: the logic of All p are q, Some p are q, and No p are q                               39
  4.1 Syntax and semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . .      39
  4.2 Proof theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .    41
  4.3 The classical syllogistic forms . . . . . . . . . . . . . . . . . . . . . . . . .   41
  4.4 S† : syllogistic logic with full negation on nouns . . . . . . . . . . . . . . .    42
  4.5 Orthoposets and their representations . . . . . . . . . . . . . . . . . . . .       44
  4.6 Completeness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .    48
  4.7 Algorithmic analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .    50
  4.8 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   52

5 R: the relational syllogistic                                                           55
  5.1 Syntax and semantics of R . . . . . . . . . . . . . . . . . . . . . . . . . . .     55
  5.2 Algorithmic analysis: building a model of a satisfiable set . . . . . . . . .       57
  5.3 Proof theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .    62
  5.4 Incorporating background facts in R . . . . . . . . . . . . . . . . . . . . .       65
  5.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   66

6 RCA: verbs, relative clauses, and comparative adjectives                                67
  6.1 Syntax and semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . .      67
  6.2 Proof system . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .    71
  6.3 Completeness of the logic . . . . . . . . . . . . . . . . . . . . . . . . . . .     74



                                                                                           5
Contents

    6.4   Exercises   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79

7 S† (card): Reasoning about the Sizes of Sets                                           83
  7.1 S (card): syllogistic logic with negation and cardinality comparison . . . . 83
         †

  7.2 S(card) and the Construction Lemma . . . . . . . . . . . . . . . . . . . . 87
  7.3 The Completeness Theorem for S(card) . . . . . . . . . . . . . . . . . . . 89
  7.4 The Completeness Theorem for S† (card) . . . . . . . . . . . . . . . . . . . 90
  7.5 Adding ∃≥ to the Boolean syllogistic fragment . . . . . . . . . . . . . . . 96
  7.6 Most . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98
  7.7 The numerical syllogistic . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
  7.8 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100

8 Small Additions                                                                      103
  8.1 Adding names . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
  8.2 Adding Boolean connectives to sentences . . . . . . . . . . . . . . . . . . . 103

9 The Limits of Syllogistic Proof Systems                                            105
  9.1 General definitions on syllogistic proof systems . . . . . . . . . . . . . . . 105
  9.2 No systems (without RAA) for R . . . . . . . . . . . . . . . . . . . . . . . 106
  9.3 No systems (even with RAA) for RC or RC† . . . . . . . . . . . . . . . . . 108

10 Logic Beyond the Aristotle Border                                                      109
   10.1 Fitch-style proof system for RC† . . . . . . . . . . . . . . . . . . . . . . . 109
   10.2 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114
   10.3 Soundness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115
   10.4 The Henkin property . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116
   10.5 Completeness via canonical models . . . . . . . . . . . . . . . . . . . . . . 118
   10.6 The finite model property . . . . . . . . . . . . . . . . . . . . . . . . . . . 119
   10.7 Adding transitivity: L(adj) . . . . . . . . . . . . . . . . . . . . . . . . . . 121
   10.8 L(adj) has the finite model property . . . . . . . . . . . . . . . . . . . . . 125

11 Complexity Results                                                                      131

12 Description Logic                                                                       137

13 Categorial Grammar                                                                139
   13.1 Categorial grammar as a syntactic system . . . . . . . . . . . . . . . . . . 139

14 Proof-theoretic Semantics                                                               143




6
1 Introduction
1.1 Examples of inferences treated
For future reference, it might be useful to list some examples of the kind of phenomena
that will interest us.

                                Some dog sees some cat
                              Some cat is seen by some dog                            (1.1)

               Bao is seen and heard by every student    Amina is a student
                                    Amina sees Bao                                    (1.2)


                               All skunks are mammals
       All who fear all who respect all skunks fear all who respect all mammals       (1.3)


           Everyone likes everyone who likes Pat
           Pat likes every clarinetist                                                (1.4)
           Everyone likes everyone who likes everyone who likes every clarinetist

                          Every giraffe is taller than every gnu
                          Some gnu is taller than every lion
                                                                                      (1.5)
                          Some lion is taller than some zebra
                          Every giraffe is taller than some zebra
           More students than professors run More professors than deans run
                             More students than deans run                             (1.6)

                At most as many xenophobics as yodelers are zookeepers
                At most as many zookeepers as alcoholics are yodelers
                                                                                      (1.7)
                At most as many yodelers as xenophobics are alcoholics
                At most as many zookeepers as alcoholics are xenophobics
  I take all of these to be valid inferences in the sense that a competent speaker who
accepts the premisses (above the line) will accept the conclusion. (1.1) involves the
passive, as does (1.2). The latter also has conjunction in the V P . (1.3) is a complicated
example of iterated subject relative clauses. In my experience with this example during
talks, most people by far cannot see that (1.3) is a valid inference. I mention this to
point out that fragments which are syntactically very simple might still host non-trivial



                                                                                         7
1 Introduction

inferences. Another example that’s hard to see is (1.4). To see it, let X be the people
who like every clarinetist. By the second premise of (1.4), Pat is an X. From this, it
follows that everyone who likes all Xs likes Pat. In informal notation,

                                 likes every X ⊆ likes Pat.

And from what we saw in Problem 3,

              likes everyone who likes Pat ⊆ likes everyone who likes every X.

By the first premise of (1.4), everyone belongs to the set on the left. And so everyone
belongs to the set on the right, too. This is the conclusion of (1.4).
  (1.5) is of interest because people can work out that it is valid, especially if they draw
a picture. The key point is that is taller than is transitive: if x is taller than y, and y is
taller than z, then x is taller than z. This transitivity is shared with other comparative
adjective phrases, and for the simplest of these one might even take it to be a semantic
universal. (In more complex phrases, transitivity is lost. For example, is liked by more
people than is not transitive, as Condorcet famously noted in his essay on voting of 1785.)
  Inference (1.6) is of interest because it is not expressible in first-order logic. The same
goes for (1.7), and this last inference is harder to see.




8
2 A: the logic of All p are q
We start with the smallest syllogistic logic “of all”, the system A.


2.1 Syntax and Semantics
For the syntax, we start with a collection P of atoms 1 (for nouns). The elements of P
may be anything, and P might be finite or infinite. We write the atoms as p, q, . . .;
occasionally we use subscripts or other devices. We take as sentences the expressions
                                                All p are q
where p and q are any atoms in P. There is nothing else in the language, not even
boolean connectives. We call this language A2 .
  The semantics is based on models. A model M for this fragment A is a structure
                                          M      =     (M, [[ ]])
consisting of a set M , together with an interpretation [[p]] ⊆ M for each atom p ∈ P.
The main semantic definition is truth in a model :
                                M |= All p are q         iff     [[p]] ⊆ [[q]]
We read this in various ways, such as M satisfies All p are q, or All p are q is true in M.


Example 2.1 Here is an example of how all of this works. Suppose that P = {n, p, q}.
In this case, A would have exactly nine sentences.
  Let M = {1, 2, 3, 4, 5}. Let [[n]] = ∅, [[p]] = {1, 3, 4}, and [[q]] = {1, 3}. This is all we
need to specify a model. We’ll call this model M. The following sentences are true in
M: All n are n, All n are p, All n are q, All p are p, All q are p, and All q are q. (In the first
two of these example sentences, we use the fact that the empty set is a subset of every
set 3 .) The other three sentences in A are false in M.
 1
   In Section section-AARC and in Chapter 5 and onward, we’ll also have binary atoms to represent
    transitive verbs and other things. So what we are calling atoms here will later be re-named to unary
    atoms.
 2
   A stands for “all.” Note that A is really a family of languages, one for each set P of atoms at the
    outset. This dependence on primitives is true for practically all logical systems. For most of the work
    in these notes, we suppress mention of the primitive syntactic items because it makes the notation
    lighter and because we rarely need to call attention to the primitives in the first place.
 3
   This means that our semantics commits us to a view of universal quantification that does not build
    in existential import. If one wishes to go the other way (in larger logical systems), then it is possible
    to do so. Either alternative leads to a well-behaved proof system.




                                                                                                           9
2 A: the logic of All p are q

We say that M |= Γ iff M |= ϕ for every ϕ ∈ Γ.
We say that Γ |= ϕ iff for all M: if M |= Γ, then also M |= ϕ.
We read this as Γ logically implies ϕ, or Γ semantically implies ϕ, or that ϕ is a
semantic consequence of Γ.

Figure 2.1: Definitions of semantic consequence in any logical system. In these, Γ is a
            set of sentences in the system, and M is a model for it.


   As soon as we have a formal semantics for a logical system, we get two further notions.
These are used with every logic in this book, and so we emphasize their importance by
putting them in a figure of their own, Figure 2.1.
   Throughout this book, we use Γ (the upper-case Greek letter gamma) to denote a set
of sentences in whatever logical system we happen to be discussing. So in this chapter,
it denotes a set of sentences in A. We sometimes call Γ a set of assumptions. We also
sometimes call it a theory, following the usage in modern logic.



Example 2.2 Here is an example of a semantic consequence which can be expressed
in A: We claim that

                               {All p are q, All n are p} |= All n are q.                         (2.1)

To see this, we give a straightforward mathematical proof.4 Let M be any model for
A, assuming that the underlying set P contains n, p, and q. Assume that M satisfies
All p are q and All n are p. We must prove that M also satisfies All n are q. From our
first assumption, [[p]] ⊆ [[q]]. From our second, [[n]] ⊆ [[p]]. It is a general fact about
sets that the inclusion relation (written as ⊆ here) is transitive, and so we conclude that
[[n]] ⊆ [[q]]. This verifies that indeed M satisfies All n are q. And since M was arbitrary,
we are done.

  Incidentally, when Γ is a finite set that is written out explicitly on the left side of a |=
or ` symbol, we usually omit it from the notation. So instead of writing (2.1), we would
usually write
                          All p are q, All n are p |= All n are q.




Example 2.3           Next, we have an example of a failure of semantic consequence:

                                       All p are q 6|= All q are p.
 4
     There is no real need to use a formal system to do mathematical proofs! They are much more readable
      when done informally.




10
                                                                         2.2 Proof theory

To show that a given set Γ does not logically entail another sentence ϕ, we need to build
a model M of Γ which is not a model of ϕ. In this example, Γ is {All p are q}, and ϕ is
All q are p. We can get a model M that does the trick by setting M = {1, 2}, [[p]] = {1},
and [[q]] = {1, 2}. For that matter, we could also use a different model, say N, defined
by N = {61}, [[p]] = ∅, and [[q]] = {61}.




Example 2.4 Here is a more complicated example. At this point, we present it mainly
as a challenge.
                                                              
                     All j are k, All j are l,  All k are l, 
                Γ =    All l are k, All l are m, All k are n,
                       All m are q, All p are q, All q are p
                                                              

True or false: Γ |= All p are n? If true, give a reason. If false, give a model of Γ where
[[p]] 6⊆ [[n]].
   The point here not to simply solve this particular problem, but to give an algorithm
which would solve all problems of this type, and to prove your answer. We’ll do this in
Section 2.5.



2.2 Proof theory
Figure 2.2 presents a proof system for the language A. The system has two inference
rules. Each rule allows conclusions to be inferred from some set of premises. The
conclusion of a rule is the sentence below the horizontal line, and the premise(s) are
above the line.
  Let us discuss the second rule, (Barbara) first. The rule says that All p are q may
be inferred from the two premises All p are n and All n are q. That is, a node in a tree
may be labeled All p are q provided it has two nodes above it in the tree, one labeled All
p are n for some atom n, and the other labeled All n are q.
  The first rule, named (Axiom), says that All p are p may label a node in a proof tree
provided that node have no nodes above it. So no premises are required, and none may
appear.
  The name (Barbara) comes from medieval logic. The reason for this is that logicians
used A for universal assertions. (Of course, they did not use English, so it is purely a
coincidence that A stands for All.) The rule has three As. Classical logicians interpolated
consonants “randomly” to get the names of their rules, hence bArbArA. Our rule
(Axiom) is so-named because an axiom in a proof system is like a rule of inference with
no premises.

Definition Let Γ be a set of sentences in A. A proof tree over Γ is a finite tree5 T



                                                                                        11
2 A: the logic of All p are q

                                                      All p are n All n are q
                                   Axiom                                      Barbara
                 All p are p                                 All p are q

                                   Figure 2.2: The logical system for A.


whose nodes are labeled with sentences, and each node is either a leaf node labeled with
an element of Γ, or else matches one of the rules in the proof system in Figure 2.2.
  Γ ` ϕ means that there is a proof tree T for over Γ whose root is labeled ϕ. We read
this as Γ proves ϕ, or Γ derives ϕ, or that ϕ follows in our proof system from Γ.




Example 2.5              Here is an example, chosen to make several points: Let Γ be

                       {All l are m, All q are l, All m are p, All n are p, All l are q}

Let ϕ be All q are p. Here is a proof tree showing that Γ ` ϕ: We start with the tree

                                                  •                  •
                                                            •                 •


                               •                                     •


                                                  •                                        (2.2)

and then we label the various points with sentences in A. Rather than give the function
in any explicit way, we merely illustrate the way it works. We take

                                                  Axiom
                         All l are m All m are m
                                                  Barbara
                                 All l are m                  All m are p
                                                                          Barbara
         All q are l                           All l are p
                                                           Barbara
                                All q are p                                                (2.3)

Again, the proof tree (technically speaking) is a tree together with a labeling function
taking the nodes of the tree to sentences. But we never need to be so explicit, and it will
be better to think of the tree as it appears in (2.3). Similarly, whenever we refer to the
root and leaves of the tree, we really mean the sentences that label the root and leaves.
  Let us check that what we have in (2.4) really is a proof tree according to our definition.
All of the leaves belong to Γ except for one: that is All m are m. This last leaf matches
the first rule in Figure 2.2. That is, this rule allows us to use All m are m with no
 5
     See page 16 for more on trees.




12
                                                                                      2.2 Proof theory

Suppose we are given a logical language and a semantics for it, defining a notion Γ |= ϕ.
Suppose we also have a proof system for the same language, defining a notion Γ ` ϕ.
The proof system is sound for the semantics if whenever Γ ` ϕ, we also have Γ |= ϕ.
The proof system is complete for the semantics if whenever Γ |= ϕ, we also have Γ ` ϕ.

     Figure 2.3: Soundness and Completeness of a proof system relative to a semantics.

parents. All of the other nodes in the tree match the second rule. They all have two
parents, and they are special cases of the rule (Barbara).
  Derivation trees come with the information of which rule is used at the various nodes
of the tree, the way we do it in (2.3). But frequently we drop all the rules. So our
derivation tree would look like
                                All l are m All m are m
                                        All l are m            All m are p
                   All q are l                      All l are p
                                   All q are p                                     (2.4)
  Finally, note also that some sentences from Γ are not used as leaves. This is permitted
according to our definition. Also, there is a smaller proof tree that also shows that Γ ` ϕ:
we could drop All m are m (The reason why have the rule (Axiom) is so that that we
can have one-element trees labeled with sentences of the form All l are l.)

   We have a proof system for the language A of this chapter. Earlier, we defined the
semantics of this language, using models. The main technical work is to connect the
semantics and the proof system. The main definitions pertaining to this connection are
found in Figure 2.3. Like much of the work in this chapter, these definitions will be used
in all of the logical system we shall see.
   Our next goal is to prove the soundness of the proof system with respect to the
semantics. This proof uses induction, and so we turn to that topic. To prove something
about all proof trees over a set Γ, we use induction on proof trees over Γ6 . The statement
that we need may be found in Figure 2.4.
  We’ll see examples of induction on proof trees in Proposition 2.2.1 and in Exercises 5
and 6.
Proposition 2.2.1 (Soundness) If Γ ` ϕ, then Γ |= ϕ.
Proof We prove this by induction on proof trees over Γ as stated in Figure 2.4. We
take S(T) to be the assertion:
                 if the root of T is labeled ϕ, then every M |= Γ also satisfies ϕ                   (2.5)
 6
     If you don’t know about induction, you might wish to consult some other sources to learn about
      induction in other contexts, especially induction on numbers. Proofs by induction will only play a
      minor role in what we do, so if you don’t mind taking a few results on faith, it would be possible to
      read on forgetting induction completely. However, the settings that we have are simple enough that
      you might even be able to pick up induction from the rest of the book.




                                                                                                        13
2 A: the logic of All p are q

Let S(T) be an assertion about proof trees. Suppose that

     (i) S(T) whenever T is a one-point tree labeled with a sentence from Γ.

  (ii) S(T) whenever T is a proof tree over Γ whose root is justified by (Axiom).

 (iii) Let T be a proof tree over Γ whose root is justified by (Barbara), and let T1
       and T2 be the subtrees right above the root. If S(T1 ) and also S(T2 ), then S(T).

Assuming these conditions, we have S(T) for all proof trees T over Γ.

                Figure 2.4: The induction principle for proof trees over Γ.


   First, we show that S(T) when T is a one-point tree labeled with a sentence from Γ.
In this case, ϕ belongs to Γ. And so every model M of all sentences in Γ is a fortiori
model of ϕ.
   Second, we show that S(T) when T is proof tree over Γ whose root is justified by
(Axiom). In this case, the root of T is a sentence of the form All p are p. (Also, in this
case, the entire tree is the root. But this is irrelevant.) Every sentence All p are p is true
in all models M whatsoever, regardless of whether M satisfies Γ or not. So S(T) holds
in this case.
   Now assume that the root of T is All n are q, and right above this we have two trees
whose roots are All n are p and All p are q, respectively. Assume that every model of Γ
satisfies All n are p, and also that every model of Γ satisfies All p are q. Fix a model M
of Γ. Then in M, [[n]] ⊆ [[p]], and also [[p]] ⊆ [[q]]. Continuing to think about this fixed
model, we also have [[n]] ⊆ [[q]]. But M was an arbitrary model of Γ. So we have shown
than every model of Γ satisfies the root of T. That is, S(T) holds.
   The paragraphs above show that for all proof trees T over Γ, every model of Γ satisfies
the root of T. Put another way, if Γ ` ϕ, then Γ |= ϕ.                                       a



Remark The soundness proofs of all the logical systems in this book are all pretty
much the same as the one in Proposition 2.2.1. They are always inductions, and the
crux of the matter is usually a simple fact about sets. (In Proposition 2.2.1, the crux of
the matter is that the inclusion relation ⊆ on subsets of a given set is always a transitive
relation.) We almost never present the soundness proof in any detail.

  Proposition 2.2.1 tells us that the formal logical system for A is not going to give us
any bad results. (This is what soundness means.) Now this is a fairly weak point. If we
dropped some of the rules, it would still hold. Even if we decided to be conservative and
say that Γ ` ϕ never holds, Proposition 2.2.1 would still hold. So the more interesting
question to ask is whether the logical system is strong enough to prove everything it
should prove. We want to know if Γ |= ϕ implies that Γ ` ϕ. If this implication does
hold for all Γ and ϕ, then we say that our system is complete.



14
                                                 2.3 Preliminaries: graphs and preorders

2.3 Preliminaries: graphs and preorders
At this point, we have presented a language called A, a semantics for it, and a sound
proof system to go along with the semantics. The main theoretical work is to show that
the system is complete: if Γ |= ϕ, then Γ ` ϕ. We also must discuss the algorithmic
properties of the system. That is, if someone gives us a (finite) set Γ and a sentence ϕ,
how can we determine whether or not Γ ` ϕ? We shall study these soon, but first we
need some preliminary notions from general mathematics.

Graphs A graph is a pair G = (G, →), where G is a set and → is a relation on G. The
elements of G are called nodes, vertices, or points. If g and h are nodes of G, we usually
write g → h to mean that g and h are related by the relation →. But sometimes the
style of exposition dictates other notation, such as (g, h) ∈→. Alternately, we might
say that g is the parent of h. The relation is also called the edge relation of the graph.
There is no requirement on this relation: G might have loops (i.e., we might have g → g
for some, or even all nodes of G). But a graph need not have any loops at all. (For that
matter, a graph need not have any nodes at all! The empty graph is perfectly fine for
us. But as with all similar situations, other authors may differ on this point of usage.)



Example 2.6      Here is a graph:

                          a      /b      /c      de            e                      (2.6)

Technically, we have drawn a picture of a graph G, where the node set G is {a, b, c, d, e},
and the edge relation → is {(a, b), (b, c), (d, d)}.




Example 2.7 For each set Γ of sentences of A and each set G of atoms, we get a
graph GΓ,G . The nodes of GΓ,G are the elements of the given set G, and the relation →
is defined by
                  x→Γ
                       y iff the sentence All x are y belongs to Γ
We call this the all-graph of Γ on G. Graphs of this form are the main reason why we
introduce graphs in this section.
   There are two special cases of this construction which interest us. One is where G = P,
the set of all atoms. The second is where we have a set Γ and another sentence ϕ, and
G is the set of all atoms which occur in Γ or in ϕ.



Definition If G is any graph, we write g →
                                         ∗ h to mean that there is a finite path




                                                                                        15
2 A: the logic of All p are q

                                                                   ∗
from g to h following the edge relation in the graph. The relation → is called the
reflexive-transitive closure of the graph.
  For example, in the graph G in Example 2.6, we have a → ∗ c, using the path a → b → c.
                                                            ∗ is
But paths can be of length 1 or even 0. The full listing of →
              ∗ b b→
             a→         ∗ c a→
                   ∗ c a→    ∗ a b→
                                  ∗ b c→
                                       ∗ c d→
                                            ∗ d e→
                                                 ∗ e



Trees We defined proof trees for our logic in Section 2.2. But we neglected at that
point to say what trees actually are. A tree is a graph with a designated node called the
root with the property that every node is reachable from the root by a unique path. A
leaf of a tree is a node with no successors (no outgoing edges).

Preorders A preorder is a pair P = (P ≤), where P is a set, and ≤ is a relation on
P which is both reflexive and transitive. Reflexivity means that p ≤ p for all p ∈ P .
Transitivity means that if p ≤ q and q ≤ r, then also p ≤ r.
   Perhaps the most natural example of a preorder would be the power set preorder on a
set X. This is (P(X), ⊆), where P(X) is the set of subsets of X, and ⊆ is the inclusion
relation on P(X): A ⊆ B means that every element of A is also an element of B.
   There is a natural way of turning every graph G into a preorder P.
                                                          ∗ ) is a preorder.
Proposition 2.3.1 For any graph (G, →), the structure (G, →
Proof The fact that we allow paths to have length 0 tells us that for each point g in
G, we have g →∗ g. Thus, → ∗ is reflexive. For the transitivity, suppose that g →
                                                                                ∗ h and

h→ ∗ i. Then there is a path from g and h, and another path from h to i. Chaining the

paths gives a path from g to i, showing that g →∗ i.                                  a


2.4 Completeness
The last section was a digression from our main thread in this chapter, the logical system
for A. We now return to that thread and prove the completeness of the system.

Definition Let Γ be a set of sentences in any fragment containing All. Define u ≤Γ v
to mean that
                                  Γ ` All u are v.                              (2.7)
As always, we simplify the notation by dropping the subscript Γ if it is clear from the
context.

Proposition 2.4.1 For all sets Γ, (P, ≤Γ ) is a preorder.
Proof To check that ≤ is reflexive, let u ∈ P. Then we have a one-line proof of All
u are u. Indeed, this is the point of having this kind of no-premise rule in the proof
system. For the transitivity, we put together a proof of u ≤ v with a proof of v ≤ w to
show that u ≤ w.                                                                      a



16
                                                                 2.5 Algorithmic analysis

  We are going to the fact that ≤ is a preorder frequently in this book, and often without
explicitly mentioning it.

The canonical model of a set Γ. We now have an important model construction.
Starting with a set P of atoms and a theory Γ in our language A, we build a model M
from the syntax and the proof theory.

                           M = P
                                                                                      (2.8)
                           [[u]] = ↓ u = {v ∈ M : v ≤ u}

We read ↓ u as “the down-set of u.” So we are taking the nouns to be the elements of
our model, and we interpret a given noun u as the set of all nouns v which we can prove
to be included in u. M is called the canonical model of Γ.

Lemma 2.4.2 The canonical model of Γ satisfies Γ.

Proof Suppose All p are q belongs to Γ. Then p ≤ q. We must show that [[p]] ⊆ [[q]].
Let v ∈ [[p]]. Then by (2.8), v ≤ p. Since ≤ is transitive, v ≤ q. That is, v ∈ [[q]]. This
for all v shows our result.                                                              a

Theorem 2.4.3 The logic of Figure 2.2 is complete for A: If Γ |= All p are q, then
Γ ` All p are q.

Proof Suppose that Γ |= All p are q. We must prove that Γ ` All p are q. Consider M
from (2.8). By Lemma 2.4.2, M satisfies all sentences in Γ. By hypothesis, we see that
All p are q is true in M. Thus [[p]] ⊆ [[q]]. We always have p ≤ p, and so p ∈ [[p]]. Hence
p ∈ [[q]]. This means that p ≤ q, so that Γ ` All p are q, as desired.                    a

Remark The proof in fact shows that if Γ 6|= All p are q, then All p are q is false in M.
So we have a very special and important fact: to see whether a given sentence ϕ follows
from Γ or not, we only have to see whether ϕ is true or false in one model, M. We say
that this model M is a characteristic model of Γ.


2.5 Algorithmic analysis
The original definition of the entailment relation Γ |= ϕ involves looking at all models
of the language. If we are given Γ and ϕ and we want to know whether or not Γ |= ϕ,
we can say “no” by producing a counter-model : a model of Γ where ϕ fails. If we want
to say “yes”, the easiest way would be to provide a derivation in our proof system of ϕ
from Γ. This would show that Γ ` ϕ, and then by soundness (Proposition 2.2.1), we
would know that indeed Γ |= ϕ.
   But suppose that we are given Γ and ϕ, and we don’t know whether or not Γ |= ϕ. For
example, suppose we are faced with Γ and ϕ from Example 2.4. What happens now?



                                                                                        17
2 A: the logic of All p are q

We could try building a counter-model and searching for a proof at the same time. This
would work, but we would like something better. That “something better” would be an
algorithm that was more detailed and more organized than a blind search, and that either
gave a derivation or a counter-model. This is the topic of this section. The centerpiece of
this section is Theorem 2.5.1 just below, a refined version of the completeness argument
which we saw in Section 2.4. Theorem 2.5.1 leads to an algorithm which we present in
Figure 2.5.

Theorem 2.5.1 Let Γ be any set of sentences in A, let G be any set of atoms which
includes the atoms in Γ, and let G be the all-graph of Γ on G. Let →
                                                                   ∗ be the reflexive-
                                                                   Γ
transitive closure of the graph relation in G. Let p, q ∈ G. Then the following are
equivalent:
        ∗ q.
  (i) p →
        Γ

 (ii) Γ ` All p are q.

(iii) Γ |= All p are q.

Proof (1)⇒(2): we show by induction on the number n that if q is reachable from p
in G by a path of length n, then Γ ` All p are q. If n = 0, then p = q, and we have a
one-point proof tree of All p are p. Suppose our result is true for n, and also that q is
reachable from p in G by a path of length n + 1. Fix such a path. Suppose that q 0 is the
point on the path right before q. Then q 0 is reachable from p in G by a path of length
n. So by induction hypothesis, we have Γ ` All p are q 0 . Since there is an edge from q 0
to q, we know that the sentence All q 0 are q belongs to Γ. So we can take T and add a
step at the end:
                                 ..
                                  ..
                           All p are q 0 All q 0 are q
                                                       Barbara
                                     All p are q
This is a proof tree over Γ, and it shows that Γ ` All p are q.
 (2)⇒(3): this is the soundness result for the logic which we saw in Proposition 2.2.1.
 (3)⇒(1): we show the contrapositive. Assume that p 6→      ∗ q. Let N be the following
                                                            Γ
model: the universe is the set G, and the interpretation is given by
                                                    ∗ u}
                                 [[u]] = {v ∈ G : v →
                                                    Γ
                                                                                        (2.9)

We claim that N |= Γ. To see this, suppose that Γ contains the sentence All x are y. We
show that [[x ]] ⊆ [[y]]. Let z ∈ [[x ]]. That is, z ∈ G and there is a path from z to x in
GΓ,G . The atom y occurs in Γ and hence belongs to G. Then taking the path from above
and adding the edge from x to y shows that z →           ∗ y. This for all x shows that indeed
                                                         Γ
[[x ]] ⊆ [[y]]; and the preceding observation for all sentences in Γ shows that N |= Γ. By
definition of →   ∗ , p→∗ p. Also, p ∈ G by hypothesis. So p ∈ [[p]]. Our overall assumption
                  Γ     Γ
that p 6→ Γ
                               / [[q]]. Hence N 6|= All p are q.
           ∗ q tells us that p ∈

    This completes the proof.                                                                a



18
                                                                  2.5 Algorithmic analysis

We are given a finite set Γ and a sentence ϕ = All p are q, and we wish to tell whether
or not Γ ` ϕ. If Γ ` ϕ, we give a derivation; if Γ 6` ϕ, we give a counter-model.

   (i) Let G be the set of atoms in Γ together with p and q.

  (ii) Let G = (G, →
                   Γ
                     ) be the all-graph of Γ on G.
                                                  ∗ of the edge relation of G.
 (iii) Calculate the reflexive-transitive closure →
                                                  Γ
                                     ∗ q, then a path in G gives a proof tree in the logic,
 (iv) If Step (iii) has shown that p →
                                     Γ
      showing that Γ ` ϕ. If not, then we construct a model N of Γ where ϕ fails. We
      take the universe to be G, and interpret each atom u by {v : v →  ∗ u}.
                                                                        Γ

                Figure 2.5: The algorithm to determine if Γ ` ϕ or not.


Corollary 2.5.2 Let Γ ∪ {All p are q} be a set of sentences in A. Let G be the set of
atoms in Γ together with p and q. Let G be the all-graph of Γ on G. Then the following
are equivalent:
  (i) Γ |= ϕ.
        ∗ q in G.
 (ii) p →
        Γ


   Corollary 2.5.2 leads to the algorithm presented in Figure 2.5. More to the point,
Corollary 2.5.2 shows that the algorithm is correct. Given a finite set Γ and a sentence
ϕ (say, All p are q), we first take the set of atoms in Γ. We add p and q to this set if they
are not there already, and then the resulting set is called G. We construct the all-graph
of Γ on G. The all-graph is directly read from Γ. There is a well-known algorithm which,
given any relation R finds the reflexive-transitive closure R∗ . So we apply this algorithm
to the all-graph of Γ on G, and we ask whether or not p →      ∗ q. If so, then the proof of
                                                              Γ
(1) ⇒ (2) in Theorem 2.5.1 shows how to turn the path into a derivation in the logic. If
not, then the model N constructed in (3) ⇒ (1) is a counter-model : a model of Γ where
the putative conclusion All p are q is false.



Example 2.8 We have seen a theory Γ in Example 2.4. The relevant set G here is
{j, k, l, m, n, p, q}. The all-graph of Γ on G is shown in Figure 2.6. The figure also shows
the preorder P associated to Γ.
   We challenged you in Example 2.4 to see whether Γ ` All p are n or not. We can see
from Figure 2.6 that p 6→   ∗ n. Even more, we can exhibit a counter-model M: We take

M = {j, k, l, m, n, p, q}, and

       [[j ]] = {j}            [[m]] = {j, k, l, m}         [[p]] = {j, k, l, m, p, q}
       [[k ]] = {j, k, l}      [[n]] = {j, k, l, n}         [[q]] = {j, k, l, m, p, q}
       [[l ]] = {j, k, l}



                                                                                          19
2 A: the logic of All p are q

                                                                     
                        All j are k,     All j are l,   All k are l, 
                   Γ =   All l are k,     All l are m,   All k are n,
                         All m are q,     All p are q,   All q are p
                                                                     

                                                         p, q
                                p

                          n                              m                n

              l
                          j                                      k, l
                                k

                                     m     q                      j

Figure 2.6: Γ is from Example 2.4. We show the all-graph of Γ on the set of atoms which
            occur in Γ, There is no special reason why we laid out the graph on the page
            like this; it was “random.” We also show the preorder associated to Γ. The
            preorder is displayed as a Hasse diagram: For example, since j ≤ k, we draw
            j below k. Note also that k ≤ l and l ≤ k. We indicate this in the picture
            by situating k and l together.


We got each of these from (2.9): the interpretation of each atom u is the set of atoms
which can reach u in the all-graph.



Comments There are a few comments to be made at this point. These are based on
questions which I have received in teaching this material, or similar material, to bright
students.
   (1) Doesn’t this proof confuse syntax and semantics? This is a good question, since we
are building a model out of the “material from the syntax” (in this case, the atoms). But
when one thinks about it, there is nothing wrong with building a model out of chairs,
numbers, abstract objects, or even the same objects that we used in the syntax. It is
more interesting that the interpretation function [[ ]] in the model was defined in terms
of a syntactic notion, the proof system. Again, we are free to define the semantics of a
model any way we like. It is interesting that we prove completeness in this way. But in
a sense it should not be such a surprise. For completeness is about a relation between
syntax and semantics, and so it makes sense that it involves a single structure that has
aspects of both.
   (2) I thought that the semantic assertion Γ |= ϕ meant that all models of Γ are again
models of ϕ. How is it that we only argue completeness on one particular model rather
than many models? It’s true that our semantic assertion Γ |= ϕ is a statement about
all models. But this does not mean that in proving something we need to use all the



20
                                                                               2.6 Exercises

models. In a sense, the question can be turned around to make an observation: the
model M we built from a set Γ is as “bad” as any model could possibly be! It makes
true any sentence which does not follow from Γ. So once we have built a single model
that covers for all the models, we can use that one model to prove completeness.

What you need to know to go on At this point, you should understand a few things
well: the syntax of the language in this chapter, beginning with the set P of atoms;
the semantics of the language, including the definition of a model and the definition of
when a model satisfies a given sentence; the proof theory, defined in terms of two rules
of inference; the statements of soundness and completeness; the proof that our logical
system is complete (it was done twice); the general issue of algorithms for proof search
in a given logic; how the algorithm works for the particular logic in this chapter; the
definition of a counter-model to an assertion of the form Γ ` ϕ.
   The reason that you should understand all of this is because in most of the remaining
chapters, we shall see an ever-increasing array of logics. Each time, we’ll see all of the
iitalicized points; of course, the specific details will vary with the logic. It would be good
to really understand all of the points above. One way to be sure would be to write out
explanations of everything mentioned in the last paragraph. Be sure to use your own
words, but also to use all of the symbols that we introduced in this chapter.


2.6 Exercises

Exercise 1. Here is an exercise just to see if you got the main points of this chapter.
Let
                   Γ = {All x are y, All z are y, All y are w}.
Let ϕ be All x are z. For each of the following assertions, say whether true or false, with
a reason:

  (i) Γ |= ϕ.

 (ii) Γ ` ϕ

(iii) x ≤Γ w.

 (iv) x →
        Γ
          w.
       ∗ w.
 (v) x →
       Γ

If you are using the soundness or completeness of the proof system for A in any part,
please be sure to note this. That is, please be aware when you are using significant facts!


Exercise 2. Suppose that Γ ` ϕ. For each of the following assertions, tell whether it
is True or False, with a reason.



                                                                                           21
2 A: the logic of All p are q

  (i) There are infinitely many proof trees over Γ which show that Γ ` ϕ.

 (ii) Any two proof trees over Γ which show that Γ ` ϕ must share a leaf.

(iii) If a sentence of the form All p are p occurs in a derivation tree, then that occurrence
      must be at a leaf.


Exercise 3. Here is a different way to prove the completeness of the logic for A.
Suppose that Γ |= All p are q. Consider the model N where N = {∗}, some one-element
set, and                             
                                        N if Γ ` All p are u
                          [[u]] =                                             (2.10)
                                        ∅ otherwise
Please note that in (2.10), the noun p is the same one as in overall statement.
  By reasoning as in the proof of Theorem 2.4.3, use N to show that Γ ` All p are q.

Exercise 4. This exercise has to do with an aspect of the canonical model defined in
(2.8). Recall that we took M to be P, the set of all atoms with underlies our language
in this chapter. If we had taken M to be the set of atoms which occur in Γ, would our
construction have worked? That is, what (if anything) would have to change in the rest
of this section?

Exercise 5. Let Γ be a set of sentences in A. Prove that for all p and q,
                                     ∗ q iff p ≤ q
                                    p→
                                     Γ          Γ

[Hint: you will need to use induction, in two forms. One direction of this exercise requires
induction on numbers; the other uses induction on proofs in our proof system.]

Exercise 6. Suppose that Γ is the empty set of sentences. Under what conditions on
p and q will we have Γ ` All p are q?

  (i) Give a semantic reason for your answer, one having to do with models.

 (ii) Give a syntactic reason for your answer, one having to do with the proof system.
      In this part, you will need to use induction on proofs.


Exercise 7. Let Γ be a theory in any logical system extending A. Let M be any model
with the property that
                                  [[ ]] : P → P(M ∗ )
is a monotone function. That is, if p ≤Γ q, then [[p]] ⊆ [[q]]. Prove that M |= All p are q,
whenever this last sentence belongs to Γ. [This is not a hard exercise, but it is one that
will be used all the time.]




22
                                                                               2.6 Exercises

Exercise 8. Let P = (P, ≤) be any preorder, and let ↓ be the function from P to its
power-set P(P ) given by
                            ↓ p = {q ∈ P : q ≤ p}

  (i) Show that ↓ is a monotone function.

 (ii) The result in part (1) is a generalization of what we saw in Exercise 7 just above.
      Why is this?


Exercise 9. Here is another logical system. Instead of atoms denoting subsets of a
given set, our syntax starts with a set N of names. We use letters like a, b, etc. for
names here. Then we take as sentences the expressions a = b, where a, b ∈ N. For
the semantics, we start with a set M and interpret a name a by an element [[a]] ∈ M .
(Again, we are not using subsets they way we did in this chapter.) This gives us the
definition of a model M.

  (i) As soon as we have a semantics, we get notions like Γ |= ϕ for this new language.
      State what Γ |= ϕ means, and then give an example of a set Γ and a sentence ϕ
      where Γ |= ϕ holds, and another example where it does not hold.

 (ii) Find a logical system that defines a notion Γ ` ϕ, and give an example of a proof
      in your system.

(iii) Prove that your system is complete.


Exercise 10. If you have worked Exercise 9, then the next step is to combine your
system from that exercise with the logical system for A. We start with sets P and N of
atoms and names, respectively. In the syntax, we use sentences of the following forms:

                                         All p are q
                                         a=b
                                         a isa p

The semantics is just what you would expect. In particular, in a given model M, we
say that a isa p is true if [[a]] ∈ [[p]]. The proof theory for this system should contain the
rules in Figure 2.2, the rules in your system from Exercise 9, and the two extra rules
below:
                            a isa p All p are q        a = b a isa p
                                     a isa q               b isa p
Prove the completeness of the system.




                                                                                           23
3 Additions to A
The logic A is perhaps the simplest possible logic, both in terms of the syntax and
semantics, and also in terms of the proof theory. The simple ideas in Sections 2.4 and ??
get used over and over as we add to the syntax, sometimes with variations.


3.1 Binary intersection terms
This section presents one of those additions, a language A2 where we can talk about
intersections of two sets.

Syntax, semantics, and proof theory Recall that we begin with a set P of atoms. In
addition to P, the fragment of this section uses a different (but related) set P2 whose
elements are the formal pairs x ∧ y of elements of P. We call these items terms. We
allow x and y to be the same, and so we have terms x ∧ x for all atoms x. We take
sentences of the form
                                 All x ∧ y are z ∧ w.
We could read this as

                        All x which are y are also z which are w.

The ∧ symbol is not a term-forming operator in the usual sense; we cannot form terms
like x ∧ (y ∧ z). All of the terms are “binary meets”. We also don’t have variables on
their own as terms in this language. So we cannot say All x ∧ y are z. Instead, we would
say All x ∧ y are z ∧ z. This detail is a choice on our part, and we made it to simplify
some of the work below. We could have made other choices for the syntax, and then
these other choices would be reflected in different formulations of the proof theory.
   We call this language A2 .
   Technically, the terms x ∧ y and y ∧ x are different. However, the idea is that they
should denote the same set, and so they will be semantically identical. That is, for all
models M,
                                   [[x ∧ y]] = [[y ∧ x]]                             (3.1)
(We have not given the semantics yet, but you might try to guess it and then to check
that (3.1) holds.) Moreover, the proof theory will also identify them. That is, we’ll have
` All x ∧ y are y ∧ x, and ` All y ∧ x are x ∧ y.
   The semantics of A2 works as follows. Recall that the set P2 is built from some set P
of atoms. We use models of the form

                              M = (M, [[ ]] : P → PM )



                                                                                       25
3 Additions to A

                                     All x ∧ y are z ∧ w All z ∧ w are a ∧ b
            All x ∧ y are y ∧ x                 All x ∧ y are a ∧ b

                                     All x ∧ y are z ∧ w All x ∧ y are a ∧ b
            All x ∧ y are x ∧ x                 All x ∧ y are z ∧ a

                Figure 3.1: Rules for A2 , the logic of binary intersections.


Then we define truth in such a model by:

                   M |= All x ∧ y are z ∧ w     iff   [[x ]] ∩ [[y]] ⊆ [[z ]] ∩ [[w ]].

Derived semantic notions Just as with all our logical languages, once we have a defi-
nition of M |= ϕ, we get the derived notions and M |= Γ and Γ |= ϕ automatically. (See
Figure 2.1.) The main technical work is in crafting a proof system so as to define Γ ` ϕ
in a syntactic way, and then to prove the soundness and completeness of this logical
system.

Logic We have a logical system for this language, using the rules in Figure 3.1. The
first two rules are the preorder property of the order relation. The third law tells us that
All x ∧ y are x ∧ x. As another instance of this rule, we get All x ∧ y are y ∧ y. The final
law in the figure is a variant on saying that z ∧ a is the greatest lower bound of z and a.
It says that if an arbitrary element (x ∧ y) is below both z and a, then it is below z ∧ a.

Soundness/Completeness Fix a set Γ of sentences in the logic. We define an order ≤Γ
on P2 by
                   x ∧ y ≤Γ a ∧ b iff Γ ` All x ∧ y are a ∧ b
As before, we sometimes drop the Γ from the notation. It is important to note that ≤Γ
is always a preorder.

Theorem 3.1.1 Γ ` All x ∧ y are z ∧ w iff Γ |= All x ∧ y are z ∧ w.

Proof The soundness being trivial, we only detail the completeness half of our theorem.
Suppose that Γ |= All x ∧ y are z ∧ w. Let M be the structure defined by
                          M = P2
                          [[u]] = {a ∧ b : Γ ` All a ∧ b are u ∧ u}
We claim that M |= Γ. For this, let All u ∧ v are a ∧ b belong to Γ. Let c ∧ d ∈ [[u]] ∩ [[v ]].
From Γ we have All c ∧ d are u ∧ u and also All c ∧ d are v ∧ v. We have a derivation
from Γ:                 ..                      ..
                         ..                      ..
              All c ∧ d are u ∧ u All c ∧ d are v ∧ v
                            All c ∧ d are u ∧ v             All u ∧ v are u ∧ u
                                            All c ∧ d are u ∧ u



26
                                                               3.2 Verbs and relative clauses

So c ∧ d ∈ [[u]]. Similarly, c ∧ d ∈ [[v ]], and so c ∧ d ∈ [[u]] ∩ [[v ]]. In this way, the sentence
u ∧ v ≤ a ∧ b holds in M.
  At this point, we know that M |= Γ. By our overall assumption that Γ |= All x ∧ y are z ∧ w,
we know that All x ∧ y are z ∧ w holds in M. Now x ∧ y ∈ [[x ]] ∩ [[y]], easily. So
x ∧ y ∈ [[z ]] ∩ [[w ]]. Thus we have a derivation from Γ:
                                    ..                   ..
                                     ..                   ..
                          All x ∧ y are z ∧ z All x ∧ y are w ∧ w
                                     All x ∧ y are z ∧ w

This completes the proof.                                                                     a



3.2 Verbs and relative clauses
The subject of this chapter is additions that we can make to the system A whose sen-
tences are just those of the form All x are y. We saw one addition in Section 3.1, and
now we turn to another. In this section, we add verbs. The idea is that we would like
to consider sentences such as All cats chase all rats. To put this in the mold of A, we
think of this as All cats (chase all rats). So our semantics will arrange that chase all rats
is interpreted by a set, just as cats is; and then we shall say that All cats (chase all rats)
is true in a given model iff [[cats]] ⊆ [[chase all rats]]. And to interpret chase all rats by a
set invites us to go further. We can just as well have chase all x where x is “the same
type of object as” chase all rats. For example, we could have chase all (see all birds). The
idea is that this would denote the entities which chase everything which chases all birds.
Now the natural language construct that this brings up are relative clauses. In English,
these are the snippets of language which frequently (but not always) start with a rela-
tive pronoun such as who or which and which modify and follow some head noun. Our
formal language in this section is not an adequate treatment relative clauses: it is only
the beginning. It only covers subject relative clauses rather than object relative clauses.
For example, we’ll have sentences corresponding to Everyone who likes all plumbers sits
but not Everyone who all plumbers like sits. Worse, we’ll have no way to modify head
nouns at all. To extend what we do in this section to cover sentences like Every carpenter
who likes all plumbers sits would involve mixing the work of this section with that of
Section 3.1. So overall, what we have is a formal language which is not going to read
like English at all (despite what we would want). It is going to serve as a language in
which to interpret a small number of sentences involving verbs and relative clauses. But
despite is meager linguistic interest, it gives us an opportunity to build a new (and, we
hope, interesting) logical system.


Syntax of A(RC) We start with one collection P of unary atoms (for nouns), just as
we did with A in Section 2. But we also start with another collection, R of and another
of binary atoms. We use these for transitive verbs.



                                                                                             27
3 Additions to A

   We define the set terms of A(RC) to be the smallest collection containing the unary
atoms and with the property that if x is a set term and r is a binary atom, then r all x
is a set term. We frequently call these terms.
   Note that set terms allow recursion. So we get set terms like

                              see all (like all (hate all dogs)).

(Of course, this is on the assumption that P and R contain the words shown above.)
Although we are not yet done with the syntax of the language, the interpretation of the
set term above in a given model would be the set of individuals who see all who like all
who hate all dogs.
   The sentences of A(RC) are the expressions All x y, where x and y are set terms. We
frequently use parentheses in the syntax to increase the readability.


Semantics A model M for A(RC) is a set M , the “universe”, together with interpre-
tations of the atoms. For each unary atom p, we have an interpretation [[p]] ⊆ M . And
for each binary atom r, we have an interpretation [[r ]] ⊆ M × M .
   We use an inductive definition to interpret the set terms. The model comes with
interpretations of the unary atoms, the “base case” of set terms. And the general case
is
                [[see all x]] = {m ∈ M : for all n ∈ [[x ]], (m, n) ∈ [[see]]}

And then we say
                               M |= All x y iff [[x ]] ⊆ [[y]]




Example 3.1 Consider the model M with universe {1, . . . , 7}, and with interpretations
of three unary atoms, boys, males, females, and one binary atom, see, shown in Figure 3.2.
   In this model,
                        [[see all boys]]           = {2, 3, 4, 5, 7}
                        [[see all males]]          = {3, 4, 5, 7}
                        [[see all females]]        = {5}
                        [[see all (see all boys)]] = {5}

Here are some examples of sentences false and true in the model:

                     M 6|= All (see all boys) (see all males)
                     M |= All (see all females) (see all (see all boys))
                     M |= All (see all (see all boys)) (see all females)




28
                                                                   3.2 Verbs and relative clauses


                                                               1


                    [[boys]] = {1}
                                                               2
                    [[males]] = {1, 6}

                    [[females]] = {3, 5, 7}                    3

                                                        4             5

                                                 6                            7



                          Figure 3.2: The model from Example 3.1.

The logic of our language A(RC) is presented in Figure 3.3. The main new law is
the last one, which we call (Anti), for antitone. To check the soundness, let M be a
model, and assume that [[q]] ⊆ [[p]]. To see that [[r all q]] ⊆ [[r all p]], let x ∈ [[r all q]]. Let
y ∈ [[p]]. So y ∈ [[q]] as well. Thus x[[r ]]y. This for all y ∈ [[p]] shows that x ∈ [[r all p]].


Example 3.2        Here is a derivation showing that All x (see all y), All z y ` All x (see all z):
                                                  All z y
                                                                  Anti
                     All x (see all y) All (see all y)(see all z)
                                                                  Barbara
                                   All x (see all z)




The canonical model MΓ of a set of assertions Γ in this logic We are given a set Γ in
this language A(RC). We aim to build a model M = MΓ of Γ with the property that if
M |= ϕ, then Γ ` ϕ. This would prove the completeness theorem for our logic, because
if Γ 6` ϕ, then M 6|= ϕ. (In other words, every sentence which is true in all models of Γ
(hence in M) would be provable from Γ.)
   Here is the definition. In it, p is a unary atom and r a binary one.
                             [[p]] = {x : Γ ` All x p}
                                                                                               (3.2)
                             [[r ]] = {(x, y) : Γ ` All x (r all y)}
  The clause for unary atoms is what we saw in Section 2. But the clause for the binary
atoms should not be obvious.




                                                                                                  29
3 Additions to A



                               All x y All y z                            All y x
               Axiom                           Barbara                                     Anti
     All x x                        All x z                        All (r all x) (r all y)

Figure 3.3: The logical system for A(RC). Note that we are using this with x, y, and z
            as set terms, not only as unary variables.


Example 3.3       Suppose we have two unary atoms p and q, and one binary atom r. Let

                                          Γ = {All p are q}

To make the notation simpler, let us write p0 for p, and pn+1 for r all pn ; we adopt similar
notation for q. Then in the canonical model of Γ, we have [[p]] = {p0 }, [[q]] = {p0 , q0 },
and the interpretation of r is shown below:

                       p0 o`       p1 o      p2 o`   p3 o     p4        ···

                                      ~                 ~
                       q0 o        q1 o      q2 o    q3 o     q4        ···

  It should be noted that we are cheating a bit in this. It is fairly easy to see that the
arrows above are included in the canonical model. To do this, we only would need to
exhibit the derivations corresponding top the arrows. But to show that no others arrows
are present, one would have to do a lot more work. In fact, it is usually easier to offer
a semantic proof of this. For that, one would take the model above and then to show
that every missing arrow corresponds to a semantic fact (by examining the model more
deeply), and then it follows that what we have above is the canonical model. If this
point is mysterious, then please don’t worry: we’ll revisit this issue as we proceed.



Lemma 3.2.1 Let Γ be a set of sentences in A(RC), and let M be the canonical model
of Γ as defined in (3.2). For all set terms x,

                                    [[x]] = {y : Γ ` All y x}



Proof The proof is by induction on x. When x is a unary atom, our result is by the
definition of our model. Assume that x is a set term and that our lemma holds for x;
we prove that
                         [[r all x]] = {y : Γ ` All y (r all x)}
First, let y ∈ [[r all x]]. By induction hypothesis, x ∈ [[x ]]. So (y, x) ∈ [[r ]]. That is,
Γ ` All y (r all x). In the other direction, assume that Γ ` All y (r all x). Suppose



30
                                                                    3.2 Verbs and relative clauses

We are given a finite set Γ of A(RC) and a sentence ϕ, and we wish to tell whether or
not Γ ` ϕ. If Γ ` ϕ, we give a derivation; if Γ 6` ϕ, we give a counter-model.

   (i) Let M0 be the set of set terms in Γ ∪ {ϕ}. Let M be the closure of M0 under
       subterms. Let M ∗ be M ∪ {r all z : z ∈ M1 }.

  (ii) Write Γ `confined ψ if there is a derivation tree of ψ from Γ all of whose set terms
       belong to Γ ∪ {ϕ} or are subterms of the root, ψ. Then calculate

                                {(x, y) ∈ M × M ∗ : Γ `confined All x y}.



 (iii) Let M be the model whose universe is M , and whose structure is defined as
       follows:
                  [[x ]] = {y ∈ M : Γ `confined All y x}
                  [[r ]] = {(x, y) ∈ M × M : Γ `confined All x (r all y)}

 (iv) If Step 2 includes a verification that Γ ` ϕ, then of course we are done. If not,
      then M is a model of Γ where ϕ fails (see Theorem 3.2.7).

                   Figure 3.4: An algorithm to determine if Γ ` ϕ or not.


that z ∈ [[x ]]. Then by induction hypothesis, Γ ` All z x. Now consider the following
derivation:                                             ..
                                  ..                     ..
                                   ..                All z x
                           All y (r all x) All (r all x) (r all z)
                                        All y (r all z)
So (y, z) ∈ [[r ]]. This for all z ∈ [[x ]] shows that y ∈ [[r all x]].                         a


Lemma 3.2.2 M |= Γ.

Proof Suppose that Γ contains All u v. To see that this sentence holds in M, let
y ∈ [[u]]. By Lemma 3.2.1, Γ ` All y u. And then using the logic, we have Γ ` All y v. a


Lemma 3.2.3 If M |= ϕ, then Γ ` ϕ.

Proof    Let ϕ be All a b. Let M be the model constructed above. M |= Γ, by
Lemma 3.2.2. So [[a]] ⊆ [[b]] in M. But a ∈ [[a]], using (Axiom) in our system and
also Lemma 3.2.1. And so a ∈ [[b]]. And this shows that Γ ` All a b, as desired. a


Theorem 3.2.4 The logical system in Figure 3.3 is sound and complete for A(RC).



                                                                                               31
3 Additions to A

Algorithmic analysis Theorem 3.2.4 shows the completeness of the logic under study.
Our next order of business is to do the algorithmic analysis. If we have a finite set S of
set terms and finite set Γ, and another sentence ϕ, then we can answer the question

        Is there a derivation showing Γ ` ϕ all of whose set terms belong to S?

We can answer this question efficiently, simply by generating all of the relevant deriva-
tions.
   However, in general we have Γ and ϕ, but not S. And so to tell whether or not Γ ` ϕ,
we need to know a priori about a relevant set S which is “big enough” for our purposes.
The good news is that we can find such a set S. It turns out that we can take S to be
all set terms in Γ ∪ {ϕ}, together with all subterms of those terms.
   Figure 3.4 presents an algorithm to tell whether or not a given finite set Γ logically
implies a given sentence ϕ. The algorithm depends on a few definitions.

Definition If p is a unary atom, the only subterm of p is p itself. The subterms of r
all x are the subterms of x together with the set term r all x.
   For fixed Γ and ϕ, a proof tree T in A(RC) is confined if every set term in T is either
a subterm of a term in Γ ∪ {ϕ} or a subterm of the root of T. (Note that this notion
depends on Γ and on ϕ.) We write Γ `confined ψ if Γ ` ψ via a confined proof tree.
  First, we show that what we have in Figure 3.4 deserves to be called an algorithm.

Remark Figure 3.4 describes an algorithm which, given a finite set Γ ∪ {ϕ} in A(RC),
produces a model M.
  Here is the reason. For all set terms x and y, let us consider the question of whether or
not Γ `confined All x y. We can decide yes or no to this question by generating all proof
trees which are built using the terms in Γ along with x and y, and all their subterms.
In more detail, the set of consequences of Γ that interests us is the fixed point of a
monotone inductive definition on a finite set.
  Using this fact, here is how we build M.

  (i) Find the set M of subterms of terms in Γ ∪ {ϕ}; there are only finitely many such
      terms;

 (ii) Find the set W of all sentences All u v with the property that u and v either belong
      to M or are subterms of either x or y. This W is also finite.

(iii) Let S0 = Γ

(iv) Given Sn , let Sn+1 be the set of sentences in W which can be inferred in one step
     using the sentences in Sn and the rules in our logical system for A(RC).

 (v) Since W is finite, there must be some n such that Sn = Sn+1 .

Once we have W , we can read off the structure of the model M.



32
                                                             3.2 Verbs and relative clauses

Lemma 3.2.5 For all x ∈ M , [[x]] = {y ∈ M : Γ `confined All y x}.

Proof The proof is by induction on x. When x is a unary atom, our result is by the
definition of M. Assume our lemma holds for x; we prove that if r all x belongs to M ,
then
                   [[r all x]] = {y ∈ M : Γ `confined All y (r all x)}.
First, let y ∈ [[r all x]]. M is closed under subterms, by definition. Since r all x belongs
to M , so also x ∈ M . Note that Γ `confined All x x. Hence by induction hypothesis,
x ∈ [[x ]]. So (y, x) ∈ [[r ]]. That is, Γ `confined All y (r all x). In the other direction,
assume that Γ `confined All y (r all x). Suppose that z ∈ [[x ]]; we show that (y, z) ∈ [[r]].
Then by induction hypothesis, Γ `confined All z x. Now consider the following derivation
tree:                                                      ..
                                     ..                     ..
                                      ..                All z x
                              All y (r all x) All (r all x) (r all z)
                                           All y (r all z)                              (3.3)
We claim that this tree is confined. Every term in the missing subtree on the left is
either a subterm of Γ ∪ {ϕ} or of y or of r all x. Every term in the missing subtree on
the right is either a subterm of Γ ∪ {ϕ} or of z or of x. But y and r all z are subterms
of the root, z is a subterm of r all z, r all x belongs to M and is thus a subterm of
Γ ∪ {ϕ}, and x is a subterm of r all x. Thus every term in the derivation tree of (3.3)
is either a subterm of Γ ∪ {ϕ} or is a subterm of the root of the tree. We conclude that
Γ `confined All y (r all z), and this goes to show that (y, z) ∈ [[r ]].               a

Proposition 3.2.6 M |= Γ.

This is Exercise 15, and it is an easy consequence of Lemma 3.2.5.

Theorem 3.2.7 The algorithm in Figure 3.4 is correct. That is, if Γ 6` ϕ, then M is a
model of Γ where ϕ fails.

Proof Recall that we fixed Γ and ϕ and then constructed M from them. By Proposi-
tion 3.2.6, M |= Γ. We prove the contrapositive of our statement: if M |= ϕ, then Γ ` ϕ.
Suppose that M |= ϕ, and write ϕ as All u v. Then u and v belong to M0 ⊆ M . By
Lemma 3.2.5, u ∈ [[u]]. So u ∈ [[v ]]. But then by the lemma again, Γ `confined All u v. So
Γ ` All u v, as desired.                                                                  a

Corollary 3.2.8 If Γ ` ϕ, then there is a derivation of ϕ from Γ all of whose set terms
belong to Γ ∪ {ϕ}.

Proof Assume that Γ ` ϕ. Recall that the notion of confined used in Theorem 3.2.7
is defined from Γ and ϕ. We need only show that Γ `confined ϕ. By soundness, Γ |= ϕ.
As mentioned in the proof of Theorem 3.2.7, the model M satisfies Γ. By soundness,
M |= ϕ. And then the argument in that proof shows exactly that Γ `confined ϕ.     a



                                                                                           33
3 Additions to A



Example 3.4      Here is a question: does the conclusion follow?
                        All boys men
                        All (see all women) (see all (see all boys))
                        All (see all (see all boys)) women
                        All women (see all men)
                        All (see all boys) (see all men)

To answer this question, we take Γ to be the assumptions above, and M0 then consists
of the set terms
                 boys                     (1)            see all women (5)
                 see all boys             (2)            men           (6)
                 see all (see all boys)   (3)            women         (7)
                 see all men              (4)
This set is closed under subterms. And so M = M0 . M ∗ would add see all (see all
women), see all (see all men), and see all (see all (see all boys)).
  It would take a fair amount of work to get the structure of the model by hand, but
the algorithm is straightforward. We would get the following structure: for the unary
atoms:
                       [[boys]]  = {boys}
                       [[men]]   = {boys, men}
                       [[women]] = {women, see all (see all boys)}
And for the binary atom see, the structure is as shown in Example 3.1. The numbering
above shows the correspondence between the elements of M and the points shown in
Example 3.1. By Proposition 3.2.6, M |= Γ. In this example we are interested in
All (see all boys) (see all men). This sentence is false in M. This shows that Γ 6`
All (see all boys) (see all men).
  Incidentally, M is isomorphic to the one depicted in Figure 3.2. The numbers corre-
spond to the listing of the set terms earlier in this example.


Many verbs Our syntax and semantics of A(RC) allows the set R of binary atoms to
be arbitrary. Yet in our examples, we always took it to be a singleton set {see}. We did
this to simplify matters: all the points which we wanted to make up until now are may
be illustrated with examples containing just one verb.
  There are a few additional interesting phenomena that happen with more than one
verb. The first is that we might want to work with background assumptions that are not
expressible in our logic so far. For example, consider the following purported inference:
                          All women are football players
                          All football fans love all football players
                                                                                    (3.4)
                          All football fans like all women




34
                                                                               3.3 Exercises

The way in which we are doing things so far, there is no relation between like and love in
our models. And so the inference above fails. Yet there is a sense in which a competent
speaker would agree to the conclusion given the premises. And we cannot add a premise
such as “loving involves liking” because this is not expressible in the language. For this
reason, we expand or overall framework.

Background assumptions on verbs In addition to our assumptions Γ, we can adopt a
set ∆ of background assumptions of the form r v s for r, s ∈ R. In this case above, we
might have
                              ∆ = {loves v likes}


Definition A model M respects ∆ if whenever r v s belongs to ∆, then [[r ]] ⊆ [[s]] in
M.
  In the proof theory, we define Γ; ∆ ` ϕ by adding to the proof system in Figure 3.3
the following rules:
                             All x (r all y)
                                             Background
                             All x (s all y)
We have one rule for each inequality assertion r v s in ∆.
     Turning back to (3.4), we take ∆ = {like v love}. And then (3.4) might be formalized
as
All fans (love all players)                              All women players
                            Background                                                 Anti
All fans (like all players)                    All (like all players) (like all women)
                                                                                       Barbara
                             All fans (like all women)

The main result on this system is left to you in Exercise 18.


3.3 Exercises

Exercise 11. Fill in the details in the last paragraph of the proof of Theorem 3.1.1.

Exercise 12.       Suppose we dropped the last rule in Figure 3.1 and instead used the
following rule:
                           All x ∧ y are z ∧ z All x ∧ y are a ∧ a
                                      All x ∧ y are z ∧ a
This rule is a special case of the rule which was dropped. Let us write Γ `∗ ϕ to mean
that there is a derivation of ϕ from Γ in the second proof system. This problem addresses
the issue of whether Γ ` ϕ is the same as Γ `∗ ϕ. The matter boils down to whether the
two rules are in fact equivalent in the presence of the other rules.
  Here are two ways which you can show this:



                                                                                           35
3 Additions to A

  (i) Check that the arguments in Section 3 go through for the relation Γ `∗ ϕ. There-
      fore, that system is complete. Then say why we must have

                 All x ∧ y are z ∧ w, All x ∧ y are a ∧ b `∗ All x ∧ y are z ∧ a.   (3.5)

 (ii) Show directly that (3.5) holds by giving a derivation.


Exercise 13. Re-read Example 3.3, and check that the picture shown there really is
the canonical model of {All p are q}. That is, show that no edges are missing from the
picture.

Exercise 14. Find the canonical model of

                          Γ = {All p are q, All q (see all p)} .



Exercise 15. Re-read the proof of Theorem 3.2.7. We are given Γ and ϕ, and from
these we construct a model M in Figure 3.4. Show that M |= Γ. [This amounts to a
careful look at the notion of confined proof trees.]

Exercise 16. Let Γ = {All x y, All y z}, and let ϕ be All (see all z) (see all x). The
derivation below shows that Γ ` ϕ:
                            All y z                        All x y
                   All (see all z) (see all y) All (see all y) (see all x)
                                  All (see all z) (see all x)

  (i) Why is the tree above not confined?

 (ii) Show that Γ `confined ϕ.


Exercise 17. Suppose that we take the logical system from Figure 3.3, drop the (Anti)
rule and instead add the following rule
                             All x (see all z) All y z
                                                       Anti0
                                  All x (see all y)

(Example 3.2 shows that (Anti0 ) can be derived in A(RC).) Show that the resulting
logical system is sound and complete. [For the completeness, there are two ways to go.
First, you can check that the completeness proof that we gave would go through for the
new system. Alternatively, you can show how to derive all instances of (Anti) in the
new system.]




36
                                                                                      3.3 Exercises


                                                  (x, y, u)   (x, y, v)   (u, v, z)
                  (x, y, x)        (x, y, y)                  (x, y, z)

          Figure 3.5: The logic of All x which are y are z, written here (x, y, z).


Exercise 18. This exercise concerns the addition of background assumptions on verbs
which we saw on page 35. Prove the following completeness theorem: Let Γ ∪ ϕ be a
set of sentences in A(RC), and let ∆ be a set of background assumptions. Then the
following are equivalent:

  (i) Every model of Γ which respects the assumptions in ∆ satisfies ϕ.

 (ii) Γ; ∆ ` ϕ.


Another variation We conclude this section with a few exercises on a logic for sentences
of the form
                             All x which are y are z.
To save space, we abbreviate this by (x, y, z). We take this sentence to be true in a given
model M if [[x ]] ∩ [[y]] ⊆ [[z ]]. Note that All x are y is semantically equivalent to (x, x, y).

Exercise 19. Prove that the logic of All x which are y are z in Figure 3.5 is complete.
[Hint: you can do this with a one-point model, just as in Exercise 3.]

Exercise 20. Let Γ be a set of (x, y, z) sentences.

  (i) Show that if Γ |= (x, y, z), then Γ |= (y, x, z).

 (ii) Show that if Γ ` (x, y, z), then Γ ` (y, x, z).

(iii) Suppose that we remove the axiom (x, y, y), and in its place take the symmetry
      rule
                                       (y, x, z)
                                       (x, y, z)
      Show that the new system is complete.


Exercise 21. Let ϕ be a sentence of A, say ϕ = All x are y. Let ϕ∗ = (x, x, y). If Γ is
a set of sentences of the first fragment, let Γ∗ = {ϕ∗ : ϕ ∈ Γ}. It is easy to check that if
Γ ` ϕ, then Γ∗ ` ϕ∗ . Prove the converse. We say that the proof system for assertions
(x, y, z) is a conservative extension of the system for All.

Exercise 22. Find a way to show that the logic of binary intersections x ∧ y ≤ z ∧ w
is a conservative extension of the logic of assertions (x, y, z).



                                                                                                37
4 S: the logic of All p are q, Some p are q, and
  No p are q
The language S contains the syllogistic sentences in All, Some, No.


4.1 Syntax and semantics
Starting with a set P of nouns, we take the sentences of S to be those of the form All p
are q, Some p are q, and No p are q, where p and q are nouns. We think of this language
(and its relative S† ) in connection with syllogisms, this is why we use the letter S.
   For the semantics, we use models M that consist of a set M with interpretations [[p]]
of the nouns. Then we define
                            M |= All p are q             iff     [[p]] ⊆ [[q]]
                            M |= Some p are q            iff     [[p]] ∩ [[q]] 6= ∅
                            M |= No p are q              iff     [[p]] ∩ [[q]] = ∅



Example 4.1 Perhaps the first semantic fact to check in this fragment is the interac-
tion of All and Some. For example,

                            {All p are q, Some p are r} |= Some q are r.                                (4.1)

To see this, let M be a model and assume that the two hypotheses are true in M. Then
[[p]] ⊆ [[q]], and also [[p]] ∩ [[r ]] 6= ∅. Let x ∈ [[p]] ∩ [[r ]]. Then x ∈ [[p]] and also x ∈ [[r ]]. Since
x ∈ [[p]] and [[p]] ⊆ [[q]], we also have x ∈ [[q]]. So x ∈ [[q]] ∩ [[r ]]. As a result, [[q]] ∩ [[r ]] 6= ∅.
This means that M |= Some q are r. This argument holds for all M, and so we have
established the semantic assertion stated in (4.1).




Example 4.2          Here is an example of a semantic fact which is expressible in S:

                       {All p are v, All q are w, No v are w} |= No p are q.

To see this, fix a model M where the hypotheses all hold. That is, [[p]] ⊆ [[v ]], [[q]] ⊆ [[w ]],
and [[v ]] ∩ [[w ]] = ∅. By elementary reasoning involving sets, we see that [[p]] ∩ [[q]] = ∅.
This means that M |= No p are q. Since M was an arbitrary model of the hypotheses,
we are done.



                                                                                                           39
4 S: the logic of All p are q, Some p are q, and No p are q

                                                    All p are n All n are q
                         All p are p                       All p are q

                       Some p are q                      Some p are q
                       Some q are p                      Some p are p

               All q are n Some p are q             All p are n No n are q
                      Some p are n                         No p are q

                         No p are q                       No p are p
                         No q are p                       No p are q

                         No p are p             Some p are q No p are q
                         All p are q                       ϕ            X


                                 Figure 4.1: The rules of S.




Example 4.3        For fixed p and q, there are no models which satisfy both of the sentences
below:
                           Some p are q       and       No p are q.

For this reason,
                               {Some p are q, No p are q} |= ϕ                          (4.2)

for any sentence ϕ. That is, if we write out what it means for (4.2) to hold, we see that
it does hold vacuously.




Example 4.4        Let us check that

               {Some p are q, Some q are n, All q are m} 6|= Some p are n

by building a model in which the hypotheses hold and the conclusion fails. Let ϕ be
Some p are q, and let ψ be Some q are n. (That is, we take the points of the model to be
sentences.) We take for a model M = {ϕ, ψ} with [[p]] = {ϕ}, [[q]] = {ϕ, ψ}, [[n]] = {ψ},
[[m]] = {ϕ, ψ}. It is clear that M has the desired properties.


  Incidentally, the reason that we take the points of the model in Example 4.4 to be
sentences and not (say) numbers is to foreshadow a general construction. See Exercise ??.



40
                                                                                     4.2 Proof theory

4.2 Proof theory
See Figure 4.1 for the rules of S.



Example 4.5           The first important derivation in the logic:

                                            All n are p Some n are n
                                                  Some n are p
                               All n are q         Some p are n
                                          Some p are q

That is, if there is a n, and if all ns are ps and also qs, then some p is a q.




Example 4.6           Corresponding to Example 4.2, let us check that

                         {All p are v, All q are w, No v are w} ` No p are q.


                                             All p are v No v are w
                                                    No p are w
                                All q are w         No w are p
                                           No p are q
                                           No q are p                                           (4.3)



  The proof system has a principle relating Some and No. We have seen the semantic
reason behind this principle in Example 4.3, and we incorporate this fact into the proof
system by taking the rule of ex falso quodlibet (also called ex contradictione quodlibet)
to our system1 . This is the rule (X) in Figure 4.1.

Definition A set Γ is inconsistent if Γ ` ϕ for all ϕ. Otherwise, Γ is consistent.


Theorem 4.2.1 The logic in Figure 4.1 is sound and complete for S.


4.3 The classical syllogistic forms
There are fifteen valid classical syllogistic forms. Figure 4.2 shows some of them.
 1
     Please do not confuse this with reductio ad absurdum. See page 73 for more on this.




                                                                                                  41
4 S: the logic of All p are q, Some p are q, and No p are q


      All p are q All r are p                     No p are q All r are p
                              Barbara                                    Celarent
             All r are q                                No r are q

      All p are q Some r are p                    No p are q Some r are p
                               Darii                                      Ferio
             Some r are q                              Some r are q 0

      No p are q All r are q                      All p are q No r are q
                             Cesare                                      Camestres
            No r are p                                   No r are p

      No p are q Some r are q                     All p are q Some r are q 0
                              Festino                                        Baroco
           Some r are p0                                 Some r are p0


Figure 4.2: The valid Aristotelian syllogistic forms of the first and second figures, with
            their traditional names. Usually these syllogistic forms are not written with
            the notation p0 but rather with the English word not.


4.4 S† : syllogistic logic with full negation on nouns
We now study the language S† which is strictly bigger than S in that it has noun-level
negation rather than sentence-level negation.
  In the syntax, we again begin with a set P of (unary) atoms. We use p, q, . . ., for
atoms. The idea once again is that unary atoms represent plural common nouns. Let

                                Lit    =    P ∪ {p0 : p ∈ P}.

In other words, we have two copies of P, using the symbol 0 to distinguish the copies.
We call the elements of this set literals following uses in areas of logic. Once again, the
elements of Lit as either atoms p, q, etc., or as complemented atoms p0 , q 0 , . . .. Moreover,
we extend this idea of complementation to a function complementation operation 0 :
Lit → Lit on the literals such that p00 = p for all literals p. (Yes, we use the same
letters p, q, etc. to range over literals in this section.) This involutive property implies
that complementation is a bijection on Lit. Then we consider sentences All p are q and
Some p are q. Here p and q are any literals, including the case when they are the same.
We call this language S† . We shall use letters like ϕ to denote sentences.

Semantics One starts with a set M and a subset [[p]] ⊆ M for each literal p, subject
to the requirement that [[p0 ]] = M \ [[p]] for all p. This gives a model M = (M, [[ ]]). We
then define the satisfaction relation M |= ϕ just as in earlier sections, and also derived
notions such as Γ |= ϕ.




42
                                         4.4 S† : syllogistic logic with full negation on nouns

                                     Some p are q                   Some p are q
                        Axiom                     Some1                          Some2
          All p are p                Some p are p                   Some q are p

         All p are n All n are q                      All q are n Some p are q
                                 Barbara                                       Darii
                All p are q                                  Some p are n

         All q are q 0                                All q 0 are q
                       Zero                                         One
         All q are p                                  All p are q

         All q are p0                                 All p are q    Some p are q 0
                       Antitone                                                     X
         All p are q 0                                               S


                                    Figure 4.3: Rules for S†


Example 4.7        We claim that Γ |= All x are z, where

          Γ    =      {All y 0 are p, All p are q, All q are y, All y are p, All q are z}.

Here is an informal explanation. Since all y and all y 0 are p, everything whatsoever is a
p. And since all p are q, and all q are y, we see that everything is a y. In particular, all
x are y. But the last two premises and the fact that all p are q also imply that all y are
z. So all x are z.



Exercise 23. Here is an example which we mention mostly as a challenge. Let Γ be
the set of the sentences below:

               All y are x, All y 0 are x, All z 0 are y, All z are y 0 , All z are w.

It is not true that
                                         Γ ` All y are w.

Find a model M |= Γ where [[y]] 6⊆ [[w ]]. The point of this exercise is that the details of
the completeness proof for our logic will give us a way of automatically solving problems
like this!
   We shall see the solution later.


No In previous work, we took No p are q as a basic sentence in the syntax. There is
no need to do this here: we may regard No p are q as a variant notation for All p are q 0 .
In other words, if one wants to add No as a basic sentence forming-operation, on a par
with Some and All, it would be easy to do so.



                                                                                             43
4 S: the logic of All p are q, Some p are q, and No p are q

Proof trees We have discussed the meager syntax of S† and its semantics. We next
turn to the proof theory whose rules are listed in Figure 4.3.
   We attached names to the rules in Figure 4.3 so that we can refer to them later. We
usually do not display the names of rules in our proof trees except when to emphasize
some point or other. The names “Barbara” and “Darii” are traditional from Aristotelian
syllogisms. But the (Antitone) rule is not part of traditional syllogistic reasoning. It is
possible to drop (Some 2 ) if one changes the conclusion of (Darii ) to Some n are p. But
at one point it will be convenient to have (Some 2 ), and so this guides the formulation.
The rules (Zero) and (One) are concerned with what is often called vacuous universal
quantification. That is, if q 0 ⊆ p, then q is the whole universe and q 0 is empty; so q is a
superset of every set and q 0 a subset. We have already seen the rule (X) rule: it permits
inference of any sentence ϕ whatsoever from a contradiction.



Example 4.8       Returning to Example 4.7, here is a proof tree showing Γ ` All x are z:

                        All p are q All q are y
        All y 0 are p          All p are y                       All p are q All q are z
                         0
                    All y are y                    All y are p          All p are z
                    All x are y                              All y are z
                                         All x are z




4.5 Orthoposets and their representations
An important step in our work is to develop an algebraic semantics for S† . There are
several definitions, and then a representation theorem. As with other uses of algebra in
logic, the point is that the representation theorem is also a model construction technique.

  An orthoposet is a tuple P = (P, ≤, 0, 0 ) such that

  (i) (P, ≤) is a partial order: ≤ is a reflexive, transitive, and antisymmetric relation on
      the set P .

 (ii) 0 is a minimum element: 0 ≤ p for all p ∈ P .

(iii) x 7→ x0 is an antitone map in both directions: x ≤ y iff y 0 ≤ x0 .

 (iv) x 7→ x0 is involutive: x00 = x.

 (v) complement inconsistency: If x ≤ y and x ≤ y 0 , then x = 0.



44
                                                        4.5 Orthoposets and their representations

   The notion of an orthoposet mainly appears in papers on quantum logic. (In fact, the
stronger notion of an orthomodular poset appears to be more central there. However, I
do not see any application of this notion to logics like S† .)



Example 4.9           The example below is sometimes called the Chinese lantern, and we’ll
call it P2 .2
                                                    1


                                  p       p0                 q       q0


                                                    0
Here and elsewhere, we understand (x0 )0 = x, 00 = 1, 10 = 0.




Example 4.10 For example, for all sets p we have an orthoposet (P(X), ⊆, ∅, 0 ), where
⊆ is the inclusion relation, ∅ is the empty set, and a0 = X \ a for all subsets a of p.


Definition Let Γ be any set of sentences in S† . Γ need not be consistent. Definition 2.4
defines the fundamental relation ≤ from Γ and the logic, and Proposition 2.4.1 shows
this relation to be a preorder. We have an induced equivalence relation ≡, and we take
LitΓ to be the quotient set Lit/≡. That is, we define u ≡ v to mean u ≤ v and v ≤ u.
This quotient set Lit/≡ is a poset under the induced relation: if [u] ≤ [v] and [v] ≤ [u],
then u ≡ v so that [u] = [v]. If there is some p such that p ≤ p0 , then for all q we
have [p] ≤ [q] in Lit/≡ In this case, set 0 to be [p] for any such p. (If such p exists,
its equivalence class is unique.) We finally define [p]0 = [p0 ]. If there is no p such that
p ≤ p0 , we add fresh elements 0 and 1 to Lit/≡. We then stipulate that 00 = 1, and that
for all x ∈ PΓ , 0 ≤ x ≤ 1.
   It is not hard to check that we have an orthoposet Lit/≡ = (Lit/≡, ≤, 0, 0 ). The
antitone property comes from the axiom with the same name, and the complement
inconsistency is verified using the similarly-named part of Lemma 26.




Example 4.11 This example pertains to Example 23 from before. Let Γ be defined
by
        Γ = {All y are x, All y 0 are x, All z 0 are y, All z are y 0 , All z are w}.
 2
     The more standard name for this seems to be M 02, with M O standing for modular ortholattice.




                                                                                                     45
4 S: the logic of All p are q, Some p are q, and No p are q

Then
                               [x] = {x}                 [x0 ] = {x0 }
                               [y] = {y, z 0 }           [y 0 ] = {y 0 , z}
                               [z] = {y 0 , z}           [z 0 ] = {y, z 0 }
                               [w] = {w}                 [w0 ] = {w0 }
  Here is a picture of the orthoposet PΓ :

                                                 [x]

                              [z 0 ] = [y]                         [w]

                                 [w0 ]                        [y 0 ] = [x]

                                                 [x0 ]




Definition Let P and Q be orthoposets. A morphism of orthoposets f : P → Q is a
is a map m : P → Q preserving the order (if x ≤ y, then mx ≤ my), the complement
m(x0 ) = (mx)0 , and minimum elements (m0 = 0). We say m is strict if the following
extra condition holds: x ≤ y iff mx ≤ my.

Definition A point of an orthoposet P = (P, ≤, 0, 0 ) is a subset S ⊆ P with the
following properties:

  (i) If p ∈ S and p ≤ q, then q ∈ S (S is up-closed ).

 (ii) For all p, either p ∈ S or p0 ∈ S (S is complete), but not both (S is consistent).




Example 4.12 Let X = {1, 2, 3}, and let P(X) be the power set orthoposet from
Example 4.10. Then S is a point, where

                         S   =     {{1, 2}, {1, 3}, {2, 3}, {1, 2, 3}}.

(More generally, if p is any finite set, then the collection of subsets of p containing more
than half of the elements of p is a point of P(X).) Also, it is easy to check that the
points on this P(X) are exactly S as above and the three sets T1 , U2 , and T3 , where

                                 Ti = {A ⊆ X : i ∈ A}.




46
                                                 4.5 Orthoposets and their representations

  If you know about ultrafilters of boolean algebras, then you should compare the defi-
nition of a point with that of an ultrafilter. (And if you do not know about ultrafilters,
please skip over this paragraph.) Both definitions have something in common and both
serve the same purpose in being related to a representation theorem. But there is a
formal difference as well: the point S in Example 4.12 shows that a point of a boolean
algebra need not be an ultrafilter or even a filter.

Lemma 4.5.1 For a subset S0 of an orthoposet P = (P, ≤, 0 ), the following are equiva-
lent:

  (i) S0 is a subset of a point S of P.

 (ii) For all x, y ∈ S0 , x 6≤ y 0 .


Proof Clearly (1) =⇒ (2). For the more important direction, use Zorn’s Lemma to get
a ⊆-maximal superset S1 of S0 with the consistency property. Let S = {q : (∃p ∈ S1 )q ≥
p}. So S is up-closed. We check that consistency is not lost: suppose that r, r0 ∈ S.
Then there are q1 , q2 ∈ S1 such that r ≥ q1 and r0 ≥ q2 . But then q20 ≥ r ≥ q1 . Since
q1 ∈ S1 , so too q20 ∈ S1 . Thus we see that S1 is not consistent, and this is a contradiction.
To conclude, we only need to see that for all r ∈ P , either r or r0 belongs to S. If r ∈  / S,
then r ∈                                                           0
        / S1 . By maximality, there is q ∈ S1 such that q1 ≤ r . (For otherwise, S1 ∪ {r}
would be a consistent proper superset of S1 .) And as r0 ∈    / S, there is q2 ∈ S1 such that
                                 0
q2 ≤ r. Then as above q1 ≤ q2 , leading to the same contradiction.                            a
   We now present a representation theorem that implies the completeness of the logic.
It is due to Calude, Hertling, and Svozil [?]. We also state an additional technical point.

Theorem 4.5.2 (Representation Theorem for Orthoposets [?, ?, ?]) Let P = (P, ≤
, 0 ) be an orthoposet. There is a set points(P ) and a strict morphism of orthoposets
m : P → P(points(P )).
                                                                           S
     Moreover, if S ∪ {p} ⊆ P has the following two properties, then m(p) \ q∈S m(q) is
non-empty:

  (i) For all q ∈ S, p 6≤ q.

 (ii) For all q, r ∈ S, q 6≥ r0 .


Proof     Let points(P ) be the collection of points of P. The map m is defined by
m(p) = {S : p ∈ S}. The preservation of complement comes from the completeness and
consistency requirement on points, and the preservation of order from the up-closed-ness.
Clearly m0 = ∅. We must check that if q 6≥ p, then there is some point S such that
p ∈ S and q ∈  / S. For this, take S = {q} in the “moreover” part. And for that, let
             0
T = {p} ∪ {q : q ∈ S}. Lemma 4.5.1 applies, and so there is some point u ⊇ T . Such u
belongs to m(p). But if q ∈ S, then q 0 ∈ T ⊆ U ; so u does not belong to m(q).        a



                                                                                            47
4 S: the logic of All p are q, Some p are q, and No p are q



Example 4.13 Here is a picture which illustrates the workings of the Representation
Theorem 4.5.2. We presented an orthoposet P2 in Example 4.9. Three subsets of the
underlying set are points, and these are shown in colors below3 .

                           1                               1                        1                       1
                 p    p0       q       q0         p   p0       q    q0     p   p0       q   q0     p   p0       q q0
                           0                               0                        0                       0

We call these points •, •, •, and •. The orthoposet

                                                       Q       =     P({•, •, •, •})

has sixteen elements, so we shall not display it. But we can illustrate the function
m : P2 → Q. For example, m(p) = {•, •}, because the points to which p belongs are •
and •. Similarly, m(0) = ∅. Here is a picture of P2 and its image under m inside Q:

                           1                                                        {•, •, •, •}

          p      p0                q         q0            {•, •}        {•, •}                        {•, •}      {•, •}

                           0                                                                ∅



4.6 Completeness
The completeness theorem is based on algebraic machinery that we have just seen.

Lemma 4.6.1 (Pratt-Hartmann) Suppose that Γ |= Some p are q. Then there is
some sentence in Γsome , say Some a are b, such that

                                            Γall ∪ {Some a are b} |= Some p are q.



Proof         If not, then for every ϕ ∈ Γsome , there is a model Mϕ |= Γall ∪ {ϕ} and
[[p]] ∩ [[q]] = ∅ in the model. Take the disjoint union of the models Mϕ to get a model of
Γall ∪ Γsome = Γ where Some p are q fails.                                              a

Lemma 4.6.2 Let Γ ⊆ S† . There is a model M = (M, [[ ]]) such that

     (i) M |= Γall .
 3
     If you cannot see the colors, the four points are {p, q, 1}, {p0 , q, 1}, {p, q 0 , 1}, and {p0 , q 0 , 1}.




48
                                                                         4.6 Completeness

 (ii) If ϕ ∈ A and M |= ϕ, then Γ ` ϕ.

(iii) If Γ is consistent, then also M |= Γsome .


Proof We write PΓ for the orthoposet Lit/≡. (Recall that this was obtained by from
the set of literals by taking quotient by p ≡ q iff p ≤ q ≤ p. See Definition 4.5.) Let n
be the natural map of P into PΓ , taking an atom p to its equivalence class [p]. Even
though P is not an orthoposet with its order ≤, it is a preorder (see Proposition 2.4.1).
This map n is an order-preserving map from one preorder P into another. Moreover, n
preserves the order in both directions. We also apply Theorem 4.5.2, to obtain a strict
morphism of orthoposets m as shown below:

                            P
                                  n    /   PΓ   m
                                                            P
                                                    / points( Γ )

Let M = points(PΓ ), and let [[ ]] : PΓ → P(M ) be the composition m ◦ n, regarded as an
order-preserving function on preorders. We thus have a model M = (points(PΓ ), [[ ]]).
  We check that M |= Γ. Note that n and m are strict monotone functions. So the
semantics has the property that the All sentences holding in M are exactly the conse-
quences of Γ. We turn to a sentence in Γsome such as Some u are v. Assuming the
consistency of Γ, u 6≤ v 0 . Thus [[u]] 6⊆ ([[v ]])0 . That is, [[u]] ∩ [[v ]] 6= ∅.   a
  Unfortunately, the last step in this proof is not reversible, in the following precise
sense. It does not follow from u 6≤ v 0 that Γ ` Some u are v. (For example, if Γ is the
empty set we have u 6≤ v 0 , and indeed M(Γ) |= Some u are v. But Γ only derives valid
sentences.)

Theorem 4.6.3 (Completeness of the proof system for S† ) Γ ` ϕ iff Γ |= ϕ.

Proof As always, the soundness half is trivial. Suppose that Γ |= ϕ; we show that
Γ ` ϕ. We may assume that Γ is consistent.
  If ϕ is a sentence All p are q, consider M(Γ) from Lemma 4.6.2. It is a model of Γ,
hence of ϕ; and then by the property the second part of the lemma, Γ ` ϕ.
  For the rest of this proof, let ϕ be Some p are q. From Γ and ϕ, we find a and b
satisfying the conclusion of Lemma 4.6.1.
  We again use Lemma 4.6.2 and consider the model M = M(Lit/≡Γall ) of points on
Lit/≡Γall . M |= Γall .
  Consider {[a], [b], [p0 ]}. If this set were a subset of a point x, then consider {x} as a
one-point submodel of M. In the submodel, Γall ∪ {Some a are b} would hold, and yet
Some p are q would fail since [[p]] = ∅.
  We use Lemma 4.5.1 to divide into cases:

  (i) a ≤ a0 .

 (ii) a ≤ b0 .

(iii) a ≤ p.



                                                                                         49
4 S: the logic of All p are q, Some p are q, and No p are q

 (iv) b ≤ b0 .

 (v) b ≤ p.

 (vi) p0 ≤ p.
(More precisely, the first case would be [a] ≤ [a0 ]. By strictness of the natural map, this
means that a ≤ a0 ; that is, Γall ` All a are a0 .) In cases (1), (2), and (4), we easily see
that Γ is inconsistent, contrary to the assumption at the outset. Case (6) implies that
both (3) and (5) hold. Thus we may restrict attention to (3) and (5).
   Next, consider {a, b, q 0 }. The same analysis gives two other cases, independently:
a ≤ q, and b ≤ q. Putting these together with the other two gives four pairs. The
following are representative:
   a ≤ p and b ≤ q: Using Some a are b, we see that Γ ` Some p are q.
   a ≤ p and a ≤ q: We first derive Some a are b, and then again we see Γ ` Some p are q.
   This completes the proof.                                                                a
 Recall that consistency is a syntactic concept; a set Γ is consistent if Γ 6` Some p are p0 .
The matching semantic concept is satisfiability: Γ is satisfiable iff it has a model.

Corollary 4.6.4 A set Γ ⊆ S† is consistent iff it is satisfiable.


4.7 Algorithmic analysis
At this point we have the completeness of the logical system for S† . We’d like to go
a bit further and give an efficient algorithm to tell whether, given a finite Γ ⊆ S† and
some ϕ ∈ S† , Γ ` ϕ or not. Further, if Γ 6` ϕ, we’d like an algorithm to construct a
counterexample. Our leading ideas come from work we did on A in Section 2, especially
the graph GΓ and Theorem 2.5.1.
   Fix a finite set Γ ⊆ S† . We construct a graph GΓ (different from the one in Section 2)
in several steps.
 (a) The points of GΓ are the elements of Lit which occur in Γ.

 (b) First, we put p →
                     Γ
                       q if Γ contains either All p are q or All q 0 are p0 .
                         ∗ q if there is a path of length at least zero4 from p to q
 (c) Second, we define p →
                         Γ
     following →
               Γ
                 .
                                                       ∗ p0 , and p is a one-point if p0 →
 (d) Third, we say that a point p is a zero-point if p →                                 ∗ p.
                                                       Γ                                 Γ
     (A point could be both a zero-point and a one-point. Also p is a zero-point iff p0
     is a one-point.)

 (e) Finally, we write p ∗∗
                         →
                         Γ
                                          ∗ q, or if p is a zero-point, or if q is a one-point.
                            q if either p →
                                          Γ
                       ∗ and ∗∗
Lemma 4.7.1 Concerning →     →  :
                       Γ     Γ
 4
     There always is a path of length zero from a point in a graph to itself. So for all points p in GΓ , p Γ∗→ p.




50
                                                                    4.7 Algorithmic analysis

  (i) The relation ∗∗
                   →
                   Γ
                      is transitive.
           ∗ q, then q 0 →
 (ii) If p →             ∗ p0 .
           Γ             Γ

(iii) If p ∗∗
           →
           Γ
              q, then q 0 ∗∗
                          →
                          Γ
                             p0 .

 (iv) If p ∗∗
           →
           Γ
              p0 , then p →
                          ∗ p0 .
                          Γ



Proof For (1), assume that p →      ∗∗ q and q → ∗∗ r. Then there are nine cases, and in
                                    Γ            Γ
                             ∗∗
each of these, we see that p →   r. Part (2) is an easy induction on the lengths of paths
                             Γ
showing p →∗ q. Part (3) is a direct verification, using the fact that p is a zero-point iff
           Γ
 0
p is a one-point. Part (4) also follows easily from the definitions.                      a


Theorem 4.7.2 Let Γ ⊆ S† . The following are equivalent:

  (i) Γ ` All p are q in our system for S† .

 (ii) p ∗∗
        →
        Γ
           q.


Proof For (1)=⇒(2), we argue by induction on proofs in our system for S† that if
Γ ` All p are q, then p ∗∗
                        →Γ
                            q. Note first that a proof from Γ must only use the sentences
of Γ, the axioms All p are p, and the rules (Barbara), (Antitone), (Zero), and (One).
The base case is for a proof tree consisting of a sentence in Γ or an axiom. In the first
of these cases, we put p →  Γ
                                q by point (b). In the second, we use (c) with a path of
length zero. For the induction step, we break into cases as to the rule at the root, and
in all cases we use Lemma 4.7.1. For example, if the rule at the root is (Barbara),
deriving All p are q from All p are r and All r are q, then by induction hypothesis p ∗∗  →Γ
                                                                                              r
and r →∗∗ q. By the first part of the lemma, p →   ∗∗  q. The induction step for (Antitone)
       Γ                                           Γ
similarly uses the third part of the lemma. Here is the induction step for (Zero); the
step for (One) is similar. Suppose Γ ` All p are q using a tree whose last step applies
(Zero) to All p are p0 . By induction hypothesis, p →      ∗∗ p0 . By part (4) of the lemma,
                                                            Γ
p→ ∗ q, so p is a zero-point. Then we have p →  ∗∗   q, as desired.
   Γ                                             Γ
   In the other direction, we show that if p →   ∗∗ q, then Γ ` All p are q. If p → q, then
                                                  Γ                                 Γ
clearly Γ ` All p are q with a one-point tree, or perhaps a two-point tree. An easy
induction on the number n shows that if there is a path in →       Γ
                                                                     of length n from p to q,
then again Γ ` All p are q. This shows that if p →      ∗ q, then Γ ` All p are q. So if p is a
                                                        Γ
zero-point, then Γ ` All p are p. This means that for all q, Γ ` All p are q. Similarly, if q
is a one-point, then for all p, Γ ` All p are q. From these last two observations, if p ∗∗
                                                                                         →Γ
                                                                                             q,
Γ ` All p are q.                                                                              a


Running time If GΓ has n points (that is, if there are n literals in Γ), then the relation
∗∗
→  may be computed in time O(n3 ). This is a standard result in algorithms.
Γ




                                                                                            51
4 S: the logic of All p are q, Some p are q, and No p are q

An algorithm to tell if Γ is consistent or not At this point, we give an algorithm to
solve the first main problem about S† , to tell whether a given finite set Γ is consistent.
Our work is based on the following result.

Lemma 4.7.3 Γ is inconsistent iff there is a sentence Some p are q in Γsome such that
Γall ` All p are q 0 .

   We leave the proof to you as Exercise 28. Based on this fact, here is how we can tell
if Γ is consistent. First, compute the relation ∗∗
                                                →
                                                Γ
                                                     . Then go through the sentences Some
                                                  ∗∗
p are q in Γsome , and for each of them, see if p →    q or not. By Theorem 4.7.2; there is
                                                   Γ
such a sentence iff Γ is inconsistent.

An algorithm to tell if Γ ` All p are q or not To tell if Γ ` All p are q in this logic, we
first check if Γ is consistent. If not, then Γ ` All p are q. (Why is this?) We thus assume
that Γ is consistent. We claim that Γ ` All p are q iff Γall ` All p are q. (By induction
on proofs in our current system, any proof in this system whose root is an All sentence
and which does not use (X) must consist entirely of All sentences.) We build GΓ , and
compute the relation ∗∗ →Γ
                            . Then see if p ∗∗
                                            →Γ
                                                q or not.

An algorithm to tell if Γ ` Some p are q or not We need a bit of preliminary work. As
before, we may assume that Γ is consistent. By Lemma 4.6.1 and Theorem 4.6.3, there
is a sentence Some a are b in Γsome such that
                          Γall ∪ {Some a are b} ` Some p are q
The proof may not use (X), since Γ is consistent. Define ∗∗→
                                                           Γ
                                                               from Γall . By Exercise 29,
we have a ∗∗
           →
           Γ
              p or b ∗∗
                     →
                     Γ
                        p, and also that a ∗∗
                                           →
                                           Γ
                                              q or b ∗∗
                                                     →
                                                     Γ
                                                        q.
  Thus to see whether a consistent Γ derives Some p are q, look for a sentence Some a
                              ∗∗ p or b →
are b in Γ such that either a →         ∗∗ p, and also either a →∗∗ q or b →
                                                                           ∗∗ q. If such a
                              Γ          Γ                       Γ          Γ
sentence Some a are b in Γ exists, then Γ ` All p are q, and vice-versa.

An algorithm to build a model of a consistent set Γ If Γ is consistent, then the model
M from Lemma 4.6.2 satisfies Γ. Suppose that Γ has n literals. The universe M of this
model is the set of points on an orthoposet of size at most n, and so M has size at most
2n . The rest of the construction of M is polynomial.


4.8 Exercises
In these exercises, Γ ` ϕ refers to derivability in our current system.

Exercise 24. Show that
                           All y are p, All y 0 are p ` All x are p.




52
                                                                                    4.8 Exercises

Exercise 25. Show that

            All y are p, All y 0 are p, All q are z, Some x are z 0 ` Some p are q 0 .



Exercise 26. Show the following:

  (i) Some p are p0 ` ϕ (a contradiction fact)

 (ii) All p are n, No n are q ` No q are p (Celarent)

(iii) No p are q ` No q are p (E-conversion)

(iv) Some p are q, No q are n ` Some p are n0 (Ferio)

 (v) All q are n, All q are n0 ` No q are q (complement inconsistency)


Exercise 27. Prove Corollary 4.6.4, using Theorem 4.6.3.

Exercise 28. Γ is inconsistent iff there is a sentence Some p are q in Γsome such that
Γall ` All p are q 0 .
  [This is Lemma 4.7.3. As a hint, for the =⇒ direction, use Lemma 4.6.1.]

Exercise 29. Let Γ be consistent, and assume that Γall ∪{Some a are b} ` Some p are q.
Show that a ≤Γ p or b ≤Γ p, and also that a ≤Γ q or b ≤Γ q. [Hint: there are two ways
to prove this. One is to give a semantic argument: if a 6≤Γ p and b 6≤Γ p, get a one-point
model of Γall ∪ {Some a are b} where [[p]] = ∅. Alternatively, one can use an induction
on proofs in our system.]




                                                                                              53
5 R: the relational syllogistic
At this point, we turn to logics with verbs. The basic goal is to have a logical system in
which we may represent a valid argument such as
                       Every porter recognizes every porter
                       No quarterback recognizes any quarterback                     (5.1)
                       No porter is a quarterback

5.1 Syntax and semantics of R
As in our previous work, we adopt as minimal a syntax as needed. In fact, the English
sentences of interest are listed in Figure 5.1. below, using p and q for nouns and r for
verbs.
   The name of this fragment comes from the word “relation”, since a transitive verb
– that is, a verb which takes a direct object – will be interpreted as a relation on the
universe M .
   It would be possible to write the syntax of R in English, as we have done with our
previous systems. But we prefer to introduce some symbols. The main reason is that
some sort of symbolic notation is needed in our larger fragments, if only because the
English sentences would not fit on one line in long derivations. And so with an eye to
the future, we (somewhat reluctantly) begin now to introduce some notation.
   The syntax of R starts the same way as the syntax of A(RC) (see page 27). All of
our work builds on collections P of unary atoms and R of binary atoms. This time we
include a complement operation on both unary and binary atoms. (So this is a difference
with what we saw earlier with A(RC).) As in Section 4.4, we understand this operation        check the reference
to be involutive, so p and p are taken to be identical, as are r and r. We call the items
p, p, r and r literals.

Set terms At times, it is convenient to adopt a bit of extra notation to the syntax to
simplify presentational matters. We introduce set terms; these are terms which denote
sets in our models. The set terms of R are

                        p   p ∀(p, r)   ∃(p, r) ∀(p, r)   ∃(p, r)

and then we can say that the overall syntax of R is

                                     ∀(p, c)   ∃(p, c)

Set terms play a minor role in this chapter, but when we turn to the larger language
RCA in Section 6, it will be essential to have them.



                                                                                       55
5 R: the relational syllogistic


     ∀(p, q)           all p are q                              ∃(p, q)              some p aren’t q
     ∃(p, q)           some p are q                             ∀(p, q)              no p are q
     ∀(p, ∀(q, r))     all p r all q                            ∃(p, ∃(q, r))        some p don’t-r some q
     ∀(p, ∃(q, r))     all p r some q                           ∃(p, ∀(q, r))        some p don’t-r any q
     ∃(p, ∀(q, r))     some p r all q                           ∀(p, ∃(q, r))        all p don’t-r some q
     ∃(p, ∃(q, r))     some p r some q                          ∀(p, ∀(q, r))        all p don’t-r any q

Figure 5.1: The syntax of R, with renderings in English. It’s important that our seman-
            tics of r is the complement relation of the semantics of r, and so this accounts
            for the unusual (and probably confusing) expression “don’t r.”

Positive and negative sentences; negations The sentences on the left of Figure 5.1
are called positive, and the ones on the right are called negative. The way that the figure
is arranged, each sentence ϕ has a semantic negation ϕ on the other side. For example,
if ϕ is ∀(p, q), then ϕ is ∃(p, q). Note that ϕ = ϕ for all sentences ϕ.

Semantics A model M for R is a set M , together with an interpretation [[p]] ⊆ M for
each noun p ∈ P and an interpretation [[r]] ⊆ M 2 for each verb r. We interpret literals
p and r using complements:
                                [[p]] = M \ [[p]]             [[r]] = M 2 \ [[r]].
We then interpret set terms by subsets of M in the following way
                     [[∀(p, s)]] = {m ∈ M : for all n ∈ [[p]], (m, n) ∈ [[s]]}
                     [[∃(p, s)]] = {m ∈ M : for some n ∈ [[p]], (m, n) ∈ [[s]]}
Finally, we have the definition of truth in a model :
                               M |= ∀(p, c)             iff         [[p]] ⊆ [[c]]
                               M |= ∃(p, c)             iff         [[p]] ∩ [[c]] 6= ∅
Finally, we have definitions of semantic consequence relation Γ |= ϕ, just as we have
seen it for other logical languages.


Example 5.1 We consider a simple case, with one unary atom p, and one binary atom
s. Consider the following model. We set M = {w, x, y, z}, and [[p]] = {w, x, y}. For the
relation symbol, s, we take the arrows below:
                                               wO              /x


                                                    ~          / z y
                                               yo
For example, [[p]] = {z}, [[∀(p, s)]] = ∅, [[∃(p, s)]] = M , and [[∃(p, s)]] = M also. Here are
some R-sentences true in M: ∃(p, p) (but note that ∃(p, p) is not in the fragment R),
and also ∀(p, ∃(p, s)).



56
                                  5.2 Algorithmic analysis: building a model of a satisfiable set

Remark Sentences like “All porters recognize some quarterback” are ambiguous in
English. In R, we can represent the subject wide scope reading: every porter has the
property of recognizing some quarterback or other. It is not possible to represent the
object wide scope reading, where there is one particular quarterback who every porter
recognizes.


5.2 Algorithmic analysis: building a model of a satisfiable set
In contrast to our other logical systems, we first do the algorithmic analysis, and then
turn that analysis into a complete logic for the fragment.
  Let Γ be any finite set of sentences of R, satisfiable or not. We aim to build a model
M = M(Γ) with the following properties:
     (i) M satisfies all of the positive sentences in Γ.
 (ii) If Γ is satisfiable, then M |= Γ.
(iii) M should be easily computed from Γ.
 (iv) If M 6|= Γ, then it should be easily traceable to some feature of Γ.
Of course, the second and third statements are vague.

A worked example As you read on, you might also consult Figure 5.2. That is, you
might look at the set Γ in Figure 5.2 and see if you can build a model of it in a principled
way.
   Before we begin the construction, please review the notation p →  ∗ q from page ??.1
                                                                     Γ
The important semantic point is that if p →       ∗ q, then Γ |= ∀(p, q). (We even have
                                                  Γ
Γ ` ∀(p, q) in A, but this is irrelevant in this section.)
   Since we have only one Γ in this discussion, we lighten the notation and change →   ∗ to
                                                                                       Γ
 ∗
→.
   We define the universe of the model together with the interpretations of the atoms
simultaneously.

The universe M of the model MΓ and an associated set M ∗ of unary atoms.
     (i) If ∃(p, c) ∈ Γ, then the sentence ∃(p, c) belongs to M , and p ∈ M ∗ .
 (ii) If ∃(p, q) ∈ Γ, then in addition q ∈ M ∗ .
(iii) If ∃(p, ∃(q, t))) ∈ Γ, then q ∈ M ∗ and q1 , q2 belong to M .
 (iv) If ∀(p, ∃(q, t)) ∈ Γ and [[p]] 6= ∅, then q ∈ M ∗ , and q1 , q2 belong to M .
We use letters like π to denote arbitrary elements of M , keeping in mind that those
elements are either existential sentences in M or else unary atoms with subscripts.
 1
     I see that there is Γ∗→ and also∗∗
                                      → , and I have to straighten this out.
                                      Γ




                                                                                              57
5 R: the relational syllogistic

Interpretations [[u]] of unary atoms u in MΓ
  (i) If p ∈ M ∗ and p →
                       ∗ u, then p , p ∈ [[u]].
                                  1 2
                           ∗ u, then ∃(p, c) ∈ [[u]].
 (ii) If ∃(p, c) ∈ M and p →
                           ∗ u, then ∃(p, q) ∈ [[u]].
(iii) If ∃(p, q) ∈ M and q →

Interpretations [[r]] of binary atoms r in MΓ
  (i) If ∀(u, ∀(r, v)) ∈ Γ, then x[[r]]y, for all x ∈ [[u]] and y ∈ [[v]].
 (ii) If ∀(u, ∃(q, r)) ∈ Γ and x ∈ [[u]], then (q1 ∈ M and) x[[r]]q1 .
(iii) If ∃(p, ∃(q, r)) ∈ Γ, then ∃(p, ∃(q, r))[[r]]q1 .
 (iv) If ∃(p, ∀(q, r)) ∈ Γ, then ∃(p, ∀(q, r))[[r]]x for all x ∈ [[q]].

The set M ∗ We mostly use this set M ∗ for convenience; it saves a small amount of
notation. M ∗ is the set of unary atoms u such that M contains u1 and u2 . (Recall that
M also contains the existential sentences of Γ.)
Lemma 5.2.1 If ϕ ∈ Γ and ϕ is positive, then M |= ϕ.
Proof We check this by examining all the possible cases as to the syntax of ϕ. These
are all straightforward verifications. For example, let us consider the last part. The
sentence ∃(p, ∃(q, r)) belongs to M ; call it ϕ. Moreover, ϕ ∈ [[p]] because p →  ∗ p. In

addition, M contains q1 (and q2 ). Finally, ϕ[[r]]q1 . This shows that indeed M |= ϕ.   a
   The converse of the second part of Lemma 5.2.1 is obvious, but the converse of the
first part is false. For example, if Γ is ∃(q, q), ∀(q, p), then M ∗ = {q} but [[p]] = {q} =
                                                                                           6 ∅.

Our main result is that M satisfies all of the sentences in Γ, provided it is satisfiable
in the first place. First some subsidiary results:
Lemma 5.2.2 If p ∈ M ∗ , then [[p]] 6= ∅. If [[p]] 6= ∅, then Γ |= ∃(p, p).
Proof     This is by induction on on the construction of the model.                            a

Lemma 5.2.3 If [[p]] ∩ [[q]] 6= ∅, then Γ |= ∃(p, q).
Proof          There are three cases, depending on the nature of the common element of
[[p]] ∩ [[q]], and also the reasons for having this in both [[p]] and [[q]]. Here are some of the
cases.
    Suppose that ui ∈ [[p]] ∩ [[q]]. Then u ∈ M ∗ , and so Γ |= ∃(u, u) by Lemma 5.2.2. We
also have u →    ∗ p, q so that Γ |= ∀(u, p) and Γ |= ∀(u, q). Then easily Γ |= ∃(p, q).

    Suppose that ∃(p1 , c1 ) ∈ [[p]] ∩ [[q]]. Then p1 →  ∗ p and p →    ∗ q. So Γ |= ∀(p , p) and
                                                                     1                   1
Γ |= ∀(p1 , q). In this case, Γ |= ∃(p1 , p1 ), and so we get Γ |= ∃(p, q).
                                                                            ∗ p and q →
    For a final case, suppose that ∃(p1 , q1 ) ∈ [[p]] ∩ [[q]], say with p1 →          ∗ q. Since
                                                                                     1
Γ |= ∃(p1 , p1 ), and so we once agin get Γ |= ∃(p, q).                                         a



58
                                 5.2 Algorithmic analysis: building a model of a satisfiable set

Let Γ be the set below
     All j are k       All j are l
                                            All p see some k           ϕ1 : Some n sees some m
     All k are l       All l are k
                                            ϕ2 : Some j is a j         ϕ3 : Some n fails to see some m
     All l are m       All k are n
                                            All l see some n           All l fail to see some n
     All m are q       All p are q
     All q are p


We show MΓ . The set M is

                                   {ϕ1 , ϕ2 , ϕ3 , m1 , m2 , k1 , k2 , n1 , n2 }

The interpretations of the unary atoms are given by

                                 [[p]] = [[q]]      =   {ϕ2 , m1 , m2 , k1 , k2 }
                                         [[m]]      =   {ϕ2 , m1 , m2 , k1 , k2 }
                                  [[k]] = [[l]]     =   {ϕ2 , k1 , k2 }
                                           [[n]]    =   {ϕ1 , ϕ3 , n1 , n2 , k1 , k2 }
                                            [[j]]   =   {ϕ2 }

The interpretation of see is the set of ordered pairs below:

    {(ϕ1 , m1 ), (ϕ2 , k1 ), (m1 , k1 ), (m2 , k1 ), (k1 , k1 ), (k2 , k1 ), (ϕ2 , n1 ), (k1 , n1 ), (k2 , n1 )}.

Figure 5.2: A worked example. The set Γ includes the set which we saw in Example 2.8
            on page 20 .


   We know that a set Γ is unsatisfiable if there is no model of all of the sentences in
Γ. We next introduce a definition of what it means for a set Γ of sentences in R to be
promptly unsatisfiable. The definition consists of many cases, and so we list them in
Figure 5.3. The idea is that if Γ is promptly unsatisfiable, then it should be “easy” to
use one of the conditions to see that Γ really is unsatisfiable; it should not be a matter
of “deep reasoning” or extensive searching.

Lemma 5.2.4 The following are equivalent:

  (i) Γ is unsatisfiable.

 (ii) Γ is promptly unsatisfiable.

(iii) M 6|= Γ.


Proof It is trivial that (1)=⇒(3). It is fairly easy to check that (2)=⇒(1): if any of the
conditions C1–C6 hold, then Γ is unsatisfiable. Let us check the first of the conditions
                                                                   ∗ q. But then Γ |= ∀(p, q).
in Figure 5.3, C1. If ∃(p, q) gets put in [[q]], it must be that p →



                                                                                                                    59
5 R: the relational syllogistic

     C1 There is a sentence ∃(p, q) ∈ Γ such that in M, ∃(p, q) ∈ [[q]].

 C2a There is a sentence ∀(p, q) ∈ Γ and some u ∈ M ∗ so that u →
                                                                ∗ p and u →
                                                                          ∗ q.


 C2b There are ∃(u, c) and ∀(p, q) in Γ such that in M, ∃(u, c) ∈ [[p]] ∩ [[q]].

     C3 The sentence ∀(p, ∀(q, r)) belongs to Γ, and one of the following hold:
           1. There is a sentence ∀(a, ∀(b, r)) in Γ such that [[p]] ∩ [[a]] 6= ∅, [[q]] ∩ [[b]] 6= ∅.
           2. ∀(p, ∃(q, r)) belongs to Γ, and [[p]] 6= ∅.
           3. ∃(p, ∀(q, r)) belongs to Γ, and [[q]] 6= ∅.
           4. ∃(p, ∃(q, r)) belongs to Γ.

 C4a There are ∀(p, ∃(q, r)) and ∀(p0 , ∀(q 0 , r)) in Γ and u ∈ M ∗ such that u →
                                                                                 ∗ p, p0 ,
           ∗  0
     and q → q .

 C4b There are ∀(p, ∃(q, r)), ∃(p0 , ∀(q 0 , r)) in Γ such that p0 →         ∗ q0.
                                                                   ∗ p and q →


 C5a There are ∃(p, ∀(q, r)) and ∀(p0 , ∀(q 0 , r)) in Γ, and x ∈ [[q]] ∩ [[q 0 ]], such that p →
                                                                                                ∗ p0 .


 C5b There are ∃(p, ∀(q, r)) and ∀(p0 , ∃(q 0 , r)) in Γ, such that p →
                                                                      ∗ p0 and q 0 →
                                                                                   ∗ q.

                                                                   ∗ u and q →
     C6 There are ∃(p, ∃(q, r)) and ∀(u, ∀(v, r)) in Γ such that p →         ∗ v.


     Figure 5.3: A set Γ is promptly unsatisfiable if any of the conditions above hold.


Of course, Γ |= ∃(p, q), since this sentence belongs to Γ. But then Γ |= ∃(q, q). Thus Γ
is unsatisfiable.

  The main work is to show (3)=⇒(2): assuming that M 6|= Γ, we’ll show that one of
C1–C6 must hold. We do this by examining the six types of negative sentences. For each,
we assume that it fails in M, and we identify the corresponding condition in Figure 5.3
that must hold.
  First, let ϕ be ∃(p, q). Note that ϕ ∈ M . As always in this proof, we assume that
M 6|= ϕ. In particular, ϕ ∈ [[q]]. Note that q is not related by →
                                                                 ∗ to anything, so the
                                            ∗
only way that ϕ can belong to [[q]] is if p → q. Thus C1 holds.
  Second, let ϕ be ∀(p, q). Since M 6|= ϕ, we have x ∈ [[p]] ∩ [[q]]. We have several cases
depending on whether x is a sentence ϕ or a subscripted atom ui . If x is ui , then we see
       ∗ p and u →
that u →           ∗ q. So we have C2a. If x is ∃(u, c) for some set term c, then C2b

holds.
    Third, let ϕ be ∀(p, ∀(q, r)). Assume that M 6|= ϕ. Let x ∈ [[p]] be related by [[r]] to
y ∈ [[q]]. There are four subcases, corresponding to the four clauses of the definition of
[[r]] in M.
    Subcase 1: There is a sentence ∀(a, ∀(b, r)) in Γ such that x ∈ [[p]] ∩ [[a]], y ∈ [[q]] ∩ [[b]].



60
                            5.2 Algorithmic analysis: building a model of a satisfiable set

 Subcase 2: x ∈ [[p]], y is q1 , and the sentence ∀(p, ∃(q, r)) belongs to Γ.
 Subcase 3: x is ∃(p, ∀(q, r)) and y ∈ [[q]].
 Subcase 4: x is ∃(p, ∃(q, r)) and y is q1 .
These together lead to C3.
    Fourth, let ϕ be ∀(p, ∃(q, r)). Suppose that π ∈ [[p]] is related by [[r]] to all elements of
[[q]]. Since ϕ ∈ Γ, our overall construction has arranged that q ∈ M ∗ ; the point of this is
that M contains q2 . We have three subcases concerning π.
    Subcase 1: π is of the form ui , or else ∃(u, c), so that u →     ∗ p, and the reason that

π[[r]]q2 is that there is a sentence ∀(p0 , ∀(q 0 , r)) ∈ Γ such that u →
                                                                        ∗ p0 and q → ∗ q 0 . So we

have C4a.
    Subcase 2: π is of the form ∃(p0 , ∀(q 0 , r)) and also p0 → ∗ p and q →∗ q 0 . This leads to

C4b.
  Fifth, let ϕ be ∃(p, ∀(q, r)). Assuming that this sentence belongs to Γ, it also belongs
to M . Assuming that M 6|= ϕ, we must have some π ∈ [[q]] such that ϕ[[r]]π.
  Case 1: π is x2 for some x ∈ M ∗ . In this case, Γ contains a sentence ∀(p0 , ∀(q 0 , r))
such that x → ∗ q, q 0 and p →∗ p0 . This leads to C5a.

  Case 2: π is x1 for some x ∈ M ∗ . One possibility is (as in Case 1 just above) Γ
contains a sentence ∀(p0 , ∀(q 0 , r)) such that x →∗ q, q 0 and p → ∗ p0 . This again leads to

C5a. The other possibility is that ∀(p0 , ∃(q, r)), and p →  ∗ p0 . This leads to C5b.

  Case 3: π is a sentence ∃(q , c). In this case, there is a sentence ∀(p0 , ∀(q 00 , r)) such
                                   0
       ∗ p0 , q 0 →
that p →          ∗ q 00 and q 0 →
                                 ∗ q. This also implies C5a.

  Finally, let ϕ be ∃(p, ∃(q, r)). Assume that M 6|= ϕ. Then ϕ ∈ M and also q2 ∈ M . We
have ϕ ∈ [[p]] and q2 ∈ [[q]]. Then ϕ[[r]]q2 . And so there is some sentence ∀(u, ∀(v, r)) ∈ Γ
such that ϕ ∈ [[u]] and q2 ∈ [[v]]. This means that p →  ∗ u and q →∗ v. So C6 holds.

  This completes the proof.                                                                  a

Lemma 5.2.5 holds. The following are equivalent:                                                     Check this!
  (i) Γ is satisfiable.
 (ii) MΓ |= Γ.

Lemma 5.2.5 is just a restatement of Lemma 5.2.4.

Summary: an algorithm for the consequence relation of R Up until now, we have
taken a set Γ and built a model of it, assuming that Γ has a model in the first place.
One point of the work we have done concerns complexity: the procedure to build MΓ
from Γ is efficient; its time complexity is polynomial in the size of Γ. A second point is
that another equally interesting question is reducible to the question of whether a set is
satisfiable or not. We have in mind the consequence question: given (a finite set) Γ and
ϕ, tell whether or not Γ |= ϕ. The reason that this is reducible to the question that we
have already answered is that
                             Γ |= ϕ iff    Γ ∪ {ϕ} has no model.



                                                                                               61
5 R: the relational syllogistic


     (i) Let ∆ = Γ ∪ {ϕ}.

  (ii) Build the model M = M∆ as in this section.

 (iii) Check to see whether M satisfies all the sentences in Γ.
          a) If ‘no’, then Γ is unsatisfiable, and so Γ |= ϕ vacuously.
          b) If ‘yes’, then see if in addition M |= ϕ. If ‘yes’, then we have a model of ∆,
             and so Γ 6|= ϕ. If ‘no’, then Γ |= ϕ.

                      Figure 5.4: An algorithm to see if Γ |= ϕ in R.


(You should be sure you understand this quite well.) Figure 5.4 summarizes this discus-
sion in the form of an algorithm for the consequence question.


5.3 Proof theory
We have already seen an analysis of the relation Γ |= ϕ, and in particular we have seen
several important results concerning this relation. At this time, we wish to turn our
previous results into a sound and complete logical system for R. The leading idea at this
point is to have whatever rules it takes to “convert |= to `”. That is, we aim to have
enough rules to insure facts like the following:
           ∗ q, then Γ ` ∀(p, q).
  (i) If p →

 (ii) If Γ is promptly unsatisfiable, then Γ ` ⊥.

(iii) Γ ` ϕ iff Γ ∪ {ϕ} ` ⊥.

The first requirement is met by incorporating the logic for A into our system. The
second is met by going carefully through the proofs above, and adding whatever rules
it takes. Of course, it is better to adopt a set of rules which “looks nice”, and so this
is what we have tried to do. Finally, the last requirement is met by adopting a rule of
reductio ad absurdum, as we discuss below.
   Our rules appear in Figure 5.5. We remind the reader that p and q range over unary
atoms, c over set terms, and t over binary literals.
   Rules (D1), (D2), (D3), (B), (A), (T) and (I) are natural generalizations of their
namesakes in S. In contrast, (∀∀), (∃∃), (∀∃) and (II) express genuinely relational
logical principles. In some settings, these last rules are called monotonicity principles.
   In addition to syllogistic rules, R contains the rule of (RAA), whereby one derives ϕ
from Γ by temporarily adding the “negation” of ϕ to Γ, thereby obtaining Γ ∪ {ϕ}, and
then deriving a contradiction from this larger set Γ ∪ {ϕ}. The idea is that This rule
(RAA) is not the same as ex falso quodlibet, the rule we have called (X) in Section 4.4.
To see why, we mention the semantic justifications for both rules.



62
                                                                                             5.3 Proof theory


           ∃(p, q)               ∀(q, c)                 ∀(p, q)             ∀(q, c)
                                           (D1)                                        (B)
                      ∃(p, c)                                      ∀(p, c)

           ∀(p, q)               ∃(p, c)                                       ∃(p, c)
                                           (D2)                    (T)                 (I)
                      ∃(q, c)                            ∀(p, p)               ∃(p, p)

           ∀(q, c̄)              ∃(p, c)                 ∀(p, p̄)              ∃(p, ∃(q, t))
                                           (D3)                   (A)                        (II)
                      ∃(p, q̄)                           ∀(p, c)                 ∃(q, q)

           ∀(p, ∀(q 0 , t))      ∃(q, q 0 )              ∃(p, ∃(q, t))        ∀(q, q 0 )
                                            (∀∀)                        0                (∃∃)
                   ∀(p, ∃(q, t))                                ∃(p, ∃(q , t))

                                                           [ϕ]
                                                            ..
                                                             ..
           ∀(p, ∃(q, t))          ∀(q, q 0 )
                                             (∀∃)           ⊥
                  ∀(p, ∃(q 0 , t))                          ϕ       RAA


           Figure 5.5: The logical system R for R. Notice the rule of (RAA).


The bottom symbol ⊥ We also define ⊥ to be any contradiction. In R, this means a
sentence of the form ∃(p, p).
  Here are the ideas behind (RAA) and (X):

  (i) If Γ ∪ {ϕ} |= ⊥, then Γ |= ϕ.

 (ii) If Γ |= ⊥, then Γ |= ϕ

The (RAA) justification changes the assumptions in the derivation from Γ ∪ {ϕ} to Γ.
This is the exact difference between reductio ad absurdum and ex falso quodlibet. 73
 We must incorporate this observation into our proof system, and we do so in (RAA).
We now can display this rule in natural-deduction-style:

                                                  [ϕ]
                                                   ..
                                                    ..
                                                   ⊥
                                                   ϕ     RAA



Definition A proof tree over Γ is a pair (T, Can), where finite tree T whose nodes are
labeled with sentences, and Can is a set of labeled leaves of T called the canceled leaves.
Each node n in the tree must satisfy one of the following conditions:

  (i) n is a leaf labeled by an element of Γ.

 (ii) n comes from its parent(s) by an application of a rule other than (RAA).



                                                                                                          63
5 R: the relational syllogistic

(iii) n ∈ Can, and there is some node m on the path from n to the root such that the
      parent of m is labeled ⊥, and the label of m is the semantic negation of the label
      of n.

   We write Γ ` ϕ if there is a proof tree T with ϕ at the root whose uncanceled leaves
all belong to Γ.




Example 5.2      Here is a derivation showing that

                                     ∀(x, x) ` ∀(y, ∀(x, r))

In words, if there are no xs, then all y’s have any relation whatsoever to all of them.
Note that we cannot simply use the rule

                                          ∀(p, p̄)
                                                   ( A)
                                          ∀(p, c)

Instead, we use RAA:
                                  [∃(y, ∃(x, r))]1
                                      ∃(x, x)       ∀(x, x)
                                             ∃(x, x)
                                                        (RAA)1
                                          ∀(y, ∀(x, r))
This example also shows that we indicate canceled leaves using bracketing, and we also
use numerical superscripts to tell which application of (RAA) has canceled which leaves.




Example 5.3      Here is a derivation showing that

                        ∀(x, ∀(y, r)), ∀(p, y), ∃(p, q) ` ∀(x, ∃(y, r))

                                   ∃(p, q) ∀(p, y)
                                                      (D1)
                    ∀(x, ∀(y, r))        ∃(p, y)
                                                 (∀∀)
                           ∀(x, ∃(p, r))                       ∀(p, y)
                                                                         (∀∃)
                                         ∀(x, ∃(y, r))




64
                                                5.4 Incorporating background facts in R

Example 5.4      Here is a formal proof showing that
                                  ∀(x, x) ` ∀(y, ∀(x, r))
In words, if there are no xs, then all y’s have any relation whatsoever to all of them. As
in Example 5.2, this does not follow from the rule (A). But here is a derivation:
                            [∃(y, ∃(x, r))]1
                                             (II)
                                ∃(x, x)            ∀(x, x)
                                                           (D1)
                                          ∃(x, x)
                                                     (RAA)1
                                       ∀(y, ∀(x, r))



   As we shall see below in Theorem 9.2.1, the rule (RAA) is essential.
   Although (RAA) may be used at any point in a derivation, our proof system in this
section has the extra property that if Γ ` ϕ using (RAA), then there is a proof using
(RAA) at most once. In this book we are not going to be concerned with this stronger         check!
property, and for more on it see [?].                                                        check this
   Now we have stated the rules of our system, and the natural question is to whether
they are complete. We assert without proof that they are. To check this completeness
result, one would have to go back to our work in Section 4.7 and to be sure that all
of the work holds when we change the semantic assertions such as “Γ |= ϕ” and “Γ is
satisfiable” to their syntactic variants “Γ ` ϕ” and “Γ is consistent.” We are not going
to do this in detail, but for the record we state the following result.

Theorem 5.3.1 (Completeness of the proof system for R) Γ ` ϕ iff Γ |= ϕ.


5.4 Incorporating background facts in R
Suppose we have a stock of background facts about verbs, such as
                                 hitting entails touching                            (5.2)
We mean that every act of hitting is also an act of touching. This background fact cannot
be stated in any of the languages which we have so far studied. Nevertheless, it can be
made into a semantic requirement: we would require of a model that the interpretation
of hitting be a sub-relation of the interpretation of touching. And then we might like to
study the entailment relation on this smaller class of models.
   Even though we cannot state (5.2) as an axiom, it does yield a rule of inference. To
state it more abstractly, suppose we have a rule like
                                          r⇒s                                        (5.3)
and we restrict attention to the models where [[r]] ⊆ [[s]]. Then Figure 5.6 lists sound
rules of inference.
  We add these to the system R as listed in Figure 5.5.



                                                                                       65
5 R: the relational syllogistic


               ∀(d, ∀(c, r))      ∀(d, ∃(c, r))    ∃(d, ∀(c, r))    ∃(d, ∃(c, r))
               ∀(d, ∀(c, s))      ∀(d, ∃(c, s))    ∃(d, ∀(c, s))    ∃(d, ∃(c, s))

     Figure 5.6: Rules of inference corresponding to the background assertion r ⇒ s.


Proposition 5.4.1 The system R together with the rules in Figure 5.6 give a sound and
complete logic: Γ ` ϕ iff Γ |= ϕ.

  this needs to be added, either as a result in the text or as an exercise

Sources The first syllogistic logic to employ verbs was Nishihara, Morita, and Iwata [?].
The logical system for R comes from Moss [?] and from Pratt-Hartmann and Moss [?].
The work on incorporating background facts is new here.


5.5 Exercises

Exercise 30. Let Γ be the set of sentences in Figure 5.2 and shown again below:

 All j are k    All j are l    All k are l    All p see some k     ϕ1 : Some n sees some m
 All l are k    All l are m    All k are n    ϕ2 : Some j is a j   ϕ3 : Some n fails to see some m
 All m are q    All p are q    All q are p    All l see some n     All l fail to see some n

For each of the following sentence ϕ, do the following: if Γ ` ϕ, then give a derivation
in our system. if Γ 6` ϕ, then give a model of Γ where ϕ is false.
  (i) Some p sees some q

 (ii) All p see all q

(iii) Some k sees some p

 (iv) All k fail to see some p


Exercise 31. In this section we gave a precise definition of the derivability relation
Γ ` ϕ. Here is another characterization of this relation. Let àlt be the the smallest
relation on P(R) × R such that
  (i) If ϕ ∈ Γ, then Γ àlt ϕ.

 (ii) If Γ àlt ψ1 , . . ., Γ àlt ψn and one of the rules of R other than (RAA) has as a
      substitution instance ψ1 , . . . , ψn \ϕ, then Γ àlt ϕ.

(iii) If Γ ∪ {ϕ} àlt ⊥, then Γ àlt ϕ.
Prove that Γ ` ϕ iff Γ àlt ϕ.



66
6 RCA: verbs, relative clauses, and
  comparative adjectives
We started out with the smallest logical system in the world, the syllogistic system of
All. At this point, we wish to consider one of the largest syllogistic systems of all, the
system RCA. This system has transitive verbs, subject relative clauses, and capable of
representing a fairly large class of natural language inferences.
  Here is an of the kind of inference we want to do in this chapter.


Example 6.1
Every hyena is taller than some jackal
Everything taller than some jackal is not heavier than any warthog
Everything which is taller than some hyena is not heavier than any warthog



6.1 Syntax and semantics
The syntax of the language RCA is shown in Figure 6.1. We start with one collection of
unary atoms (for nouns), another collection of tv atoms (for transitive verbs), and finally
a third collection of adjective atoms (for comparative adjectives). The second column in
the figure indicates the variables that we shall use in order to refer to the objects of the
various syntactic categories. Because the syntax is not standard, it will be worthwhile
to go through it slowly and to provide glosses in English for expressions of various types.
   Our intention is that unary atoms represent plural nouns, adjective atoms represent
comparative adjective phrases such as larger than and smaller than, and tv atoms represent
transitive verbs. We group the adjective atoms and tv atoms into binary atoms, and r
we use letters like r for those. Moving on, we have set terms; these are named because in
the semantics they denote sets. To understand how they work, let us exhibit a rendering
of the simplest set terms into more idiomatic English:
                 ∀(boy, see)       those who see all boys
                 ∃(girl, taller)   those who are taller than some girl(s)
                 ∀(boy, see)       those who fail-to-see all boys
                                   = those who see no boys
                                   = those who don’t see any boys
                 ∃(girl, see)      those who fail-to-see some girl
                                   = those who don’t see some girl



                                                                                         67
6 RCA: verbs, relative clauses, and comparative adjectives


               expression           variables   syntax
               unary atom           p, q
               adjective atom       a
               tv atom              v
               binary atom          r           v | a
               positive set term    c+ , d+     p | ∃(p, r) | ∀(p, r)
               set term             c, d        c+ | p | ∃(p, r) | ∀(p, r)
               sentence             ϕ           ∀(d+ , c) | ∃(d+ , c)

                             Figure 6.1: The syntax of RCA.


The bar notation indicates negation. The semantics will work “classically” in the sense
that the interpretations of cat and cat will be set complements; this is a choice that could
be reconsidered, of course. Returning to set terms and how we read them, the syntax
indicates that the set terms in this language are a recursive construct. That is, we may
embed set terms. So we have set terms like

                                   ∃(∀(cat, sees), taller)

which may be taken to denote the individuals who are taller than someone who sees no
cat.
  We should note that the relative clauses which can be obtained in this way are all
“missing the subject”, never “missing the object”. The language is too poor to express
predicates like λx.all boys see x.
  We also have sentences using the constants, such as ∀(g, s)(m), corresponding to Mary
sees all girls. But we are not able to say all girls see Mary; the syntax again is too
weak. We should note that the relative clauses which can be obtained in this way are all
“missing the subject”, never “missing the object”. The language is too poor to express
predicates like λx.all boys see x.


The bar notation. We intend the bar notation for negation to be involutive: that is,
we shall never iterate the bar notation, and so we simply will not see expressions such
as p. That is, we make the choice that our syntax does not include such a notation.
However, it will be convenient to adopt a syntactic negation and to say that the syntax
should be closed under the bar notation; this means that we would be identifying p with
p, and making similar identifications.
   A positive set term is either a unary atom, or else a quantified set term with a non-
negated verb or adjective. More generally, a set term also allows negation, indicated by
the overline on the atom.
   The sentences in the language are of the form ∀(b, c) and ∃(b, c); they can be read as
statements of the inclusion of one set term extension in another, and of the non-empty
intersection. The first must be a positive set term.



68
                                                                                    6.1 Syntax and semantics

The bar notation in general. We have already seen that our unary and binary atoms
come with negative forms. We extend this notation to set terms and sentences in the
following ways: p = p, s = s, ∃(l, r) = ∀(l, r), ∀(l, r) = ∃(l, r), ∀(c, d) = ∃(c, d), and
∃(c, d) = ∀(c, d).
   We call ϕ and ϕ̄ semantic negations for the following reason: for all models M, M |= ϕ
iff M 6|= ϕ̄.

Semantics. A model (for this language L) is a pair M = (M, [[ ]]), where M is a non-
empty set, [[p]] ⊆ M for all p ∈ P, [[r]] ⊆ M 2 for all binary atoms r ∈ R. The only
requirement is that for all adjectives a, [[a]] should be a transitive relation: if a(x, y) and
a(y, z), then a(x, z).
  Given a model M, we extend the interpretation function [[ ]] to the rest of the language
by setting

              [[p]]         =        M \ [[p]]
              [[r]]         =        M 2 \ [[r]]
              [[∃(l, t)]]   =        {x ∈ M : for some y such that [[l]](y), [[t]](x, y)}
              [[∀(l, t)]]   =        {x ∈ M : for all y such that [[l]](y), [[t]](x, y)}

We define the truth relation |= between models and sentences by:

                                 M |= ∀(c, d)         iff      [[c]] ⊆ [[d]]
                                                                                                       (6.1)
                                 M |= ∃(c, d)         iff      [[c]] ∩ [[d]] 6= ∅

If Γ is a set of formulas, we write M |= Γ if for all ϕ ∈ Γ, M |= ϕ.



Example 6.2 Consider the model M with M = {w, x, y, z}, [[cat]] = {w, x, y}, [[dog]] =
{z}, with [[see]] shown below on the left, and [[bigger]] on the right:

                            wO o           x
                                                        x, z         /y         /w
                                 ~        / z y
                                yo

Then [[∃(dog, see)]] is the set of entities that see some dog, namely {x, y, z, w}. Similarly,
[[∃(dog, bigger)]] = {w, y}. It follows that

                                       [[∀(∃(dog, bigger), see)]] = {x}.

Since [[cat]] contains x, we have

                                     M |= ∀(∀(∃(dog, bigger), see), cat).

That is, in our model it is true that everything which sees everything bigger than some
dog is a cat.



                                                                                                         69
6 RCA: verbs, relative clauses, and comparative adjectives




                                ∃(c, d)     ∀(c, b)     ∀(b, c)         ∀(c, d)
                        (T)             (I)         (C)                         (B)
             ∀(c, c)            ∃(c, c)     ∀(b, c)             ∀(b, d)

            ∃(b, c)             ∀(c, d)                       ∀(b, c)             ∃(b, d)
                                          (D1)                                              (D2)
                      ∃(b, d)                                           ∃(c, d)


                       ∀(p, q)                                ∀(p, q)
                                      (J)                                    (K)
                  ∀(∀(q, r), ∀(p, r))                    ∀(∃(p, r), ∃(q, r))

                       ∃(p, q)                                ∃(q, ∃(p, r))
                                      (L)                                   (II)
                  ∀(∀(p, r), ∃(q, r))                           ∃(p, p)

                          ∀(p, p̄)                            ∀(p, p̄)
                                      (Z)                                    (W)
                        ∀(c, ∀(p, r))                    ∃(∀(p, r), ∀(p, r))


                   ∀(p, ∃(q, a))                           ∀(p, ∀(q, a))
                                     (tr1)                                   (tr2)
                 ∀(∃(p, a), ∃(q, a))                     ∀(∃(p, a), ∀(q, a))

                   ∃(p, ∀(q, a))                           ∃(p, ∃(q, a))
                                     (tr3)                                   (tr4)
                 ∀(∀(p, a), ∀(q, a))                     ∀(∀(p, a), ∃(q, a))


                                                 [ϕ]
                                                  ..
                                                   ..
                                                  ⊥
                                                  ϕ     RAA

Figure 6.2: The proof system for RCA. In it, p and q range over unary atoms, b and
            c over set terms, d over positive set terms, r over binary atoms, and a over
            adjective atoms.




70
                                                                             6.2 Proof system




Example 6.3      The following putative inference is invalid:

                               Every giraffe sees every gnu
                               Some gnu sees every lion
                               Some lion sees some zebra
                               Every giraffe sees some zebra

To see this, consider the model shown below

                  giraffe          / gnu           / lion          / zebra

The interpretations of the unary atoms are obvious, and the interpretation of the verb
is the relation indicated by the arrow.



6.2 Proof system
At this point, we have a syntax and a semantics. Then we have a notion of semantic
consequence Γ |= ϕ, where Γ is a set of sentences in the current fragment, and ϕ is also a
sentence in it. As always, this means that every model of all sentences in Γ is also a model
of ϕ. We give the rules of a natural deduction proof system for validity in this fragment
in Figure 6.2. The system generates trees, just as in the proof system of Section 2 but
with many more rules. The majority of the rules of the system (those above the last
four) are the system for the logic R∗ in [?]. The first two lines are syllogistic rules.
We can read an instance of (C): if no senators are millionaires, then no millionaires are
senators. We need both (D) rules because of the restriction that d must be a positive
set term. Here are some readings the other rules:

 (J) If all watches are gold items, then everyone who owns all gold items owns all
     watches.

 (K) If all watches are gold items, then everyone who owns some watch owns some gold
     item.

 (L) If some watches are gold items, then everyone who owns all watches owns some
     gold item.

 (II) If someone owns a watch, then there is a watch.

(tr1) If all watches are bigger than some pencil, then everthing bigger than some watch
      is bigger than some pencil.

(tr2) If all watches are bigger than all pencils, then everthing bigger than some watch
      is bigger than all pencils.



                                                                                          71
         6 RCA: verbs, relative clauses, and comparative adjectives

         (tr3) If some watch is bigger than all pencils, then everthing bigger than all watches is
               bigger than all pencils.

         (tr4) If some watch is bigger than some pencil, then everthing bigger than all watches
               is bigger than some pencil.

         Notice that the validity of the four rules is due to the transitivity of comparative ad-
         jectives. These rules come from [?]. The overall import of this logical system is that it
         is complete: every valid inference in the language of this fragment may be syntactically
         derived in the proof system.



check!   Example 6.4         Here is a derivation for (1.3) from early on in this book:

                                             ∀(skunk, mammal)
                                                                            (J)
                                 ∀(∀(mammal, respect), ∀(skunk, respect))
                                                                                     (J)
                          ∀(∀(∀(skunk, respect), fear), ∀(∀(mammal, respect), fear))

         Note that inference using (J) is antitone each time: skunk and mammal have switched
         positions.




         Example 6.5          Here is an example of a derivation which formalizes the reasoning in
         Example 6.1:

                  ∀(hyena, ∃(jackal, taller))
                                                     (tr1)
              ∀(∃(hyena, taller), ∃(jackal, taller))       ∀(∃(jackal, taller), ∀(warthog, heavier))
                                                                                                       (B)
                                   ∀(∃(hyena, taller), ∀(warthog, heavier)))

         The application of (tr1) corresponds to using the premise every hyena is taller than some
         jackal to derive the sentence everything which is taller than some hyena is taller than some
         jackal. The second step corresponds to the transitivity of predication (is taller than).



         Reductio ad absurdum In addition to syllogistic rules, the logic contains the rule of
         reductio ad absurdum (RAA), whereby one derives ϕ from Γ by temporarily adding the
         “negation” of ϕ to Γ, thereby obtaining Γ ∪ {ϕ}, and then deriving a contradiction from
         this larger set Γ ∪ {ϕ}.
           This rule (RAA) is not the same as ex falso quodlibet, the rule we have called (X) in
         Section 4.2 (see page 41). To see why, we mention the semantic justifications for both
         rules.



         72
                                                                         6.2 Proof system

The bottom symbol ⊥ We define ⊥ to be any contradiction. In R, this means a
sentence of the form ∃(p, p).
  Here are the ideas behind (RAA) and (X):

  (i) If Γ ∪ {ϕ} |= ⊥, then Γ |= ϕ.

 (ii) If Γ |= ⊥, then Γ |= ϕ

The (RAA) justification changes the assumptions in the derivation from Γ ∪ {ϕ} to Γ.
This is the exact difference between reductio ad absurdum and ex falso quodlibet.
 We must incorporate this observation into our proof system, and we do so in (RAA).
We now can display this rule in natural-deduction-style:

                                          [ϕ]
                                           ..
                                            ..
                                           ⊥
                                           ϕ     RAA



Definition A proof tree over Γ is a pair (T, Can), where T is a finite tree whose nodes
are labeled with sentences, and Can is a set of labeled leaves of T called the canceled
leaves. Each node n in the tree must satisfy one of the following conditions:

  (i) n is a leaf labeled by an element of Γ.

 (ii) n comes from its parent(s) by an application of a rule other than (RAA).

(iii) n ∈ Can, and there is some node m on the path from n to the root such that the
      parent of m is labeled ⊥, and the label of m is the semantic negation of the label
      of n.

   We write Γ ` ϕ if there is a proof tree T with ϕ at the root whose uncanceled leaves
all belong to Γ.




Example 6.6      Here is a proof of the (Zero) rule of S† : ∀(p, p) ` ∀(p, q):

                               [∃(p, q)]1
                                          (I)
                                ∃(p, p)            ∀(p, p)
                                                           (D1)
                                          ∃(p, p)        1
                                                  (RAA)
                                          ∀(p, q)




                                                                                      73
             6 RCA: verbs, relative clauses, and comparative adjectives

             Example 6.7 Similarly, here is a formal proof showing (A) from the system for R in
             Figure 5.5 on page 63:
                                           ∀(p, p) ` ∀(y, ∀(p, d))
             Here is a derivation:
                                                   [∃(p, d)]1
                                                              (II)
                                                    ∃(p, p)          ∀(p, p)
                                                                              (D1)
                                                             ∃(p, p)         1
                                                                     (RAA)
                                                             ∀(p, d)
             This example also shows that we indicate canceled leaves using bracketing, and we also
             use numerical superscripts to tell which application of (RAA) has canceled which leaves.


               As we shall see below, the special status of (RAA) is essential: indirect syllogistic
             systems are in general more powerful than direct syllogistic systems.
               Although (RAA) may be used at any point in a derivation, our proof system in this
             section has the extra property that if Γ ` ϕ using (RAA), then there is a proof using
Check this   (RAA) at most once. In this book we are not going to be concerned with this stronger
             property, and for more on it see [?].


             6.3 Completeness of the logic
             At this point, we mention a few features of the logical system which play a role in our
             completeness proof. The first is proof by cases.
             Lemma 6.3.1 (Cases) Suppose that Γ ∪ {ϕ} ` ψ and also Γ ∪ {ϕ} ` ψ. Then Γ ` ψ.
             Proof The hypotheses imply that Γ ∪ {ϕ, ψ} ` ⊥. Also Γ ∪ {ϕ, ψ} ` ⊥, and by (RAA)
             we also have Γ ∪ {ψ} ` ϕ. Let T1 be a proof tree showing that Γ ∪ {ϕ, ψ} ` ⊥, let T2
             be a proof tree showing that Γ ∪ {ψ} ` ϕ. Take T1 and replace every leaf labeled ϕ
             with a copy of T2 . This gives a proof tree with root ⊥ and whose leaves are labeled in
             Γ ∪ {ψ} ` ⊥. Using (RAA) again, we see that Γ ` ψ.                                    a

             Definition A set Γ is complete if for all ϕ, either ϕ ∈ Γ or ϕ ∈ Γ.1

             Lemma 6.3.2 Every consistent set Γ has a complete and consistent superset Γ∗ .
             Proof We are going to use Zorn’s Lemma2 . Let C be the set of consistent ∆ ⊇ Γ,
             ordered by inclusion. A chain in C is a set X of elements of C with the property that if
              1
                Please do not confuse the completeness of a set of sentences with the completeness of the logical system
                 under discussion.
              2
                If you are not comfortable with Zorn’s Lemma, it is also possible to prove the result in the case
                 that the overall language is countable by a step-by-step procedure. Here is a sketch. One lists the
                 sentences in the language in a list as ϕ0 , ϕ1 , . . ., ϕn , . . .. One also constructs an infinite sequence
                 Γ = Γ0 ⊆ · · · Γn ⊆ · · · of sets of sentences. Γn+1 is either Γn ∪ {ϕn } or else Γn ∪ {ϕn },S  whichever is
                 consistent. One must be consistent, lest Γn be inconsistent by Lemma 6.3.1. And then n Γn would
                 be as desired.




             74
                                                                  6.3 Completeness of the logic

X contains both ∆1 and ∆2 , then either ∆1 ⊆ ∆2 or ∆2 ⊆ ∆1 . To use Zorn’s Lemma,
we must check S that every chain X in C has an upper bound. This is immediate: we
take the union X. The important point is that this is a consistent set, and this point
follows from the fact that proofs are finite.
   Zorn’s Lemma applies and gives us a maximal element Γ∗ of C. Γ∗ is thus a consistent
superset of Γ. We need only check that it is complete. For if not, suppose that neither
ϕ nor ϕ belong to Γ∗ . By maximality, both Γ∗ ∪ {ϕ} ` ⊥ and Γ∗ ∪ {ϕ} ` ⊥. By
Lemma 6.3.1, Γ∗ ` ⊥. This contradicts the consistency of Γ∗ , and so we conclude that
Γ∗ is indeed complete.                                                                a
   A logic has a semantic negation, let ϕ be such that every model satisfies exactly one
of them.
Lemma 6.3.3 (A useful sufficient condition for completeness) Let L be a logic
with a semantic negation, and let ` be a proof system with RAA. The proof system is
complete iff every consistent set is satisfiable.
Proof Assume that the logic is complete. Let Γ be unsatisfiable, so Γ |= ⊥. By
completeness, Γ ` ⊥. Thus, Γ is inconsistent.
   Assume that every consistent set in the logic is satisfiable Suppose that Γ |= ϕ. Let ϕ
be a semantic negation of ϕ. Then Γ ∪ {ϕ} has no models. By our assumption, Γ ∪ {ϕ}
is inconsistent. Using RAA, we see that Γ ` ϕ. Thus the logic is complete.               a

Remark Lemmas 6.3.1, 6.3.2, and 6.3.3 have nothing to do with the particular proof
system, and indeed they hold for all logical systems which have (RAA). So versions of
these results hold for all of the logical systems in the rest of the book.                             check this
  The logic is easily seen to be sound: if Γ ` ϕ, then Γ |= ϕ. In the next section, we’ll
see a proof of the completeness of this system.
Theorem 6.3.4 The logic in Figure 6.2 is sound and complete for RCA.
Proof We omit the soundness verification. To prove completeness, we use Lemma 6.3.3.
We need only show that every theory Γ ⊆ RCA which is consistent in the logic is
satisfiable. Also, by Lemma 6.3.2, we may assume that Γ is maximal consistent.
  We shall construct a structure M and prove that it satisfies Γ. First, let C+ be the
set of positive set terms. Then we define M by:
     M                                   = {hc1 , c2 , Qi ∈ C+ × C+ × {∀, ∃} : Γ ` ∃(c1 , c2 )}
     [[p]]                               = {hc1 , c2 , Qi ∈ M : Γ ` ∀(c1 , p) or Γ ` ∀(c2 , p)}
     hc1 , c2 , Q1 i[[r]]hd1 , d2 , Q2 i iff either (a) for some i, j, and q ∈ P,
                                             Γ ` ∀(ci , ∀(q, r)) and Γ ` ∀(dj , q);
                                             or else (b) Q2 = ∃, and for some i and q ∈ P,
                                             d1 = d2 = q, and Γ ` ∀(ci , ∃(q, r)).

Note that the set M is non-empty. For let p ∈ P. If Γ ` ∃(p, p), then hp, p, ∀i ∈ M .
Otherwise, Γ ` ∀(p, p), and so for all binary atoms r, Γ ` ∃(∀(p, r), ∀(p, r)) by (W). Thus
hc, c, ∀i ∈ M , where c is ∀(p, r).



                                                                                                  75
6 RCA: verbs, relative clauses, and comparative adjectives

Lemma 6.3.5 For all c ∈ C+ ,

                 [[c]] = {hd1 , d2 , Qi ∈ M : either Γ ` ∀(d1 , c), or Γ ` ∀(d2 , c)}.



Proof The result for c a unary atom is immediate. We often shall use the resulting
fact that if Γ ` ∃(p, p), then [[p]] 6= ∅; it contains both hp, p, ∀i and hp, p, ∃i. The main
work concerns set terms of the form ∀(p, r) and ∃(p, r). We remark that all set terms
referred to in this proof are positive.
   We begin with c = ∀(p, r). Let hd1 , d2 , Qi ∈ [[∀(p, r)]]. Now, either Γ ` ∃(p, p) or
Γ 6` ∃(p, p). If the former, then hp, p, ∀i ∈ [[p]]. By the semantics of our fragment,
hd1 , d2 , Qi[[r]]hp, p, ∀i. By the structure of M, there are i and q giving the derivation
from Γ as in the tree on the left below:
                                                ..
                                                 ..
                         ..                                            ..
                          ..                 ∀(p, q)                    ..
                                                           (J)
                 ∀(di , ∀(q, r))       ∀(∀(q, r), ∀(p, r))         ∀(p, p̄)
                                                           (B)                 (Z).
                               ∀(di , ∀(p, r))                 ∀(dj , ∀(p, r))

This shows that Γ ` ∀(di , ∀(p, r)). On the other hand, if Γ 6` ∃(p, p), we use the
assumption that Γ is complete to assert that Γ ` ∀(p, p). And then we have the derivation
from Γ on the right above, for both j.
    Conversely, fix i and suppose that Γ ` ∀(di , ∀(p, r)). We claim that hd1 , d2 , Qi belongs
to [[∀(p, r)]]. For this, take any hb1 , b2 , Q0 i ∈ [[p]] so that Γ ` ∀(bj , p) for some j. (We are
thus using b1 and b2 to range over positive set terms, just as the c’s and d’s do.) Then
p, i and j show that hd1 , d2 , Qi[[r]]hb1 , b2 , Q0 i. This for all elements of [[p]] shows that
hd1 , d2 , Qi ∈ [[∀(p, r)]].
    We next prove the statement of our lemma for c = ∃(p, r).
    Let hd1 , d2 , Qi ∈ [[∃(p, r)]]. Thus we have hd1 , d2 , Qi[[r]]hb1 , b2 , Q0 i for some hb1 , b2 , Q0 i ∈
[[p]]. We first consider case (a) in the definition of our structure M: there are i, j, and
q so that Γ ` ∀(di , ∀(q, r)) and Γ ` ∀(bj , q). We have Γ ` ∃(b1 , b2 ), since hb1 , b2 , Q0 i ∈
M . Further, let k be such that Γ ` ∀(bk , p). We show the desired conclusion using a
derivation from Γ:
                                          ..
                                           ..
                                                           ..
                                      ∃(b1 , b2 )           ..
                                                                                  ..
                                      ∃(bk , bj )      ∀(bj , q)                   ..
                                                                 (D1)
                                               ∃(bk , q)                     ∀(bk , p)
                          ..                                                            (D1)
                           ..                                  ∃(q, p)
                                                                               (L)
                  ∀(di , ∀(q, r))                        ∀(∀(q, r), ∃(p, r))
                                                                               (B)
                                       ∀(di , ∃(p, r))

  This concludes the work in case (a). In case (b), Q0 = ∃, there is some q ∈ P such
that b1 = b2 = q, and for some i, Γ ` ∀(di , ∃(q, r)). Again we have Γ ` ∀(q, p). So we



76
                                                                            6.3 Completeness of the logic

have a derivation from Γ as follows:
                                                          ..
                                                           ..
                                    ..
                                     ..                ∀(q,   p)
                                                                     ( K)
                            ∀(di , ∃(q, r))      ∀(∃(q, r), ∃(p, r))
                                                                     (B)
                                         ∀(di , ∃(p, r))

 At this point, we know that if hd1 , d2 , Qi ∈ [[∃(p, r)]], then Γ ` ∀(di , ∃(p, r)) for some i.
We now verify the converse. Let hd1 , d2 , Qi ∈ M , and fix i such that Γ ` ∀(di , ∃(p, r)).
Then Γ ` ∃(d1 , d2 ). We thus have a derivation from Γ:
                                  ..
                                   ..
                                                            ..
                              ∃(d1 , d2 )                    ..
                                           (I)
                              ∃(di , di )           ∀(di , ∃(p, r))
                                                                    (D1)
                                          ∃(di , ∃(p, r))
                                                          (II)
                                              ∃(p, p)

This goes to show that hp, p, ∃i ∈ M . By the construction of M, hd1 , d2 , Qi[[r]]hp, p, ∃i,
and hp, p, ∃i ∈ pM . So hd1 , d2 , Qi ∈ [[∃(p, r)]]. This completes the proof.             a

Lemma 6.3.6 The interpretation of each adjective atom a is transitive.

Proof     Assume that

                          hb1 , b2 , Q1 i [[a]] hc1 , c2 , Q2 i [[a]] hd1 , d2 , Q3 i.

We shall use several times the fact that since hc1 , c2 , Q2 i belongs to the model, Γ `
∃(c1 , c2 ). We have four cases.
  Case 1: for some i, j, k, l, and q1 , q2 ∈ P, Γ ` ∀(bi , ∀(q1 , a)), Γ ` ∀(cj , q1 ), Γ `
∀(ck , ∀(q2 , a)), and Γ ` ∀(dl , ∀(q2 , a)). We have Γ ` ∃(cj , ck ) also. Now we have
derivation from Γ:
                                                                      ..              ..
                                                                       ..              ..
                                                 ..
                                                  ..            ∀(cj , q1 ) ∃(cj , ck )
                                        ∀(ck , ∀(q2 , a))                 ∃(q1 , ck )
                             ..
                              ..                     ∃(q 1 , ∀(q 2 , a))
                                                                              (tr3)
                     ∀(bi , ∀(q1 , a))         ∀(∀(q1 , a), ∀(q2 , a))
                                                                              (B)
                                      ∀(bi , ∀(q2 , a))
And now we see that hb1 , b2 , Q1 i[[a]]hd1 , d2 , Q3 i, using alternative (a) in the definition of
[[r]].
    Case 2: for some i, j, and q1 ∈ P, Γ ` ∀(bi , ∀(q1 , a)) and Γ ` ∀(cj , q1 ); Q3 = ∃, and
for some k and q2 ∈ P, d1 = d2 = q2 , and Γ ` ∀(ck , ∃(q2 , a)). This time, we have
Γ ` ∃(q1 , ck ), and by a derivation similar to what we saw in Case 1, Γ ` ∀(bi , ∃(q2 , a)).
In this case, alternative (b) shows that hb1 , b2 , Q1 i[[a]]hd1 , d2 , Q3 i.



                                                                                                      77
6 RCA: verbs, relative clauses, and comparative adjectives

   Case 3: Q2 = ∃, and for some i and q1 ∈ P, c1 = c2 = q1 , and Γ ` ∀(bi , ∃(q1 , a)); and
also for some j, k, and q2 ∈ P, Γ ` ∀(cj , ∀(q2 , a)) and Γ ` ∀(dk , q2 ). Thus cj at the end
is the same as q1 . The proof system now shows that Γ ` ∀(bi , ∀(q2 , a)). We again finish
the case with an application of (a).
   Case 4: Q2 = ∃, and for some i and q1 ∈ P, c1 = c2 = q1 , and Γ ` ∀(bi , ∃(q1 , a)); and
also Q3 = ∃, and for some j and q2 ∈ P, d1 = d2 = q2 , and Γ ` ∀(cl , ∃(q2 , a)). This
time we see that Γ ` ∀(bi , ∃(q2 , a)), and we use (b) to see that hb1 , b2 , Q1 i[[a]]hd1 , d2 , Q3 i.
   This completes the proof.                                                                         a


Lemma 6.3.7 M |= Γ.

Proof The proof is by cases on the various sentence types in the current logic. Using
the fact that formulas ∃(e, f ) and ∃(f, e) are interderivable in the logic, and similarly
for ∀(ē, f¯) and ∀(f, e), we may take all sentences to have one of the forms:

                      ∀(c+ , d+ ),   ∀(c+ , d+ ),    ∃(c+ , d+ ),    ∃(c+ , d+ ),

where c+ and d+ range over positive set terms. In the remainder of the proof, we omit
the + -superscripts for clarity: i.e. c and d range over positive set terms.
    Let ϕ ∈ Γ be ∀(c, d). Using (B) and Lemma 6.3.5, we see that [[c]] ⊆ [[d]].
                        ¯ Suppose towards a contradiction that M 6|= ϕ. Let hb1 , b2 , Qi ∈
    Let ϕ ∈ Γ be ∀(c, d).
[[c]] ∩ [[d]]. Let i and j be such that Γ ` ∀(bi , c) and Γ ` ∀(bj , d). Then using (B),
Γ ` ∀(bi , d). ¯ And since Γ ` ∃(bi , bj ), we use (D1) to see that Γ ` ∃(d, d).     ¯ So Γ is
inconsistent, a contradiction.
    If ϕ ∈ Γ is ∃(c, d), then (c, d, ∃) ∈ M . Indeed, (c, d, ∃) ∈ [[c]] ∩ [[d]], by Rule (T) and
Lemma 6.3.5.
    Finally, consider the case when ϕ ∈ Γ is of the form ∃(c, d). Then, using (I), Γ ` ∃(c, c),
so hc, c, ∀i ∈ M . Suppose towards a contradiction that M |= ∀(c, d). Then hc, c, ∀i ∈ [[d]].
But then we have Γ ` ∀(c, d), by Lemma 6.3.5 again. One application of (D2) now shows
that Γ ` ∃(d, d). Thus we have a contradiction to the consistency of Γ.                        a
  This completes the proof of Theorem 6.3.4.                                                         a


A last point: extensions of the system It is possible to go somewhat further in
this direction. We could add proof rules for the irreflexivity of comparative adjective
phrases, and for matter we can also force the domains to be finite (or to be infinite).
We can also add rules for the converse relations, thus relating bigger than and smaller
than. (Technically, this last addition is harder to handle: it leads to a rather large set of
axioms.) We still would have complete and decidable logical systems. We can also add
a few more features to syllogistic logics like this.

Sources Most of the material in this chapter is from Moss [?], Pratt-Hartmann and
Moss [?].



78
                                                                                           6.4 Exercises

   To the best of my knowledge, the first presentation of a complete proof-system for a
fragment close to the relational syllogistic seems to be Nishihara, Morita, and Iwata [?].
This logic is in effect a relational version of Lukasiewicz’, in that formulas roughly similar
to those of R are treated as atoms of a propositional calculus. The authors provide
axiom-schemata which, together with the usual axioms of propositional logic, yield a
complete proof-system for the language in question. Actually, the propositional atoms
in this language are allowed to feature n-ary predicates for all n ≥ 1. However, the rather
strange restrictions on quantifier-scope (existentials must always outscope universals),
mean that this language is primarily of interest for atoms featuring only unary and binary
predicates; these atoms (and their negations) then essentially correspond the formulas
of our fragment R.


6.4 Exercises

Exercise 32. Formalize Example 5.1 in RCA and then construct a derivation for your
formalization using the rules of this section.

Exercise 33. Consider the following inference:
                             Every giraffe is taller than every gnu
                             Some gnu is taller than every lion
                             Some lion is taller than some zebra
                             Every giraffe is taller than some zebra
The inference is valid. Construct a derivation in the system.

Exercise 34. Let Γ consist of the formalizations of the following three sentences:
                 Some giraffe is a female animal
                 Every giraffe is taller than every female animal
                 Every female animal is not taller than some female animal
In the last sentence, we use the wide-scope reading; so for every female animal x is not
taller there is some female animal y (depending on x) so that x is not taller than y.
  (i) Show that Γ is unsatisfiable.
 (ii) Show that Γ is inconsistent in the logic.

Exercise 35. Show the following principles are all derivable in our logic for RCA:
           ∀(p, ∀(q 0 , t))      ∃(q, q 0 )         ∃(p, ∃(q, t))          ∀(q, q 0 )
                                            (∀∀)                                      (∃∃)
                   ∀(p, ∃(q, t))                           ∃(p, ∃(q 0 , t))

           ∀(p, ∃(q, t))          ∀(q, q 0 )        ∀(q, c̄)              ∃(p, c)
                                             (∀∃)                                   (D3)
                  ∀(p, ∃(q 0 , t))                             ∃(p, q̄)




                                                                                                     79
6 RCA: verbs, relative clauses, and comparative adjectives




                   [[men]] = {a, d, f }                               c                b
                   [[women]] = {b, c, e}
                   [[walks]] = {a, b, c}
                                                             d                                  a



                                                                      e                f

Figure 6.3: The model M from Exercise 37 with the interpretation [[see]] drawn as a graph
            rather than listed as a set of ordered pairs. We also take [[taller]] to be the
            strict alphabetic order relation on M .


Exercise 36. The language R is smaller than RCA because it doesn’t have nested set
terms. It consists of the sentences shown in Figure ??. Prove that we get a sound and
complete logic for R using some of the rules in Figure 6.2: (T), (B), (D1), (D2), (I);
together with (A) from Example 6.7; together with the rules D3), (∀∀)), (∃∃), and (∀∀)
from Exercise 35 above.

Exercise 37.          In Figure 6.3, you’ll see a model for this fragment. Technically, M =
{a, . . . , f },

[[see]]   =      {(a, b), (a, c), (a, e), (c, d), (b, a), (b, b), (b, f ), (c, f ), (d, b), (d, d), (d, e), (d, f )},

and [[bigger]] = {(b, a), (c, a), . . . , (f, e)}.
  Find the following sets:
  (i) [[man]]

  (ii) [[see]]

 (iii) [[∃(walks, see)]]

 (iv) [[∀(walks, see)]]

  (v) [[∃(∀(walks, see), bigger)]]


Exercise 38. This is a continuation of Exercise 37. Translate the following sentences
from English into our formalism and see if they are true or false in the model M in
Figure 6.3:
  (i) Every man walks.



80
                                                                              6.4 Exercises

 (ii) Some men walk.
(iii) Some men see every woman.
(iv) Every man sees some woman who is taller than some man.
 (v) Everyone who sees every man doesn’t see someone who is taller than some woman.
(vi) Everyone who sees every man doesn’t see anyone who is taller than some woman.

Exercise 39.       A relation R on a set X is reflexive if for all x ∈ M , x is related to
itself by R. R is irreflexive if for all x ∈ M , x is not related to itself by R.
  (i) Let M be a model in which the interpretation [[a]] of every adjective atom is ir-
      reflexive Show that for all set terms c and all adjectives a, M |= ∀(c, ∃(c, a)).
 (ii) Let Γ be a maximal consistent theory in the logic for RCA, and let M = M(Γ) be
      the model constructed in Section 6.3. Which points in M are related to themselves
      by the interpretations of adjectives?
(iii) Continuing with the last part, suppose that we add all sentences of the form
                                                       (irr)
                                       ∀(c, ∃(c, a))                                   (6.2)
     as axioms to the logic. Suppose again that Γ is maximal consistent in the new
     logic, and that we construct M(Γ) as before. Which points in M are related to
     themselves by the interpretations of adjectives? (Exercise 34 is relevant here.)
(iv) Modify M to get an irreflexive model N of Γ. This proves that the logic obtained
     by adding the new axioms ∀(c, ∃(c, a)) is a sound and complete logic when we
     restrict the interpretations of the adjectives to be irreflexive relations.
     [Hint: The idea is to take each reflexive point p in M that you found in part 3
     and to replace p with infinitely many copies p1 , p2 , . . .. We want to have pi [[a]]pj
     iff i < j. And we want to have the rest of the structure of N be as close to M
     as possible. This exercise requires a fair amount of checking; most of the work is
     similar to what we saw in the proof of Theorem 6.3.4.]

Exercise 40. We continue to study models M with the property that the interpretation
of the comparative adjectives are required to be irreflexive (and of course transitive).
We also want to restrict attention to models M whose domain M is finite.
  (i) Show that the following rule of inference is sound for this class:
                                         ∃(c, c, )
                                                     (fin)
                                       ∃(c, ∀(c, a))

 (ii) Show that the logic of RCA together with the rules (Irr) from (6.2) and (fin) are
      complete for the class of finite models which interpret the adjectives by irreflexive
      (and transitive) relations.




                                                                                          81
7 S†(card): Reasoning about the Sizes of
  Sets
Up until now, all of our logical systems were fragments of first-order logic. And for the
most part, many people have assumed that if a fragment of natural language was to be
formalized at all, it would wind up being a fragment of first-order logic. This chapter
shows that this is not true: we’ll study a logical system which is provably not first-order.


7.1 S† (card): syllogistic logic with negation and cardinality
    comparison
The logic S† (card) merges two logical systems which we have aready seen. The language
of this fragment has nouns p, q, . . ., as we have seen previously. It also has negated
nouns p0 , q, . . .. In addition to the sentences ∀(p, q) and ∃(p, q), it has sentences ∃≥ (p, q)
and ∃> (p, q). The semantics begins with a universe M and interpretations [[p]] for all
nouns p. We assume that in the syntax, p00 = p for all p. Thus, the semantics of each
complemented noun p0 is M \ [[p]]. The sentences ∃≥ (p, q) and ∃> (p, q) have the following
semantics:
                                M |= ∃≥ (p, q)    iff |[[p]]| ≥ |[[q]]|
                                M |= ∃ (p, q)
                                       >          iff |[[p]]| > |[[q]]|
We read “∃≥ (p, q)” as “there are at least as many p as q”, and we read “∃> (p, q)” as
“there are more p than q.” So ∃≥ (p, p0 ) might be read as “the p’s are at least half of
the objects in the universe.” Similarly, ∃≥ (p, p0 ) might be read as “the p’s are at most
half of the objects in the universe.” We can also read ∃> (p, p0 ) might be read as “the
p’s are more than half of the objects in the universe,” and ∃> (p0 , p) as “the p’s are less
than half of the objects in the universe,”
   We are interested in working with this semantics only on finite universes. This is
because the logic is stronger this way. That is, some of the rules which we shall see
shortly are not sound for infinite universes.
   The rules of the system are listed in Figure 7.1. One rule which uses the finiteness
assertion is (Card Mix). It says that if all y are x, and there are at least as many
elements in the bigger set y as in x, then the sets have to be the same.
   We turn to the rules at the bottom of Figure 7.1, since they show the interaction of
the different sentence types and also involve the “half” interpretation from above.
   The logic has two Ex falso quodlibet rules, listed at the bottom of Figure 7.1. However,
the second is derivable from the first.




                                                                                              83
7 S† (card): Reasoning about the Sizes of Sets




                                        ∀(n, p) ∀(p, q)                                    ∃(p, q)
                   (axiom)                              (Barbara)                                  (some)
         ∀(p, p)                            ∀(n, q)                                        ∃(p, p)

       ∃(q, p)                                  ∀(p, q)                                    ∀(p, p0 )
               (conversion)                                  (anti)                                  (zero)
       ∃(p, q)                                  ∀(q 0 , p0 )                               ∀(p, q)

     ∃(p, n) ∀(n, q)                               ∀(p0 , p)                            ∀(p, q)
                     (Darii)                                 (one)                                 (subset-size)
          ∃(p, q)                                  ∀(q, p)                             ∃≥ (q, p)

      ∃≥ (p, q)                              ∃≥ (p, q)                             ∀(p, q) ∃≥ (p, q)
                     (card-mon)                            (card-anti)                               (card-mix)
      ∃≥ (q 0 , p0 )                        ∃≥ (q 0 , p0 )                               ∀(q, p)

 ∃(p, p) ∃≥ (p, q)                        ∀(q, p) ∃(p, q 0 )                           ∃> (p, q)
                   (card-∃)                                  (more)                               (more-some)
       ∃(q, q)                                ∃> (p, q)                                ∃(p, q 0 )

     ∃> (p, q)                        ∃> (n, p) ∃≥ (p, q)                              ∃> (q, p)
                 (more-at least)                          (more-left)                                 (more-anti)
     ∃≥ (p, q)                             ∃> (n, q)                                   ∃> (p0 , q 0 )


 ∃(p, p) ∃≥ (q, q 0 )                ∃≥ (p, p0 )     ∃≥ (q 0 , q)                ∃> (p, p0 ) ∃≥ (q 0 , q)
                      (int)                                         (half)                                (strict half)
       ∃(q, q)                               ∃≥ (p, q)                                  ∃> (p, q)


                                   ∃≥ (p, p0 ) ∃≥ (q, q 0 )     ∃(p0 , q 0 )
                                                                               (maj)
                                               ∃(p, q)
                        ∃(p, q) ∀(q, q 0 )                ∃> (p, q) ∃≥ (q, p)
                               ϕ           (X)                     ϕ          (X)


      Figure 7.1: Rules for S† (card). (card-mon) and (card-anti) are the same!




84
                7.1 S† (card): syllogistic logic with negation and cardinality comparison

Example 7.1         All x are non-y follows from the list of assumptions below:

  (i) There are at least as many non-y as y

 (ii) There are at least as many non-z as z

(iii) All x are z

(iv) All non-y are z

  Here is a formal proof in our system:

                                             ∃≥ (y, y)   ∃≥ (z, z)
                                                                 (Half)
                                  ∀(y, z)          ∃≥ (y, z)
                                                             (Card Mix)
                        ∀(x, z)             ∀(z, y)
                                                    (Barbara)
                                  ∀(x, y)



   We write ∃≥ (x, y) for There are at least as many x as y, and we are interested in
adding these sentences to our fragments. We are usually interested in sentences in this
fragment on finite models. We write |S| for the cardinality of the set ϕ. The semantics
is that M |= ∃≥ (x, y) iff |[[x]]| ≥ |[[y]]| in M.

Remark In the remainder of this chapter Γ denotes a finite set of sentences. The reason
is that the logic is not so well-behaved for infinite sets of assumptions; see Exercise 41.
  We need a little notation at this point.

Definition Let Γ be a (finite) set of sentences. As before, we write x ≤ y for Γ `
All x are y. Note that Γ is left off the notation. And we write x ≡ y for x ≤ y ≤ x.
  We write x ≤c y for Γ ` ∃≥ (y, x). We also write x ≡c y for x ≤c y ≤c x, and x <c y
for x ≤c y but x 6≡c y.
  Finally, we write x <more y if Γ ` ∃> (y, x).

Proposition 7.1.1 Let Γ ⊆ L(all, ∃≥ ) be a (finite) set. Let V be the set of variables in
Γ.

  (i) If x ≤ y, then x ≤c y.

 (ii) (V, ≤c ) is a preorder: a reflexive and transitive relation.

(iii) If x ≤c y ≤ x, then x ≤ y.

(iv) If x ≤c y, x ≡ x0 , and y ≡ y 0 , then x0 ≤c y 0 .

 (v) (V, ≤c ) is pre-wellfounded: a preorder with no descending sequences in its strict
     part.



                                                                                        85
7 S† (card): Reasoning about the Sizes of Sets

Proof Part (1) uses the (subset-size) rule. In part (2), the reflexivity of ≤c comes
from that of ≤ and part (1); the transitivity is by the second rule of ∃≥ . Part (3) is by
the last rule of ∃≥ . Part 4 uses part (1) and transitivity. Part 5 is just a summary of
the previous parts.                                                                      a


Preliminary: listings of finite transitive sets A listing of a set is an enumeration
without repetitions.

Lemma 7.1.2 Let (T, <) be a finite set with a transitive, irreflexive relation. Then
there is a listing of T as
                                  t1 , t2 , . . . , tn
with the property that if ti < tj , then i < j. In words, the <-predecessors of each point
are listed before it.

Proof By induction on the size of T . If T has 0 or 1 element, the result is trivial.
Assume the result for orders of size n, and let (T, ≤) be of size n + 1. Let x be such
that there is no y < x. Such x must exist since T is finite. (Here is the argument in
more detail: Suppose towards a contradiction that for every z there were some w < z,
we would have an infinite sequence z0 > z1 > · · · > zn > · · · . By finiteness there is
m < n so that zm = zn . But by transitivity we have zm > zn . And this contradicts
the irreflexivity of <.) Let T 0 = T \ {x}, and consider T 0 with the restriction <0 of <.
This order (T 0 , <0 ) is again transitive and irreflexive, and it has size n. By induction
hypothesis, there exists a listing of T 0 as t1 , t2 , . . . , tn . Then we take for the listing on T
the list x, t1 , t2 , . . . , tn .                                                                  a
  We also need the following refinement of Lemma 7.1.2.

Lemma 7.1.3 Let (T, <) be a finite set with a transitive, irreflexive relation. Suppose
that x 6≤ y in T . Then there is a listing of T as

                                           t1 , t2 , . . . , tn

with the following properties:
  (i) If ti < tj , then i < j: the <-predecessors of each point are listed before it.

 (ii) If ti = x and tj = y, then j < i. That is, x comes after y in the listing.

Proof Let t1 , t2 , . . . , tn be an enumeration as in Lemma 7.1.2. If y comes before x in
the enumeration, then we are done. Otherwise, x comes before y in the enumeration.
Let

        S = {z : z is between x and y (inclusive) in the enumeration, and x 6≤ z}

Notice that y ∈ S. Move the points in S to just before x, in their order in the original
enumeration. We need to check that the <-predecessors of each point are listed before



86
                                                         7.2 S(card) and the Construction Lemma



                                       ∀(n, p) ∀(p, q)                        ∃(p, q)
                    (axiom)                            (Barbara)                      (some)
          ∀(p, p)                          ∀(n, q)                            ∃(p, p)

       ∃(q, p)                          ∃(p, n) ∀(n, q)                    ∀(p, q)
               (conversion)                             (Darii)                       (subset-size)
       ∃(p, q)                               ∃(p, q)                      ∃≥ (q, p)

     ∃> (p, q)                         ∃(p, p) ∃≥ (p, q)               ∀(p, q) ∃≥ (p, q)
                 (more-at least)                         (card-∃)                        (card-mix)
     ∃≥ (p, q)                               ∃(q, q)                         ∀(q, p)

 ∃> (n, p) ∃≥ (p, q)
                     (more-left)
      ∃> (n, q)


                                   Figure 7.2: Rules for S(card).


it. The only points to worry about are those in S, and for some z ∈ S, we only need to
show that z has no <-predecessors which are ≥ x are also in S. Suppose that towards
a contradiction that w were such a predecessor. Then w < z ≤ y and, since w ∈  / S, we
have x ≤ w. Thus x ≤ w < z, and this contradicts z ∈ S.                              a


7.2 S(card) and the Construction Lemma
The Completeness Theorem for S† (card) takes a fair amount of work, and it makes sense
to study a smaller system first. We are going to study a logic S(card) as a stepping stone
towards S† (card). This smaller language S(card) has everything S† (card) has, but not
complemented variables.
             At this point, we need to emphasize that there is a difference between <c
           and <more . When we write a <c b, we mean that Γ ` At least as many b as a
           and Γ 6` At least as many a as b. This is weaker than Γ ` More b than a. If
           Γ is consistent and Γ ` More b than a, then Γ ` At least as many b as a. But
           the converse does not hold.

Lemma 7.2.1 Let Γ be a finite set of sentences in S(card) which is consistent in the
logic. Let V be a finite set of variables which include all the variables occurring in Γ.
Let V/ ≡c be the set of equivalence classes of variables in Γ under ≡c . Let

                                         [u0 ], [u2 ], . . . , [uk ]

be a listing of V/ ≡c with the property that if ui <c uj , then i < j.
  Then there is a model M = MΓ such that for all a, b ∈ V and 0 ≤ i, j ≤ k,

 (α) If a ≤ b, then [[a]] ⊆ [[b]].



                                                                                                      87
7 S† (card): Reasoning about the Sizes of Sets

 (β) If i < j and ∃≥ (uj , ui ), then |[[ui ]]| ≤ |[[uj ]]|.

 (γ) If i < j and ∃> (uj , ui ), then |[[ui ]]| < |[[uj ]]|.

Moreover, M |= Γ.

Proof We define by recursion on i ≤ k the interpretation [[v]] of all v ∈ [ui ]. Suppose
that for all j < i and all w ≡c uj , we have an interpretation [[w]]. For v ∈ [ui ], let
                         S
                    Bv = S{[[x]] : x ≤ v and (∃j < i)(x ≡c uj )}
                    Cv =   {ϕ ∈ Γ : ϕ is ∃(v, u) or ∃(u, v) for some u}
                    Dv = Bv ∪ Cv

We start by setting [[v]] to be Dv , but we might need to add more points in order to
satisfy some of the requirements. Let

                                    n = max{|Dv | : v ∈ [ui ]}.

For each v, add fresh points to [[v]] in order that they all have the same size. That is,
add n − |Dv | points to [[v]]. Finally, if there is some i < j such that ∃> (uj , ui ), and yet
|[[uj ]]| = |[[ui ]], then add one fresh point to [[v]] for all v ∈ [ui ].
    It is not hard to see that (α), (β), and (γ) all hold. Further, we check that M |= Γ. a


Example Suppose that Γ is the following set of sentences:

     All p are q                                               There are at least as many x as w
     There are at least as many q as p                         There are at least as many x as r
     All q are s                                               All y are z
     There are at least as many r as s                         There are at least as many w as z
     There are at least as many s as r                         All z are v
     There are at least as many w as x                         There are at least as many s as v

Here is a picture of the relations ≤ and ≤c . The lines are the ≤c relation, reading
upward, with the stronger ≤ relations shown.


                                                          v
                                                                      z≤v


                              r ≡c s                                           z
                  q≤s                                                                 y≤z


      q≡p                                             w ≡c x                                  y

  We start with distinct elements ∗p = ∗q , ∗r , ∗s , ∗w , ∗x , ∗y , ∗z .
  Let’s list V/ ≡c as [p], [w], [r], [y], [x], [v].



88
                                                  7.3 The Completeness Theorem for S(card)

   We follow the proof of Lemma 7.2.1 using this listing. Each time we need fresh
elements, we shall use numbers.

          [[p]]   =   {∗p }         [[r]]   =   {∗r , 3, 4, 5, 6, 7}
          [[q]]   =   {∗p }         [[s]]   =   {∗p , ∗s , 8, 9, 10, 11}
          [[w]]   =   {∗w , 1}      [[y]]   =   {∗y , 12, . . . , 22, 23}
          [[x]]   =   {∗x , 2}      [[z]]   =   {∗y , ∗z , 12, . . . , 22, 23}
                                    [[v]]   =   {∗v , ∗y , ∗z , 12, . . . , 23, 24, 25, . . . , 39}

Observe that the model satisfies Γ, and that the only inclusion (⊆) relations between
the interpretations of different atoms are the ones implied by Γ: [[q]] ⊆ [[s]], [[y]] ⊆ [[z]],
[[z]] ⊆ [[v]], and [[y]] ⊆ [[v]].


7.3 The Completeness Theorem for S(card)
Theorem 7.3.1 The logic of Figure 7.2 is complete for S(card).

Proof We show that for all sentences ϕ, if Γ |= ϕ, then Γ ` ϕ. Actually, we assume
that Γ is consistent, and then we prove that if Γ 6` ϕ, then there is a model of Γ where
ϕ fails. We break into two cases, depending on what kind of sentence ϕ is.

The first case: ϕ is of the form ∃(x, y)         In this case, we check by induction on i that
                                                S
                                 [[x]] ∩ [[y]] ∩ j<i [[ui ]] = ∅.

The next case: ϕ is of the form ∃≥ (x, y) Assuming that Γ 6` ϕ, we see that y 6≤c x.
We start with a listing of V/ ≡c which puts [x] before [y]. And then at the step when
we define [[y]] (and also [[v]] for all v ≡c y, we need only add a fresh element to [[y]] (if
need be) in order to get a model where |[[y]]| > |[[x]]|.

The next case: ϕ is of the form ∀(x, y) If x ≡c y, then we also have ¬(x ≡ y). So
when we define [[x]] and [[y]], we can add a point to [[x]] which is not in [[y]]. If x <c y,
then our listing of V/ ≡c puts [x] before [y]. When we define [[x]], make sure that it is
not empty. Then when we define [[y]], our construction has arranged that it not be a
superset of [[x]]. Finally, we have the case when y <c x. In this case, when we define
[[x]] we already have [[y]], and we can add a fresh point to [[x]] to insure that it not be a
subset of [[x]].

The final case: ϕ is of the form ∃> (x, y) If x ≡c y, then our model construction gives
a model of Γ where [[x]] and [[y]] are of the same size, as desired. If x <c y, then our
construction gives a model where |[[x]]| ≤ |[[y]]|. Again, this is what we want. Finally, we
have the case when y <c x. This is the trickiest and most interesting case.
  This concludes the proof of our theorem.                                                 a




                                                                                                      89
7 S† (card): Reasoning about the Sizes of Sets

7.4 The Completeness Theorem for S† (card)
We now use the Construction Lemma 7.2.1 and also Theorem 7.3.1 to prove the com-
pleteness of our system for S† (card).

7.4.1 Small, large, and half

Definition Γ is trivial if for all p, Γ ` ∀(p, p). Otherwise, Γ is non-trivial.

Lemma 7.4.1 Let Γ be consistent and non-trivial. There is a partition of the unary
atoms into three sets
                             small, half, and large
such that
  (i) If Γ ` ∃> (p, p), then p ∈ small.
 (ii) If Γ ` ∃≥ (p, p), then p ∈ small or p ∈ half.
 (iii) If Γ ` ∃≥ (p, p) and also Γ ` ∃≥ (p, p), then p, p ∈ half.
 (iv) If Γ ` ∃> (p, p), then p ∈ large.
  (v) If Γ ` ∃≥ (p, p), then p ∈ large or p ∈ half.
 (vi) If p ∈ small, then p ∈ large.
(vii) If p ∈ half, then p in half.
(viii) If p ∈ large, then p ∈ small.
 (ix) If p ∈ small and q ≤c p, then q ∈ small.
  (x) If p ∈ large and p ≤c q, then q ∈ large.
 (xi) If p ∈ half and q ≤c p, then either q ∈ small or q ∈ half.
(xii) If p ∈ half and p ≤c q, then either q ∈ large or q ∈ half.

Proof By induction on the number of raw variables in the language. For n = 0, the
result is trivial.
  Assume our result for n, and let the raw variables be p0 , . . . , pn+1 . Let Π be a partition
for p0 , . . . , pn . We need to see where pn+1 and pn+1 belong. If any of items (1)–(5) apply,
then we know where to put p and p using (1)–(5) and (6)–(8). (Since Γ is consistent, at
most one of (1)–(5) applies.) In these cases, we must be sure that (9)–(12) continue to
hold.
  If none of (1)–(5) apply, then we check if any of (9)–(12) apply. More specifically, we
take q = pn+1 and see if there is some p which works in any of (9)–(12). We first need
to check that this step does not lead to contradictory results. And then we would need
to know that after we assign pn+1 and pn+1 to the three classes, that (9)–(12) continue
to hold.                                                                                       a



90
                                             7.4 The Completeness Theorem for S† (card)

  We also need two generalizations of Lemma 7.4.1.
  We say that the small class is smaller than the half class, and both of these are smaller
than the large class.

Lemma 7.4.2 Suppose that Γ 6` ∃≥ (p, q). Then there is a partition of the nouns as in
Lemma 7.4.1 such that one of the following holds:

  (i) p and q are both in small.

 (ii) p and q are both in small.

(iii) p and q are in different classes, and the class of p is smaller than the class of q.

Proof The hypothesis that Γ 6` ∃≥ (p, q) implies that Γ is consistent and non-trivial.
The idea is to follow the proof of Lemma 7.4.1 but to start with the raw variables
underlying p and q. For example, we might classify p as small because Γ ` ∃≥ (p, p), and
then perhaps p ≤ q so that we classify q as large. These first two steps easily arrange
that one of the three possibilities in our lemma holds. That is, we cannot classify p and
q as both in half, and we also cannot classify p in a class that is larger than the class of
q.
   Formally, the proof is by induction on the number of raw variables other than the
raw variables underlying p and q. If this number is 0, we have sketched the argument.
Assume our result for some number n, and suppose that we have n + 1 raw variables to
classify, and let Π be a partition of the first n (and also of p and q).                  a


7.4.2 Building a model of a consistent set Γ of S† (card)
Lemma 7.4.3 Every consistent set Γ has a model.

  We prove this lemma in stages in this section.

The preliminary model M0 The model M0 is defined by taking the existential sentences
as points in the usual way. Under the standing assumption that Γ is consistent, this
model satisfies Γall and Γsome . As we continue to build other models to satisfy the
cardinality sentences in Γ, we need to be sure that the models again satisfy Γall and
Γsome .

M1 : cardinality comparison for small and half At this point, we uncouple our model.
  We next use previous work to expand the model to take care of the following types of
sentences:

 ∃≥ (p, q) with p ∈ small

 ∃> (p, q) with p ∈ small

 ∃≥ (p, q) with p ∈ half and q ∈ small



                                                                                         91
7 S† (card): Reasoning about the Sizes of Sets

 ∃> (p, q) with p ∈ half and q ∈ small

We can do this in such a way that the universal and existential sentences in Γ continue
to hold. We treat all of the polarized variables independently, and we need to know that
“at the top” (i.e., in half) the order ≤ is trivial: see two of the last observations before
this paragraph.
  We then extend this to take into account comparison between small and half variables.
We always insure that the ∀ sentences in Γ are respected.
  Call this model M1 .
  In M1 , if x and y are polarized variables in half, then their interpretations [[x]] and [[y]]
might or might not have the same size. Even if they did have the same size, there is no
reason to think that this size will be half the size of the universe M1 .

Proposition 7.4.4 Either Γ is trivial, or else whenever p and q belong to large, then it
is consistent with Γ that ∃(p, q).

Proof    This is because
                                            ∃≥ (p, p)         ∃≥ (q, q)
                                 ∀(p, q)          ∃≥ (p, q)
                                           ∀(q, p)



There are at least as many p as non-p, There are at least as many q as non-q, No p are q ` There ar

That is, if it were inconsistent with Γ that ∃(p, q), then both p and q would belong to
half.
  This uses (subset card), (card trans), and (antitone).                              a


M2 : Adding a point, if necessary If |M1 | is odd, then we need to add a point. (If |M1 |
is even, skip this step.) Let ∗ be a fresh point. We want to insure that if p and p belong
to half, then the number Dp defined below is even.

                                    Dp      =      |[[p]] − [[p]]|.

If Dp is odd, then add ∗ to [[p]]. (Actually, it would work to add ∗ to either [[p]] or [[p]].)
We need to insure that Γall is respected. The first thing is that by the assumption that
Γ is non-trivial, Γ ` ∃(p, p) for all p ∈ half. Second, we need to say what happens when
both p and p belong to half and also q and q. The point is that adding the same point
∗ to both [[p]] and [[q]] insures that ∃(p, q) holds in the model; however, it might be that
Γ ` ∀(p, q). So for this, we list the raw variables in half:

                                            p1 , . . . , pk

and then we proceed down this list. For 1 ≤ i ≤ k, we must either add ∗ to [[pi ]] or [[pi ]].
And if i < j and Γ ` ∀(pi , pj ), then we should not add ∗ to both [[pi ]] and [[pj ]]. Finally,



92
                                                     7.4 The Completeness Theorem for S† (card)

if Γ ` ∀(pi , pj ), then we should not add ∗ to both [[pi ]] and [[pj ]]. Suppose we have done
this up to i, and we consider pi+1 . If there is some j < i + 1 such that Γ ` ∀(pj , pi+1 ),
then add ∗ to [[pi+1 ]] iff it was added to [[pj ]]. If there is some j < i + 1 such that
Γ ` ∀(pj , pi+1 ), then add ∗ to [[pi+1 ]] iff it was added to [[pj ]]. In other cases, ∗ may be
added to either [[pi+1 ]] or to [[pi+1 ]].
   We also would like to know that there cannot be contradictory requirements to fulfill.
There are a few cases to consider here, and they are all similar. For example, suppose
that we had j, h < i + 1 such that pj ≤ pi+1 , ∗ ∈ [[pj ]], ph ≤ pi+1 , and ∗ ∈ [[ph ]]. If this
were possible, we would be in the problematic position of needing to add ∗ to both [[pi+1 ]]
and [[pi+1 ]]. However, the assumptions imply that pj ≤ ph (see Example 7.1). Without
loss of generality, j < h. So our construction has already arranged that ∗ was added to
[[ph ]]. This is a contradiction.
   We are still showing that M2 satisfies all of the All sentences in Γ. There are a few
more points to check. Notice first that if we are making an addition at this point, then
the universe of M1 must be of odd cardinality, hence non-empty. Thus it must be the
case that Γ ` ∃(q, q) for some q. The (Int) rule tells us that if p ∈ half, then Γ ` ∃(p, p).
So adding ∗ cannot lead to a contradiction of the form ∀(p, p) with p ∈ half. And if p
and q are different elements of half, and if Γ contains ∀(p, q), then ∗ will not be put in
both [[p]] and [[q]], by construction. Finally, if p and q are both in large, we might well add
∗ to both [[p]] and [[q]]. We claim that in this case, Γ 6` ∀(p, q). For if we did have p ≤ q,
then by by Proposition 7.4.4, q would belong to large. And this contradicts q ∈ large.

M3 : Making sure that the half polarized variables are interpreted by half of the
universe At this point, we know that the differences Dp are even numbers whenever p
is a half-occurring raw variable. Let

                                           N    = maxp Dp

By what we just did, N is an even number. We next add N fresh points to the universe,
call them a1 , . . . , aN . When we add points to the universe, we must say for each p
whether they go in [[p]] or [[p]]. If p ∈ small, we add all the fresh points to [[p]]. If p ∈ large,
we add all the fresh points to [[p]]. If p ∈ half, we divvy the fresh points up. Suppose that
[[p]] − [[p]] ≥ 0, call it m. Then we and a1 , . . . , a N +m to [[p]] and a1+ N +m , . . . , aN to [[p]]. If
                                                           2                     2
[[p]] − [[p]] < 0, the division is similar. This has arranged that |[[p]]| = |[[p]]| for all p ∈ half.
To make sure that these additions have not messed anything up, we need to check that
if Γ ` ∀(p, q), then no ai belongs to [[p]] ∩ [[q]]. For suppose that this happenend. We have
four cases:

  (i) p ∈ half, q ∈ half.

 (ii) p ∈ half, q ∈ large.

 (iii) p ∈ large, q ∈ half.

 (iv) p ∈ large, q ∈ large.



                                                                                                          93
       7 S† (card): Reasoning about the Sizes of Sets

       We cannot have q in large: for if we did, then q ∈ small, and so p ∈ small as well. This
       leaves cases 1 and 3. In case 3, we have q ∈ half, and so this contradicts p ∈ large and
       ∀(p, q). In case 1, we have p ≤ q, and the construction has arranged that the fresh points
       in [[p]] are the same as the fresh points in [[q]]. So we are again done in this case.

       M4 : Taking care of the large variables Finally, we expand M3 to be sure that all of the
       cardinality statements for the large variables are true in the model. The only sentences
       that we need to consider are ∃≥ (p, q) and ∃> (p, q), with p ∈ large and q ∈ small or
       q ∈ half.
         We find some appropriate number K and add K fresh points to [[p]] for p ∈ large. We
       must be sure that K is even, and then for each p ∈ half, we add half of the fresh points
       to [[p]] and half to [[p]].

       7.4.3 The completeness theorem
       Recall that to prove completeness, we are going to show that if Γ 6` ϕ then Γ 6|= ϕ.
       In logics with (RAA), we would usually consider Γ ∪ {ϕ} and then show that this has
       a model. But in logics like S† (card), this is not available to us. Instead, we need a
       generalization of Theorem ??.

       Theorem 7.4.5 Γ 6` ϕ then Γ 6|= ϕ.

       Proof What we are going to do is to repeat the model constructions in Theorem ??.
       We need to argue case-by-case depending on ϕ.

       Case 1: ϕ is ∀(p, q). One starts M0 with an extra point declared to be in [[p]] ∩ [[q]].
       The rest of the construction is the same.
          In case p and q are both small, this follows from what we did on the language of ∃≥ .
       It is easy to check that this same assertion holds for all of the other cases, except when
       p and q are both in half. Here we need to be sure that adding points to [[p]] ∩ [[q]] will not
       cause problems. For if Γ ` ∀(p, q), then also Γ ` ∀(q, p). But if p and q are in half, then
       we also have Γ ` ∀(p, q). And this is a contradiction.

       Case 2: ϕ is ∃(p, q). In this case, we need to be sure that the models M0 , . . . , M4 can
       be constructed subject to the additional requirement that [[p]] ∩ [[q]] = ∅.
         For M0 , this is easy.
         For M1 and M2 , and p, q ∈ half, it is important that we can always insist that [[p]] = [[q]]
       (and also that [[q]] = [[p]]). The only way this could cause a problem is that Γ ` ∃(p, q)
       (contrary to this case) or Γ ` ∃(p, q). But in this last case, we would have Γ ` ∃(p, q)
       using the (Maj) rule.
         For M4 , this is due to the fact that if p and q both belong to large, then Γ cannot
need   contain ∀(p, q).

       Case 3: ϕ is ∃≥ (p, q).



       94
                                                  7.4 The Completeness Theorem for S† (card)

Case 4: ϕ is ∃> (p, q). We have several subcases.



  (i) Γ 6` ∃≥ (p, p), Γ 6` ∃≥ (p, p), Γ 6` ∃≥ (q, q), Γ 6` ∃≥ (q, q).

      We can put p ∈ small and q ∈ large.


  (ii) Γ 6` ∃≥ (p, p), Γ 6` ∃≥ (p, p), Γ 6` ∃≥ (q, q), Γ ` ∃≥ (q, q).

      We can put p ∈ small and also put q ∈ small, and also arrange ∃≥ (q, p).


 (iii) Γ 6` ∃≥ (p, p), Γ 6` ∃≥ (p, p), Γ ` ∃≥ (q, q), Γ 6` ∃≥ (q, q).

      We can put p ∈ small and we automatically have q ∈ large.


 (iv) Γ 6` ∃≥ (p, p), Γ 6` ∃≥ (p, p), Γ ` ∃≥ (q, q), Γ ` ∃≥ (q, q).

      We can put p ∈ small and we automatically have q ∈ half.


  (v) Γ 6` ∃≥ (p, p), Γ ` ∃≥ (p, p), Γ 6` ∃≥ (q, q), Γ 6` ∃≥ (q, q).

      We automatically have p ∈ small, and we can put q ∈ large.


 (vi) Γ 6` ∃≥ (p, p), Γ ` ∃≥ (p, p), Γ 6` ∃≥ (q, q), Γ ` ∃≥ (q, q).

      We automatically have p, q ∈ small, and we can arrange that ∃≥ (q, p).


(vii) Γ 6` ∃≥ (p, p), Γ ` ∃≥ (p, p), Γ ` ∃≥ (q, q), Γ 6` ∃≥ (q, q).

      In this case, Γ ` ∃≥ (q, p), and so our model M4 |= ¬∃> (p, q).


(viii) Γ 6` ∃≥ (p, p), Γ ` ∃≥ (p, p), Γ ` ∃≥ (q, q), Γ ` ∃≥ (q, q).

      This is the same as case 7.



                                                                                         95
7 S† (card): Reasoning about the Sizes of Sets

 (ix) Γ ` ∃≥ (p, p), Γ 6` ∃≥ (p, p), Γ 6` ∃≥ (q, q), Γ 6` ∃≥ (q, q).
       We automatically have p ∈ large, and we can put q ∈ large and also arrange that
       p ≡c q.

  (x) Γ ` ∃≥ (p, p), Γ 6` ∃≥ (p, p), Γ 6` ∃≥ (q, q), Γ ` ∃≥ (q, q).

 (xi) Γ ` ∃≥ (p, p), Γ 6` ∃≥ (p, p), Γ ` ∃≥ (q, q), Γ 6` ∃≥ (q, q).

(xii) Γ ` ∃≥ (p, p), Γ 6` ∃≥ (p, p), Γ ` ∃≥ (q, q), Γ ` ∃≥ (q, q).

(xiii) Γ ` ∃≥ (p, p), Γ ` ∃≥ (p, p), Γ 6` ∃≥ (q, q), Γ 6` ∃≥ (q, q).
       We automatically have p ∈ half, and we can arrange that q ∈ large.

(xiv) Γ ` ∃≥ (p, p), Γ ` ∃≥ (p, p), Γ 6` ∃≥ (q, q), Γ ` ∃≥ (q, q).
       We automatically have p ∈ half, and we should be able to put q ∈ half as well.

(xv) Γ ` ∃≥ (p, p), Γ ` ∃≥ (p, p), Γ ` ∃≥ (q, q), Γ 6` ∃≥ (q, q).
       We automatically have p ∈ half and q ∈ large.

(xvi) Γ ` ∃≥ (p, p), Γ ` ∃≥ (p, p), Γ ` ∃≥ (q, q), Γ ` ∃≥ (q, q).
       In M4 , p and q have the same size.

   This completes the proof of Theorem 7.4.5.                                           a


7.5 Adding ∃≥ to the Boolean syllogistic fragment
We now put aside Most and return to the study of ∃≥ from earlier. We close this chapter
with the addition of ∃≥ to the fragment of Section 7.
  Our logical system extends the axioms of Figure ?? by those in Figure ??. Note
that the last new axiom expresses cardinal comparison. Axiom 4 in Figure 7.3 is just a
transcription of the rule for No that we saw in Section 42. We do not need to also add
the axiom
                       (Some y are y) ∧ ∃≥ (x, y) → Some x are x
because it is derivable. Here is a sketch, in English. Assume that there are some ys, and
there are at least as many xs as ys, but (towards a contradiction) that there are no xs.
Then all x’s are ys. From our logic, all ys are xs as well. And since there are y’s, there
are also x’s: a contradiction.
  Notice also that in the current fragment we can express There are more x than y. It
would be possible to add this directly to our previous systems.

Theorem 7.5.1 The logic of Figures ?? and 7.3 is complete for assertions ∆ |= ϕ in
the language of boolean combinations of sentences in L(all, some, no, ∃≥ ).



96
                                            7.5 Adding ∃≥ to the Boolean syllogistic fragment


   (i) All x are y → ∃≥ (y, x)

  (ii) ∃≥ (x, y) ∧ ∃≥ (y, z) → ∃≥ (x, z)

 (iii) All y are x ∧ ∃≥ (y, x) → All x are y

 (iv) No x are x → ∃≥ (y, x)

  (v) ∃≥ (x, y) ∨ ∃≥ (y, x)

           Figure 7.3: Additions to the system in Figure ?? for ∃≥ sentences.


Proof We need only build a model for a maximal consistent set ∆ in the language of
this section. We take the basic sentences to be those of the form All x are y, Some x
and y, J is M , J is an x, ∃≥ (x, y), or their negations. Let

                              Γ    =      {S : ∆ |= S and ϕ is basic}.

As in Section 4.4, we need only build a model M |= Γ (see Lemma ??). We construct M             rework this
such that for all A and B,

 (α) [[A]] ⊆ [[B]] iff A ≤ B.

 (β) A ≤c B iff |[[A]]| ≤ |[[B]]|.

 (γ) For A ≤c B, [[A]] ∩ [[B]] 6= ∅ iff A ↑ B.

  Let V be the set of variables in Γ. Let ≤c and ≡c be as in Section ??. Proposition 7.1.1
again holds, and now the quotient V/ ≡c is a linear order due to the last axiom in
Figure 7.3. We write it as

                           [u0 ]     <c    [u2 ]   <c   ···     <c   [uk ]

  We define by recursion on i ≤ k the interpretation [[v]] of all v ∈ [ui ]. The case of
i = 0 is special. If Γ |= No u0 is a u0 , then the same holds for all w ≡c u0 . In this case,
we set [[w]] = ∅ for all these w. Note that by our fourth axiom in Figure 7.3, all of the
other variables w are such that Γ ` ∃w. In any case, we must interpret the variables in
[u0 ] even when Γ ` (∃u0 ). In this case, we may take each [[w]] to be a singleton, with the
added condition that v ≡ w iff [[v]] = [[w]].
  Suppose we have [[w]] for all j ≤ i and all w ≡c uj . Let
                                                  [
                                 Xi+1 =                [[w]],
                                                   j≤i,w≡c uj

and note that this is the set of all points used in the semantics of any variable so far.
Let m = |Γsome |, and let
                                 n = 1 + m + |Xi+1 |                                (7.1)



                                                                                          97
7 S† (card): Reasoning about the Sizes of Sets

For all v ≡c ui+1 , we shall arrange that [[v]] be a set of size n.
   Now [ui+1 ] splits into equivalence classes of the finer relation ≡. For a moment,
consider one of those finer classes, say [A]≡ . We must interpret each variable in this
class by the same set. For this A, let
                                   [
                        YA =         {[[B]] : (∃j ≤ i) vj ≡c B ≤ A}.

Note that YA ⊆ Xi+1 so that |YA | ≤ |Xi+1 | for all A ≡c ui+1 . We shall set [[A]] to be YA
plus other points. Let A be the set of pairs {A, B} with B ≡c ui+1 and A ↑Γ B. (This
is the same as saying that Some A are B in Γsome .) Notice that if both A and B are
≡c ui+1 and A ↑Γ B, then {A, B} ∈ ZA ∩ B .) We shall set [[A]] to be YA ∪ A plus one
last group of points. If C <c ui+1 and A ↑Γ C, then we must pick some element of [[C]]
and put it into [[A]]. Note that the number of points selected like this plus |ZA | is still
≤ |Γsome |. So the number of points so far in [[A]] is ≤ |Γsome | + m. We finally add fresh
elements to [[A]] so that the total is n.
    We do all of this for all of the other ≡-classes which partition the ≡c -class of ui+1 .
We must insure that for A 6≡ A0 , the fresh elements added into [[A0 ]] are disjoint from
the fresh elements added into [[A]]. This is needed to arrange that neither [[A]] nor [[A0 ]]
will be a subset of the other.
    This completes the definition of the model. We say a few words about why require-
ments (α)–(γ) are met. First, and easy induction on i shows that if j < i, then
|[[uj ]]| < |[[ui ]]|. The point is that |[[uj ]]| ≤ |Xi | < |[[ui ]]|. The argument for (β) is the
same as in the proof of Theorem ??. For that matter, the proof of (α) is also essentially
the same. The point is that when A ≡c B and A 6≡ B, then [[A]] and [[B]] each contain a
point not in the other.
    For (γ), suppose that A ≤c B. Let i ≤ j be such that A ≡c ui and B ≡ uj . The
construction arranged that [[A]] and [[B]] be disjoint except for the case that A ↑ B.
    So this verifies that (α)–(γ) hold. We would like to conclude that M |= Γ, but there is
one last point: (γ) appears to be a touch too weak. We need to know that [[A]] ∩ [[B]] 6= ∅
iff A ↑ B (without assuming A ≤c B). But either A ≤c B or B ≤c A by our last axiom.
So we see that indeed [[A]] ∩ [[B]] 6= ∅ iff A ↑ B.                                               a
  The next step in this direction would be to consider At least as many x as y are z.


7.6 Most
The semantics of Most is that Most x are y are that this is true iff |[[x]] ∩ [[y]]| > 21 |[[x]]|.
So if [[x]] is empty, then Most x are y is false.
   As an example of what is going on, consider the following. Assume that All x are z, All
y are z, Most z are y, and Most y are x. Does it follow that Most x are y? As it happens,
the conclusion does not follow. One can take x = {a, b, c, d, e, f, g}, y = {e, f, g, h, i},
and z = {a, b, c, d, e, f, g, h, i}. Then |x| = 7, |y| = 5, |z| = 9, |y ∩ z| = 5 > 9/5,
|x ∩ y| = 3 > 5/2, but |x ∩ y| = 3 < 7/2. (Another countermodel: let x = {1, 2, 4, 5},
y = {1, 2, 3}, and z = {1, 2, 3, 4, 5}. Then |y ∩ z| = 3 > 5/2, |y ∩ x| = 2 > 3/2, but
|x ∩ y| = 2 6 > 4/2.)



98
                                                                                       7.6 Most

               Most x are y      Some x are x     Most x are y Most x are z
               Some x are y      Most x are x           Some y are z

             Figure 7.4: Rules of Most to be used in conjunction with Some.


  On the other hand, the following is a sound rule:
                  All u are x    Most x are v All v are y        Most y are u
                                       Some u are v

Here is the reason for this. Assume our hypotheses and also that towards a contradiction
that u and v were disjoint. We obviously have |v| ≥ |x ∩ v|, and the second hypothesis,
together with the disjointness assumption, tells us that |x ∩ v| > |x ∩ u|. By the first
hypothesis, we have |x ∩ u| = |u|. So at this point we have |v| > |u|. But the last two
hypotheses similarly give us the opposite inequality |u| > |v|. This is a contradiction.
  At the time of this writing, I do not have a completeness result for L(all, some, most).
The best that is known is for L(some, most). The rules are are shown in Figure 7.4. We
study these on top of the rules for some which we have seen:
                                Some y are x       Some x are y
                                                                                            (7.2)
                                Some x are y       Some x are x

Proposition 7.6.1 The following two axioms are complete for Most.
                                Most x are y       Most x are y
                                Most x are x       Most y are y

Moreover, if Γ ⊆ L(most), x 6= y, and Γ 6|= Most x are y, then there is a model M of Γ
which falsifies Most x are y in which all sets of the form [[u]] ∩ [[v]] are nonempty, and
|M | ≤ 5.

Proof Suppose that Γ 6` Most x are y. We construct a model M which satisfies all
sentences in Γ, but which falsifies Most x are x. There are two cases. If x = y, then x
does not occur in any sentence in Γ. We let M = {∗}, [[x]] = ∅, and [[y]] = {∗} for y 6= x.
  The other case is when x 6= y. Let M = {1, 2, 3, 4, 5}, [[x]] = {1, 2, 4, 5}, [[y]] = {1, 2, 3},
and for z 6= x, y, [[z]] = {1, 2, 3, 4, 5}. Then the only statement in Most which fails in the
model M is Most x are y. But this sentence does not belong to Γ. Thus M |= Γ.                   a

Theorem 7.6.2 The rules in Figure 7.4 together with the first two rules (7.2) are com-
plete for L(some, most). Moreover, if Γ 6|= ϕ, then there is a model M |= Γ with M 6|= ϕ,
and |M | ≤ 6.

Proof Suppose Γ 6` ϕ, where ϕ is Some x are y. If x = y, then Γ contains no sentence
involving x. So we may satisfy Γ and falsify ϕ in a one-point model, by setting [[x]] = ∅
and [[z]] = {∗} for z 6= x.



                                                                                               99
7 S† (card): Reasoning about the Sizes of Sets

   We next consider the case when x 6= y. Then Γ does not contain ϕ, Some y are x,
Most x are y, or Most y are x. And for all z, Γ does not contain both Most z are
x and Most z are y. Let M = {1, 2, 3, 4, 5, 6}, and consider the subsets a = {1, 2, 3},
b = {1, 2, 3, 4, 5}, c = {2, 3, 4, 5, 6}, and d = {4, 5, 6}. Let [[x]] = a and [[y]] = d, so that
M 6|= ϕ. For z different from x and y, if Γ does not contain Most z are x, let [[z]] = c.
Otherwise, Γ does not contain Most z are y, and so we let [[z]] = b. For all these z,
M satisfies whichever of the sentences Most z are x and Most z are y (if either) which
belong to Γ. M also satisfies all sentences Most x are z and Most y are z, whether or
not these belong to Γ. It also satisfies Most u are u for all u. Also, for z, z 0 each different
from both x and y, M |= Most z are z 0 . Finally, M satisfies all sentences Some u are v
except for u = x and y = v (or vice-versa). But those two sentences do not belong to Γ.
The upshot is that M |= Γ but M 6|= ϕ.
   Up until now in this proof, we have considered the case when ϕ is Some x are y. We
turn our attention to the case when ϕ is Most x are y. Suppose Γ 6` ϕ. If x = y, then
the second rule of Figure 7.4 shows that Γ 6` Some x are x. So we take M = {∗} and
take [[x]] = ∅ and for y 6= x, [[y]] = M . It is easy to check that M |= Γ.
   Finally, if x 6= y, we clearly have Γmost 6` ϕ. Proposition 7.6.1 shows that there is a
model M |= Γmost which falsifies ϕ in which all sets of the form [[u]] ∩ [[v]] are nonempty.
So all Some sentences hold in M. Hence M |= Γ.                                                  a


7.7 The numerical syllogistic
I hope to add Ian Pratt-Hartmann’s results in [?] on the complexity of reasoning with
the numerical syllogistic, and also his result in [?] that there is no finite syllogistic system
for it.

Sources for this chapter      The material in this chapter comes from Moss [?].


7.8 Exercises

Exercise 41. Given an example which shows a semantic failure of the Compactness
Theorem S(card). That is, find an infinite set Γ with the property that every finite
subset of Γ has a model, but Γ itself has no model.

Exercise 42. Consider the following two rules:

                          Some y are y ∃≥ (x, y)          No y are y
                              Some x are x                 ∃≥ (x, y)

  (i) Add the rule on the left to our existing system for S(all, some) and to the rules in
      Figure ??. Prove that the resulting system is complete for L(all, some, ∃≥ ).



100
                                                                           7.8 Exercises

(ii) Similarly, add the rule on the right to get a complete logic for the resulting lan-
     guage.

(iii) Finally, add both rules to again get a complete logic for the resulting language.




                                                                                     101
8 Small Additions
8.1 Adding names

8.2 Adding Boolean connectives to sentences
The purpose of this section is to add to our logical systems for S† and RCA the standard
Boolean sentential connectives: not (¬), and (∧), or (∨), if (→), if and only if (↔).
So we are adding to the syntax; the sentences of S† , and RCA are now regarded as
atomic sentences, and we add the Boolean connectives on top of our previous work. The
semantics is the obvious one.
  For the proof theory, we wish to present a proof system for the enlarged languages
which extends our previous systems.
  We continue to present our system as a natural deduction system. We could also
present it as a Fitch-style system as in textbook presentations.




                                                                                    103
9 The Limits of Syllogistic Proof Systems
When we presented a logic for RCA in Section 6, we made use of reductio ad absurdum
(RAA) . The reader might well wonder whether we need (RAA) or some such device,
or whether the kinds of logics which we have previously considered were sufficient. Now
is the time to answer this. We need to formulate exactly what we mean by a purely
syllogistic system, and then prove that there are no purely syllogistic systems for R
which are finite, sound, and complete.


9.1 General definitions on syllogistic proof systems
Let F be a syllogistic fragment. A derivation relation |∼ in F is a subset of P(F) × F,
where P(F) is the power set of F. For readability, we write Θ |∼ θ instead of hΘ, θi ∈ |∼.
We say that |∼ is sound if Θ |∼ θ implies Θ |= θ, and complete (for F) if Θ |= θ implies
Θ |∼ θ.

Definition Let F be a syllogistic fragment, what we have been calling a logical language
in these notes. We employ the following terminology. A syllogistic rule (sometimes,
simply: rule) in F is a pair Θ/θ, where Θ is a finite set (possibly empty) of F-sentences,
and θ an F-sentence. We call Θ the antecedents of the rule, and θ its consequent. The
rule Θ/θ is sound if Θ |= θ.
  A substitution is a function g = g1 ∪ g2 , where g1 : P → P and g2 : R → R. If θ is an
F-formula, denote by g(θ) the F-formula which results by replacing any atom (unary or
binary) in θ by its image under g, and similarly for sets of formulas. An instance of a
syllogistic rule Θ/θ is the syllogistic rule g(Θ)/g(θ), where g is a substitution.
  A syllogistic proof system is a set of syllogistic rules.
  We generally display rules in ‘natural-deduction’ style. For example,

               ∀(q, o)             ∃(p, q)              ∀(q, ō)              ∃(p, q)
                                                                                        (9.1)
                         ∃(p, o)                                   ∃(p, ō)

where p, q and o are unary atoms, are syllogistic rules in S, corresponding to the tradi-
tional syllogisms Darii and Ferio, respectively.
   Syllogistic rules which differ only with respect to re-naming of unary or binary atoms
will be informally regarded as identical, because they have the same instances. Thus,
the letters p, q and o in (9.1) function, in effect, as variables ranging over unary atoms.
It is often convenient to display syllogistic rules using variables ranging over other types
of expressions, understanding that these are just more compact ways of writing finite



                                                                                         105
9 The Limits of Syllogistic Proof Systems

collections of syllogistic rules in the official sense. For example, the two rules (9.1) may
be more compactly written

                                    ∀(q, l)             ∃(p, q)
                                                                  (D1)
                                              ∃(p, l)

where p and q range over unary atoms, but l ranges over unary literals.
  Fix a syllogistic fragment F, and let X be a set of syllogistic rules in F. Define `X to
be the smallest derivation relation in F satisfying:

  (i) if θ ∈ Θ, then Θ `X θ;

 (ii) if {θ1 , . . . , θn }/θ is a rule in X, g a substitution, Θ = Θ1 ∪ · · · ∪ Θn , and Θi `X g(θi )
      for all i (1 ≤ i ≤ n), then Θ `X g(θ).

It is simple to show that the derivation relation `X is sound if and only if each rule in X
is sound.
   Informally, we imagine chaining together instances of the rules in X to construct
derivations, in the obvious way; and we refer to the resulting proof system as the direct
syllogistic system defined by X. We generally display derivations in natural-deduction
style, as we have been doing throughout these notes.


9.2 No systems (without RAA) for R
Theorem 9.2.1 ([?]) There exists no finite set X of syllogistic rules in R such that `X
is both sound and complete.

Proof Let X be any finite set of syllogistic rules for R, and suppose `X is sound. We
show that it is not complete. Since X is finite, fix n ∈ N greater than the number of
antecedents in any rule in X.
  Let p1 , . . . , pn be distinct unary atoms and r a binary atom. Let Γ be the following
set of R-formulas:

                     ∀(pi , ∃(pi+1 , r))                                 (1 ≤ i < n)            (9.2)
                     ∀(p1 , ∀(pn , r))                                                          (9.3)
                     ∀(p, p)                                                (p ∈ P)             (9.4)
                     ∀(pi , p̄j )                                  (1 ≤ i < j ≤ n)              (9.5)

and let γ be the R-formula ∀(p1 , ∃(pn , r)). Observe that Γ |= γ. To see this, let M |= Γ.
If pM                                                     M
    1 = ∅, then trivially M |= γ; on the other hand, if p1 6= ∅, a simple induction using
formulas (9.2) shows that pMi 6= ∅ for all i (1 ≤ i ≤ n), whence M |= γ by (9.3).
   For 1 ≤ i < n, let ∆i = Γ \ {∀(pi , ∃(pi+1 , r))}.

Claim If ϕ ∈ R and ∆i |= ϕ, then ϕ ∈ Γ.



106
                                                                        9.2 No systems (without RAA) for R

  It follows from this claim that Γ 6`X γ. For, since no rule of X has more than n − 1
antecedents, any instance of those antecedents contained in Γ must be contained in ∆i
for some i. Let δ be the corresponding instance of the consequent of that rule. Since
`X is sound, ∆i |= δ. By Claim 9.2, δ ∈ Γ. By induction on the number of steps in
derivations, we see that no derivation from Γ leads to a formula not in Γ. But γ 6∈ Γ.
Proof [Proof of Claim] Certainly, ∆i has a model, for instance the model Mi given by:


                                                                                                                    (9.6)
                  p1     / p2   /     ···                  / pi     pi+1    /             ···          / pn

Here, A = {p1 , . . . , pn }, pM
                               j
                                 i
                                   = {pj } for all j (1 ≤ j ≤ n), and rMi is indicated by the
arrows. All other atoms (unary or binary) are assumed to have empty extensions. Note
that there is no arrow from pi to pi+1 .
   We consider the various possibilities for ϕ in turn and check that either ϕ ∈ Γ or there
is a model of ∆i in which ϕ is false.
(i) ϕ is of the form ∀(p, p). Then ϕ ∈ Γ by (9.4).
(ii) ϕ is not of the form ∀(p, p), and involves at least one unary or binary atom other
than p1 , . . . , pn , r. In this case, it is straightforward to modify Mi so as to obtain a model
M0i of ∆i such that M0i 6|= ϕ. Henceforth, then, we may assume that ϕ involves no atoms
other than p1 , . . . , pn , r.
(iii) ϕ is of the form ∀(pj , pk ). If j = k, then ϕ ∈ Γ, by (9.4). If j 6= k, then Mi 6|= ϕ by
inspection.
(iv) ϕ is of the form ∀(pj , p̄k ). If j = k, then Mi 6|= ϕ, since pM
                                                                    j
                                                                      i
                                                                        6= ∅. If j 6= k, then
ϕ ∈ Γ, by (9.5) and the identification ∀(pj , p̄k ) = ∀(pk , p̄j ).
(v) ϕ is of the form ∀(pj , ∀(pk , r)). If j = 1 and k = n, then ϕ ∈ Γ, by (9.3). So we
may assume that either j > 1 or k < n, in which case, k 6= j + 1 implies Mi 6|= ϕ, by
inspection. Hence, we may assume that ϕ = ∀(pj , ∀(pj+1 , r)), with j < n. Let Bi,j be
the structure obtained from Mi by adding a second point b to the interpretation of pj+1 ,
and to which pj is not related by r. In pictures:


               / p2    / ···          / pj+1         / pj+2        / ···           / pi                 / ···    
         p1                     pj                                                              pi+1            pn
                                                      :
                                          b
(This picture shows j + 2 < i. Similar pictures are possible in all other cases.) By
inspection, Bi,j |= ∆i , but Bi,j 6|= ϕ.
(vi) ϕ is of the form ∀(pj , ∃(pk , r)). If k = j + 1, then ϕ ∈ Γ, by (9.2). Moreover, if
k 6= j + 1, then, unless j = 1 and k = n, Mi 6|= ϕ, by inspection. Hence we may assume
ϕ = ∀(p1 , ∃(pn , r)). Let Ci be the structure:
                                     p1       / p2     /          ···           / pi ,




                                                                                                                      107
9 The Limits of Syllogistic Proof Systems

with pCj i = ∅ for all j (i < j ≤ n). Then Ci |= ∆i , but Ci 6|= ϕ.
(vii) ϕ is of either of the forms ∀(pj , ∀(pk , r̄)), ∀(pj , ∃(pk , r̄)). Define M00i to be like
Mi except that rMi additionally contains the pair of points hpj , pk i. By inspection,
                        00


M00i |= ∆i , but M00i 6|= ϕ.
(viii) ϕ is of the form ∃(p, c). Let M0 be a structure over any domain in which every
atom has empty extension. Then M0 |= ∆i , but M0 6|= ϕ.                             a
  This also completes the proof of Theorem 9.2.1.                                             a


9.3 No systems (even with RAA) for RC or RC†




108
10 Logic Beyond the Aristotle Border
There are only two languages in this chapter (actually they are families of languages
parameterized by sets of basic symbols): the language RC† which we have seen already,
and an extension L(adj) studied in Section 10.7. We reformulate RC† a bit, adding
constants and also being allowing for recursive constructs. To avoid confusion, we do
not speak of RC† but instead call the language of this chapter L. L is based on three
pairwise disjoint sets called P, R, and K. These are called unary atoms, binary atoms,
and constant symbols.


10.1 Fitch-style proof system for RC†
We review the syntax of L in Figure 10.1. Sentences are built from constant symbols,
unary and binary atoms using an involutive symbol for negation, a formation of set
terms, and also a form of quantification. The second column indicates the variables that
we shall use in order to refer to the objects of the various syntactic categories. Because
the syntax is not standard, it will be worthwhile to go through it slowly and to provide
glosses in English for expressions of various types.
   One might think of the constant symbols as proper names such as John and Mary.
The unary atoms may be glossed as one-place predictates such as boys, girls, etc. And
the relation symbols correspond to transitive verbs (that is, verbs which take a direct
object) such as likes, sees, etc. They also correspond to comparative adjective phrases
such as is bigger than. (However, later on in Section 10.7, we introduce a new syntactic
primitive for the adjectives.)
   Unary atoms appear to be one-place relation symbols, especially because we shall form
sentences of the form p(j). However, we do not have sentences p(x), since we have no
variables at this point in the first place. Similar remarks apply to binary atoms and two-
place relation symbols. So we chose to change the terminology from relation symbols to
atoms.
   We form unary and binary literals using the bar notation. We think of this as ex-
pressing classical negation. So we take it to be involutive, so that p = p and s = s.
   The set terms in this language are the only recursive construct. If b is read as boys
and s as sees, then one should read ∀(b, s) as sees all boys, and ∃(b, s) as sees some boys.
Hence these set terms correspond to simple verb phrases. We also allow negation on the
atoms, so we have ∀(b, s); this can be read as fails to see all boys, or (better) sees no boys
or doesn’t see any boys. We also have ∃(b, s), fails to see some boys. But the recursion
allows us to embed set terms, and so we have set terms like

                                     ∃(∀(∀(b, s), h), a)



                                                                                          109
10 Logic Beyond the Aristotle Border


            Expression             Variables      Syntax
            unary atom             p, q
            binary atom            s
            constant               j, k
            unary literal          l              p | p̄
            binary literal         r              s | s̄
            set term               b, c, d        l | ∃(c, r) | ∀(c, r)
            sentence               ϕ, ψ           ∀(c, d) | ∃(c, d) | c(j) | r(j, k)

                               Figure 10.1: Syntax of sentences of L.


which may be taken to symbolize a verb phrase such as admires someone who hates
everyone who does not see any boy.
  We should note that the relative clauses which can be obtained in this way are all
“missing the subject”, never “missing the object”. The language is too poor to express
predicates like λx.all boys see x.
  The main sentences in the language are of the form ∀(b, c) and ∃(b, c); they can be
read as statements of the inclusion of one set term extension in another, and of the
non-empty intersection. We also have sentences using the constants, such as ∀(g, s)(m),
corresponding to Mary sees all girls. But we are not able to say all girls see Mary; the
syntax again is too weak. (However, in our Conclusion we shall see how to extend our
system to handle this.) This weakness in expressive power corresponds to a less complex
decidability result, as we shall see.

Semantics. A model (for this language L) is a pair M = hM, [[ ]]i, where M is a non-
empty set, [[p]] ⊆ M for all p ∈ P, [[r]] ⊆ M 2 for all r ∈ R, and [[j]] ∈ M for all
j ∈ K.
  Given a model M, we extend the interpretation function [[ ]] to the rest of the language
by setting
             [[p]]         =    M \ [[p]]
             [[r]]         =    M 2 \ [[r]]
             [[∃(l, t)]]   =    {x ∈ M : for some y such that [[l]](y), [[t]](x, y)}
             [[∀(l, t)]]   =    {x ∈ M : for all y such that [[l]](y), [[t]](x, y)}
We define the truth relation |= between models and sentences by:
                                M |= ∀(c, d)     iff    [[c]] ⊆ [[d]]
                                M |= ∃(c, d)     iff    [[c]] ∩ [[d]] 6= ∅
                                M |= c(j)        iff    [[c]]([[j]])
                                M |= r(j, k)     iff    [[r]]([[j]], [[k]])
If Γ is a set of formulas, we write M |= Γ if for all ϕ ∈ Γ, M |= ϕ.




110
                                                             10.1 Fitch-style proof system for RC†

Example 10.1 For example, look back to Examples 5.1 and 6.2. This concerned the
model M defined by M = {w, x, y, z}, [[p]] = {w, x, y}, and with [[s]] shown below

                                           wO       /x


                                                ~   / z y
                                           yo

Note at this point that [[∃(∀(p, s), s)]] = ∅. We also set [[j]] = w and [[k]] = x. We get
additional sentences true in M such as s(j, k), s(k, j), and ∃(p, s)(k).
  Here is a point that will be important later. For all terms c, M |= c(j) iff M |= c(k).
(The easiest way to check this is to show that for all set terms c, [[c]] is one of the following
four sets: ∅, M, {w, x, y}, or {z}.) However, M |= s(j, k) and M |= s(k, j).

  The satisfiability problem for the language is decidable for a very easy reason: the
language L translates to the two-variable fragment FO2 of first-order logic. (We shall
see this shortly.) Thus we have the finite model property (by Mortimer [?]) and decid-
ability of satisfiability in non-deterministic exponential time (Grädel et al [?]). It might
therefore be interesting to ask whether the smaller fragment L is of a lower complexity.
As it happens, it is. Pratt-Hartmann [?] showed that the satisfiability problem for a
certain fragment E2 of FO2 can be decided in ExpTime in the length of the input Γ,
and his fragment was essentially the same as the one in this chapter.

The bar notation. We have already seen that our unary and binary atoms come with
negative forms. We extend this notation to all sentences in the following ways: p = p,
s = s, ∃(l, r) = ∀(l, r), ∀(l, r) = ∃(l, r), ∀(c, d) = ∃(c, d), ∃(c, d) = ∀(c, d), c(j) = c(j),
and r(j, k) = r(j, k).

Translation of the syllogistic into L. We indicate briefly a few translations to orient
the reader. First, the classical syllogistic translates into L:
              All p are q   7→ ∀(p, q)              No p are q      7 → ∀(p, q)
              Some p are q 7→ ∃(p, q)               Some p aren’t q → 7 ∃(p, q)

We can also translate L to FO2 , the fragment of first order logic using only the variables
x and w. We do this by mapping the set terms two ways, called c 7→ ϕc,x and c 7→ ϕc,y .
Here are the recursion equations for c 7→ ϕc,x :

                 p 7→ P (x)             ∀(c, r) →
                                                7   (∀y)(ϕc,y (y) → r(x, y))
                 p 7→ ¬P (x)            ∃(c, r) → 7 (∃y)(ϕc,y (y) ∧ r(x, y))

The equations for c 7→ ϕc,y are similar. Then the translation of the sentences into FO2
follows easily.
   We present our system in natural-deduction style in Figure 10.3. It makes use of
introduction and elimination rules, and more critically of variables. For a textbook
account of a proof system for first-order logic presented in this way, see van Dalen [?].



                                                                                              111
10 Logic Beyond the Aristotle Border


             Expression             Variables      Syntax
             individual variable    x, y
             individual term        t, u           x |j
             general sentence       α              ϕ | c(x) | r(x, y) | ⊥

      Figure 10.2: Syntax of general sentences of L, with ϕ ranging over sentences.


General sentences in this fragment are what usually are called formulas. We prefer
to change the standard terminology to make the point that here, sentences are not built
from formulas by quantification. In fact, sentences in our sense do not have variable
occurrences. But general sentences do include variables. They are only used in our
proof theory.
   The syntax of general sentences is given in Figure 10.2. What we are calling individual
terms are just variables and constant symbols. (There are no function symbols here.)
Using terms allows us to shorten the statements of our rules, but this is the only reason
to have terms.
   An additional note: we don’t need general sentences of the form r(j, x) or r(x, j). In
larger fragments, we would expect to see general sentences of these forms, but our proof
theory will not need these.

The bar notation, again. We have already seen the bar notation c for set terms c,
and ϕ for sentences ϕ. We extend this to formulas b(x) = b(x), r(x, y) = r(x, y). We
technically have a general sentence ⊥, but this plays no role in the proof theory.
   We write Γ ` ϕ if there is a proof tree conforming to the rules of the system with
root labeled ϕ and whose axioms are labeled by elements of Γ. (Frequently we shall be
sloppy about the labeling and just speak, e.g, of the root as if it were a sentence instead
of being labeled by one.) Instead of giving a precise definition here, we shall content
ourselves with a series of examples in Section 10.2 just below.
   The system has two rules called (∀E), one for deriving general sentences of the form
c(x) or c(j), and one for deriving general sentences r(x, y) or r(j, k). (Other rules are
doubled as well, of course.) It surely looks like these should be unified, and the system
would of course be more elegant if they were. But given the way we are presenting the
syntax, there is no way to do this. That is, we do not have a concept of substitution, and
so rules like (∀E) cannot be formulated in the usual way. Returning to the two rules
with the same name, we could have chosen to use different names, say (∀E1) and (∀E2).
But the result would have been a more cluttered notation, and it is always clear from
context which rule is being used.
   Although we are speaking of trees, we don’t distinguish left from right. This is espe-
cially the case with the (∃E) rules, where the canceled hypotheses may occur in either
order.

Side Conditions. As with every natural deduction system using variables, there are
some side conditions which are needed in order to have a sound system.



112
                                                         10.1 Fitch-style proof system for RC†


                  c(t)     ∀(c, d)                      c(u) ∀(c, r)(t)
                                   ∀E                                   ∀E
                         d(t)                               r(t, u)

                    c(t) d(t)                             r(t, u) c(u)
                              ∃I                                       ∃I
                      ∃(c, d)                               ∃(c, r)(t)

                      [c(x)]                                 [c(x)]
                         ..                                      ..
                          ..                                      ..
                       d(x)                                  r(t, x)
                              ∀I                                       ∀I
                      ∀(c, d)                               ∀(c, r)(t)

                             [c(x)]         [d(x)]                    [c(x)]      [r(t, x)]
                                      ..                                       ..
                                       ..                                       ..
               ∃(c, d)                α              ∃(c, r)(t)                α
                         α                  ∃E                    α               ∃E

                                                                  [ϕ]
                                                                   ..
                                                                    ..
                         α       α                                 ⊥
                                     ⊥I                                  RAA
                             ⊥                                     ϕ

Figure 10.3: Proof rules. See the text for the side conditions in the (∀I) and (∃E) rules.


  In (∀I), x must not occur free in any uncanceled hypothesis. For example, in the
version whose root is ∀(c, d), one must cancel all occurrences of c(x) in the leaves, and
x must not appear free in any other leaf.
  In (∃E), the variable x must not occur free in the conclusion α or in any uncanceled
hypothesis in the subderivation of α.
  In contrast to usual first-order natural deduction systems, there are no side conditions
on the rules (∀E) and (∃I). The usual side conditions are phrased in terms of concepts
such as free substitution, and the syntax here has no substitution to begin with. To be
sure on this point, one should check the soundness result of Lemma 10.3.1.


Formal proofs in the Fitch style. The proof system in this chapter is presented in a
standard Gentzen-style format. But it may easily be re-formatted to look more like a
Fitch system, as we shall see in Example 10.3 and Figure 10.5. These examples might give
the impression that we have merely re-presented Fitch-style natural deduction proofs.
The difference is that our syntax is not a special case of the syntax of first-order logic.
Corresponding to this, our proof rules our rather restrictive, and the system cannot be
used for much of anything beyond the language L. However, the fact that our Fitch-style
proofs look like familiar formal proofs is a virtue: for example, it means that one could
teach logic using this material.



                                                                                              113
10 Logic Beyond the Aristotle Border

10.2 Examples
We present a few examples of the proof system at work, along with comments pertaining
to the side conditions. Many of these are taken from the proof system R∗ for the language
RC of [?]. That system R∗ is among the strongest of the known syllogistic systems, and
so it is of interest to check the current proof system is at least as strong.



Example 10.2 Here is a proof of the classical syllogism Darii : ∀(b, d), ∃(c, b) ` ∃(c, d).
First, in Fitch-style:
                                 1   ∀(b, c)      hyp
                                 2   ∃(b, d)      hyp
                                 3   b(x)         ∃E, 2
                                 4   d(x)         ∃E, 2
                                 5   c(x)         ∀E, 1, 3
                                 6   ∃(c, d)      ∃I, 4, 5

and then in natural deduction:
                                 [b(x)]1 ∀(b, d)
                                                 ∀E
                                       d(x)           [c(x)]1
                                                              ∃I
                         ∃(c, b)              ∃(c, d)
                                                      ∃E 1
                                    ∃(c, d)




Example 10.3 Next we study a principle called (K) in Figure 6.2. Intuitively, if all
watches are expensive items, then everyone who owns a watch owns an expensive item. The
formal statement in our language is ∀(c, d) ` ∀(∃(c, r), ∃(d, r)). See Figure 10.4. We
present a Fitch-style proof on the left and the corresponding one in our formalism on
the right. One aspect of the Fitch-style system is that (∃E) gives two lines; see lines 3
and 4 on the left in Figure 10.4.




Example 10.4       Here is an example of a derivation using (RAA). It shows ∀(c, c) `
∀(d, ∀(c, r)).



114
                                                                               10.3 Soundness



    1   ∀(c, d)                     hyp                                    [c(y)]1 ∀(c, d)
                                                                                           ∀E
    2    x   ∃(c, r)(x)             hyp                       [r(x, y)]1         d(y)
                                                                                      ∃I
                                               [∃(c, r)(x)]2         ∃(d, r)(x)
                                                                                 ∃E 1
    3        c(y)                   ∃E, 2                 ∃(d, r)(x)
                                                                          ∀I 2
    4        r(x, y)                ∃E, 2             ∀(∃(c, r), ∃(d, r))

    5        d(y)                   ∀E, 1, 3
    6        ∃(d, r)(x)             ∃I, 4, 5
    7   ∀(∃(c, r), ∃(d, r))         ∀I, 1–6

                          Figure 10.4: Derivations in Example 10.3


                                     [c(y)]1 ∀(c, c)
                                                       ∀E
                                           c(y)             [c(y)]1
                                                                    ⊥I
                                                      ⊥
                                                            RAA
                                                   r(x, y)
                                                             ∀I 1
                          [d(x)]2                 ∀(c, r)(x)
                                                             ∀I 2
                                     ∀(d, ∀(c, r))




Example 10.5 As in Lemma 6.3.1, we have the rule of proof by cases: If Γ + ϕ ` ψ
and Γ + ϕ ` ψ, then Γ ` ψ.



10.3 Soundness
Before presenting a soundness result, it might be good to see an improper derivation.
Here is one, purporting to infer some men see some men from some men see some women:
                                           [s(x, x)]1 [m(x)]2
                                                              ∃I
                                               ∃(s, m)(x)           [m(x)]2
                                        2                                   ∃I
                            [∃(w, s)(x)]               ∃(m, ∃(m, s))
                                                                     ∃E 1
             ∃(m, ∃(w, s))                ∃(m, ∃(m, s))
                                                        ∃E 2
                           ∃(m, ∃(m, s))

The specific problem here is that when [s(x, x)] is withdrawn in the application of ∃I 1 ,
the variable x is free in the as-yet-uncanceled leaves labeled m(x).



                                                                                            115
10 Logic Beyond the Aristotle Border

   To state a result pertaining to the soundness of our system, we need to define the truth
value of a general sentence under a variable assignment. First, a variable assignment in
a model M is a function v : V → M , where V is the set of variable symbols and M is the
universe of M. We need to define M |= α[v] for general sentences α. If α is a sentence,
then M |= α[v] iff M |= α in our earlier sense. If α is b(x), then M |= α[v] iff [[b]](v(x)).
If α is r(x, y), then M |= α[v] iff [[r]](v(x), v(y)). If α is ⊥, then M 6|= ⊥ for all models
M.

Lemma 10.3.1 Let Π be any proof tree for this fragment all of whose nodes are labeled
with L-formulas, let ϕ be the root of Π, let M be a structure, let v : X → M be a variable
assignment, and assume that for all uncanceled leaves ψ of Π, M |= ψ[v]. Then also
M |= ϕ[v].

Proof By induction on Π. We shall only go into details concerning two cases. First,
consider the case when the root of Π is
                                                 [c(x)]      [r(t, x)]
                                                          ..
                                                           ..
                                ∃(c, r)(t)                α
                                             α               ∃E

To simplify matters further, let us assume that t is a variable. Let v be a variable
assignment making true all of the leaves of the tree, except possibly c(x) and r(t, x).
By induction hypothesis, M |= ∃(c, r)(t)[v]. Let a ∈ A witness this assertion. In the
obvious notation, [[c]](a) and [[r]](tM,v , a). Let w be the same variable assignment as v,
except that w(x) = a. Then since x is not free in any leaves except those labeled c(x)
and r(t, x), we have M |= ψ[w] for all those ψ. And so M |= α[w], using the induction
hypothesis applied to the subtree on the right. And since x is not free in the conclusion
α, we also have M |= α[v], as desired.
  Second, let us consider the case when the root is

                                    c(y)     ∀(c, r)(x)
                                                        ∀E
                                           r(x, y)

(That is, we are considering an instance of (∀E) when the terms t and u are variables.)
The variables x and y might well be the same. Let M be a structure, and v be a variable
assignment making true the leaves of the tree. By induction hypothesis, [[c]](v(y)) and
also [[r]](v(x), m)) for all m ∈ [[c]]. In particular, [[r]](v(x), v(y)).
   The remaining cases are similar.                                                   a


10.4 The Henkin property
The completeness of the logic parallels the Henkin-style completeness result for first-
order logic. Given a consistent theory Γ, we get a model of Γ in the following way:
(1) take the underlying language L, add constant symbols to the language to witness



116
                                                                    10.4 The Henkin property

existential sentences; (2) extend Γ to a maximal consistent set in the larger language;
and then (3) use the set of constant symbols as the carrier of a model in a canonical
way. In the setting of this chapter, the work is in some ways easier than in the standard
setting, and in some ways harder. There are more details to check, since the language has
more basic constructs. But one doesn’t need to take a quotient by equivalence classes,
and in other ways the work here is easier.
   Given two languages L and L0 , we say that L0 ⊇ L if every symbol (of any type)
in L is also a symbol (of the same type) in L0 . In this chapter, the main case is when
P(L) = P(L0 ), R(L) = R(L0 ), and K(L) ⊆ K(L0 ); that is, L0 arises by adding constants
to L.
   A theory in a language is just a set of sentences in it. Given a theory Γ in a language
L, and a theory Γ∗ in an extension L0 ⊇ L, we say that Γ∗ is a conservative extension
of Γ if for every ϕ ∈ L, if Γ∗ ` ϕ, then Γ ` ϕ.

Lemma 10.4.1 Let Γ be a consistent L-theory, and let j ∈
                                                       / K(L).

  (i) If ∃(c, d) ∈ Γ, then Γ + c(j) + d(j) is a conservative extension of Γ.

 (ii) If ∃(c, r)(j) ∈ Γ, then Γ + r(j, k) + c(k) is a conservative extension of Γ.


Proof For (1), suppose that Γ contains ∃(c, d) and that Γ + c(j) + d(j) ` ϕ. Let Π
be a derivation tree. Replace the constant j by an individual variable x which does not
occur in Π. The result is still a derivation tree, except that the leaves are not labeled by
sentences. (The reason is that our proof system has no rules specifically for constants,
only for terms which might be constants and also might be individual variables.) Call
the resulting tree Π0 . Now the following proof tree shows that Γ ` ϕ:

                                            [c(x)]         [d(x)]
                                                     ..
                                                      ..
                                  ∃(c, d)            ϕ
                                            ϕ              ∃E

The subtree on the right is Π0 . The point is that the occurrences of c(x) and d(x) have
been canceled by the use of ∃E at the root.
  This completes the proof of the first assertion, and the proof of the second is similar.
a


Definition An L-theory Γ has the Henkin property if the following hold:

  (i) If ∃(c, d) ∈ Γ, then for some constant j, c(j) and d(j) belong to Γ.

 (ii) If r is a literal of L and ∃(c, r)(j) ∈ Γ, then for some constant k, r(j, k) and c(k)
      belong to Γ.




                                                                                        117
10 Logic Beyond the Aristotle Border

Lemma 10.4.2 Let Γ be a consistent L-theory. Then there is some L∗ ⊃ L and some
L∗ -theory Γ∗ such that Γ∗ is a maximal consistent theory with the Henkin property.
Moreover, if s ∈ R(L), j ∈ K(L∗ ) and k ∈ K(L), and if s(j, k) ∈ Γ∗ , then j ∈ K(L).

Proof This is a routine argument, using Lemma 10.4.1. One dovetails the addition of
constants which is needed for the Henkin property together with the addition of sentences
needed to insure maximal consistency. The formal details would use Lemma 10.4.1 for
steps of the first kind, and for the second kind we need to know that if Γ is consistent,
then for all ϕ, either Γ + ϕ or Γ + ϕ is consistent. This follows from the derivable rule
of proof by cases; see Lemma 6.3.1 in Section 10.2.                                     a
  The last point in Lemma 10.4.2 states a technical property that will be useful in
Section 10.8.
  It might be worthwhile noting that the extensions produced by Lemma 10.4.2 add
infinitely many constants to the language.


10.5 Completeness via canonical models
In this section, fix a language L and a maximal consistent Henkin L-theory Γ. We
construct a canonical model M = M(Γ) as follows: M = K(L); [[p]](j) iff p(j) ∈ Γ;
[[s]](j, k) iff s(j, k) ∈ Γ; and [[j]] = j. That is, we take the constant symbols of the
language to be the points of the model, and the interpretations of the atoms are the
natural ones. Each constant symbol is interpreted by itself.

Lemma 10.5.1 For all set terms c, [[c]] = {j : c(j) ∈ Γ}.

Proof By induction on c. The base case of unary atoms p is by definition of M.
    Before we turn to the induction proper, here is a preliminary point. Assuming that
[[c]] = {j : c(j) ∈ Γ}, we check that [[c]] = {j : c(j) ∈ Γ}:

                     j ∈ [[c]]   iff   j∈
                                        / [[c]]   iff   c(j) ∈
                                                             /Γ   iff   c(j) ∈ Γ.

The last point uses the maximal consistency of Γ.
   Turning to the inductive steps, assume our result for c; we establish it for ∀(c, s) and
∃(c, s); it then follows from the preliminary point that we have the same fact for ∀(c, s)
and ∃(c, s).
   Let j ∈ [[∀(c, s)]]. We claim that ∀(c, s)(j) ∈ Γ. For if not, then ∃(c, s)(j) ∈ Γ. By
the Henkin property, let k be such that Γ contains c(k) and s(j, k). By the induction
hypothesis, k ∈ [[c]], and by the definition of M, [[s]](j, k) is false. Thus j ∈
                                                                                / [[∀(c, s)]]. This
is a contradiction.
   In the other direction, assume that ∀(c, s)(j) ∈ Γ; this time we claim that j ∈ [[∀(c, s)]].
Let k ∈ [[c]]. By induction hypothesis, Γ contains c(k). By (∀E), we see that Γ ` s(j, k).
Hence Γ contains s(j, k). So in M, [[s]](j, k). Since k was arbitrary, we see that indeed
j ∈ [[∀(c, s)]].



118
                                                             10.6 The finite model property

  The other induction step is for ∃(c, s). Let j ∈ [[∃(c, s)]]. We thus have some k ∈ [[c]]
such that [[s]](j, k). That is, s(j, k) ∈ Γ. Using (∃I), we have Γ ` ∃(c, s)(j); from this we
see that ∃(c, s)(j) ∈ Γ, as desired.
  Finally, assume that ∃(c, s)(j) ∈ Γ. By the Henkin condition, let k be such that Γ
contains c(k) and s(j, k). Using the derivation above, we have the desired conclusion
that j ∈ [[∃(c, s)]].
  This concludes the proof.                                                                 a


Lemma 10.5.2 M |= Γ.

Proof     We check the sentence types in turn. Throughout the proof, we shall use
Lemma 10.5.1 without mention.
  First, let Γ contain the sentence ∀(c, d). Let j ∈ [[c]], so that c(j) ∈ Γ. We have
d(j) ∈ Γ using (∀E). This for all j shows that M |= ∀(c, d).
  Second, let ∃(c, d) ∈ Γ. By the Henkin condition, let j be such that both c(j) and
d(j) belong to Γ. This element j shows that [[c]] ∩ [[d]] 6= ∅. That is, M |= ∃(c, d).
  Continuing, consider a sentence c(j) ∈ Γ. Then j ∈ [[c]], so that M |= c(j).
  Finally, the case of sentences r(j, k) ∈ Γ is immediate from the structure of the model.
a


Theorem 10.5.3 If Γ |= ϕ, then Γ ` ϕ.

Proof We rehearse the standard argument. Due to the classical negation, we need
only show that consistent sets Γ are satisfiable. Let L be the language of Γ, Let L0 ⊇ L
be an extension of L, and let Γ∗ ⊇ Γ be a maximal consistent theory in L0 with the
Henkin property (see Lemma 10.4.2). Consider the canonical model M(Γ∗ ) as defined
in this section. By Lemma 10.5.2, M(Γ∗ ) |= Γ∗ . Thus Γ∗ is satisfiable, and hence so is
Γ.                                                                                     a


10.6 The finite model property
Let Γ be a consistent finite theory in some language L. As we now know, Γ has a model.
Specifically, we have seen that there is some Γ∗ ⊇ Γ which is a maximal consistent theory
with the Henkin property in an extended language L∗ ⊇ L. Then we may take the set
of constant symbols of L∗ to be the carrier of a model of Γ∗ , hence of Γ. The model
obtained in this way is infinite. It is of interest to build a finite model, so in this section
Γ must be finite. The easiest way to see that Γ has a finite model is to recall that our
overall language is a sub-language of the two variable fragment FO2 of first-order logic.
And FO2 has the finite model property by Mortimer’s Theorem [?].
  However, it is possible to give a direct argument for the finite model property, along
the lines of filtration in modal logic (but with some differences). We sketch the result
here because we shall use the same method in Section 10.8 below to prove a finite model



                                                                                           119
                      10 Logic Beyond the Aristotle Border

                      property for our second logical system L(adj) with respect to its natural semantics; that
                      result does not follow from others in the literature.
                        Let M = M(Γ∗ ) be the canonical model as defined in Section 10.5. Let Sub(Γ) be
                      the collection of set terms occurring in any sentence in the original finite theory Γ. So
                      Sub(Γ) is finite, and if ∀(c, r) ∈ Sub(Γ) or ∃(c, r) ∈ Sub(Γ), then also c ∈ Sub(Γ). For
                      constant symbols j and k of L∗ , write j ≡ k iff the following conditions hold:

                        (i) If either j or k is a constant of L, then k = j.

                       (ii) For all c ∈ Sub(Γ), c(j) ∈ Γ iff c(k) ∈ Γ.


check the reference   Remark The equivalence relation ≡ may be defined on any structure. It is not neces-
                      sarily a congruence, as Example 5.1 shows. Specifically, we had constant symbols j and
                      k such that j ≡ k, and yet in our structure s(j, k) and s(k, j). In the case of M(Γ∗ ), we
                      have no reason to think that ≡ is a congruence. That is, the construction in Section 10.5
                      did not arrange for this.
                        Let N = {[k] : k ∈ K(L)} × {∀, ∃}. (We use ∀ and ∃ as tags to give two copies of the
                      quotient K/ ≡.) We endow N with an L-structure as follows:

                        (i) [[p]] = {([j], Q) : p(j) ∈ Γ∗ and Q ∈ {∀, ∃}}.

                       (ii) [[s]](([j], Q), ([k], Q0 )) iff one of the following two conditions holds:
                              a) There is a set term c such that Γ∗ contains c(k) and ∀(c, s)(j).
                              b) Q0 = ∃, and for some j∗ ≡ j and k∗ ≡ k, Γ∗ contains s(j∗ , k∗ ).

                       (iii) For a constant j of L, [[j]] = ([j], ∃). (Of course, [j] is the singleton set {j}.)

                          Before going on, we note that the first of the two alternatives in the definition of
                      [[s]](([j], Q), ([k], Q0 )) is independent of the choice of representatives of equivalence classes.
                      And clearly so is the second alternative.
                          We shall write N for the resulting L-structure, hiding the dependence on Γ and Γ∗ .

                      Lemma 10.6.1 For all c ∈ Sub(Γ), [[c]] = {([j], Q) : c(j) ∈ Γ∗ and Q ∈ {∀, ∃}}.

                      Proof By induction on set terms c. We are not going to present any of the details here
                      because in Lemma 10.8.3 below, we shall see all the details on a more involved result.
                      a

                      Lemma 10.6.2 N |= Γ.

                      Proof Again we only highlight a few details, since the full account is similar to what
                      we saw in Lemma 10.5.2, and to what we shall see in Lemma 10.8.4. One would check
                      the sentence types in turn, using Lemma 10.6.1 frequently. We want to go into details
                      concerning sentences in Γ of the form s(j, k) or s(j, k). Recall that we are dealing in this



                      120
                                                                 10.7 Adding transitivity: L(adj)

result with sentences of L, and so j and k are constant symbols of that language. Also
recall that [[j]] = ([j], ∃), and similarly for k.
  First, consider sentences in Γ of the form s(j, k). By the definition of [[s]], we have

                                    [[s]](([j], ∃), ([k], ∃)).

By the way binary atoms and constants are interpreted in N, we have N |= s(j, k), as
desired.
  We conclude with the consideration of a sentence in Γ of the form s(j, k). We wish
to show that N |= s(j, k). Suppose towards a contradiction that N |= s(j, k). Then we
have [[s]](([j], ∃), ([k], ∃)). There are two possibilities, corresponding to the alternatives
in the semantics of s. The first is when there is a set term c such that Γ∗ contains c(k)
and ∀(c, s)(j). By (∀E), Γ∗ then contains s(j, k). But recall that Γ contains s(j, k). So
in this alternative, Γ∗ ⊇ Γ is inconsistent. In the second alternative, there are j∗ ≡ j
and k∗ ≡ k such that s(j∗ , k∗ ) ∈ Γ∗ . But recall that the equivalence classes of constant
symbols from the base language L are singletons. Thus in this alternative, j∗ = j and
k∗ = k; hence s(j, k) ∈ Γ∗ . But then again Γ∗ is inconsistent, a contradiction.             a

Theorem 10.6.3 (Finite Model Property) If Γ is consistent, then Γ has a model of
size at most 22n , where n is the number of set terms in Γ.

Complexity notes. Theorem 10.6.3 implies that the satisfiability problem for our lan-
guage is in NExpTime. We can improve this to an ExpTime-completeness result by
quoting the work of others. Pratt-Hartmann [?] defines a logic called E2 and showed that
the complexity of its satisfiability problem is ExpTime-complete. E2 corresponds to a
fragment of first-order logic, and it is somewhat bigger than the language L. (It would
correspond to adding converses to the binary atoms in L, as we mention at the very end
of this chapter.) Since satisfiability for E2 is ExpTime-complete, the same problem for
L is in ExpTime.
   A different way to obtain this upper bound is via the embedding into Boolean modal
logic which we saw in Section ??. For this, see Theorem 7 of Lutz and Sattler [?]. We
shall use an extension of that result below in connection with an extension L(adj) of L.
   The ExpTime-hardness for L follows from Lemma 6.1 in [?]. That result dealt with
a language called R† , and R† is a sub-language of L.


10.7 Adding transitivity: L(adj)
Before going further, let us briefly recapitulate the overall problem of this chapter and
point out where we are and what remains to be done. We aim to formalize a fragment
of first-order logic in which one may represent arguments as complex as that in (10.1) in
the Introduction. We are especially interested in decidable systems, and so the systems
must be weaker than first-order logic. We presented in Section 10 a language L and
a proof system for it. Validity in the logic cannot be captured by a purely syllogistic
proof system, and so our proof system uses variables. But the use is very special and



                                                                                             121
10 Logic Beyond the Aristotle Border

restricted. The proof system is complete and decidable in exponential time. To our
knowledge, it is the first system with these properties.
  There are a number of ways in which one can go further. In this section, we want to
explore one such way, connected to the example in (10.1) below:
       Every sweet fruit is bigger than every ripe fruit
       Every pineapple is bigger than every kumquat
                                                                                    (10.1)
       Every non-pineapple is bigger than every unripe fruit
       Every fruit bigger than some sweet fruit is bigger than every kumquat
One key feature of this example is that comparative adjectives such as bigger than are
transitive. This is true for all comparative adjectives.
   We extend our language L to a language L(adj) by taking a basic set A of comparative
adjective phrases in the base. The proof system simply extends the one we have already
seen with a rule corresponding to the transitivity of comparatives. Our completeness
result, Theorem 10.5.3, extends to the new setting. The next section does this. The
decidability of the language is a more delicate matter than before, since it does not
follow from Mortimer’s Theorem [?] on the finite model property for FO2 . Indeed,
adding transitivity statements to FO2 renders the logic undecidable, as shown in Grädel,
Otto, and Rosen [?]. Instead, one could use Theorem 12 of Lutz and Sattler [?] on the
decidability of a variant on Boolean modal logic in which some of the relations are taken
to be transitive. This would indeed give the ExpTime-completeness of L(adj) with
our semantics. However, we have decided to present a direct proof for several reasons.
First, Lutz and Sattler’s result does not give a finite model property, and our result
does do this. Second, our argument is shorter. Finally, our treatment connects to modal
filtration arguments and is therefore different; [?] uses automata on infinite trees and is
based on Vardi and Wolper [?].
   I do not wish to treat the transitivity of comparison with adjectives as an enthymeme
(missing premise) because the transitivity seems more fundamental, more ‘logical’ some-
how. Hence it should be treated on a deeper level. The decidability considerations give a
supporting argument: if we took the transitivity to be a meaning postulate, then it would
seem that the underlying language would have to be rich enough to state transitivity.
This requires three universal quantifiers. For other reasons, we want our languages to
be closed under negation. It thus seems very likely that any logical system with these
properties is going to be undecidable. The upshot is a system in which the transitivity
turns out to be a proof postulate rather than a meaning postulate. We turn to the system
itself.

Syntax and semantics. We start with four pairwise disjoint sets A (for comparative
adjective phrases) and the three that we saw before: P, R, and K. We use a as a
variable to range over A in our statement of the syntax and the rules.
  For the syntax, we take elements a ∈ A to be binary atoms, just as the elements s ∈ R
are. Thus, the binary literals are the expressions of the form s, s, a, or a.
  The syntax is the same as before, except that we allow the binary atoms to be elements
of A in addition to elements of R. So in a sense, we have the same syntax is before,



122
                                                              10.7 Adding transitivity: L(adj)

except that some of the binary atoms are taken to render transitive verbs, and some are
taken to render comparative adjective phrases. The only difference is in the semantics.
Here, we require that (in every model M) for an adjective a ∈ A, [[a]] must be a transitive
relation.

Proof system. We adopt the same proof system as in Figure 10.3, but with one addi-
tion. This addition is the rule for transitivity:

                                  a(t1 , t2 ) a(t2 , t3 )
                                                          trans
                                         a(t1 , t3 )

This rule is added for all a ∈ A.



Example 10.6 We have seen an informal example in (10.1) at the beginning of this
chapter. At this point, we can check that our system does indeed have a derivation
corresponding to this. We need to check that Γ ` ϕ, where Γ contains

      ∀(sw, ∀(ripe, bigger)), ∀(pineapple, ∀(kq, bigger)), ∀(pineapple, ∀(ripe, bigger)),

and ϕ is
                               ∀(∃(sw, bigger), ∀(kq, bigger)).
(We are going to use kq as an abbreviation of kumquat for typographical convenience,
and similarly for sw and sweet.)




Example 10.7 The example at the beginning of this chapter cannot be formalized
in this fragment because the correct reasoning uses the transitivity of is bigger than.
However, we can prove a result which may itself be used in a formal proof of (10.1):

                   Every sweet fruit is bigger than every ripe fruit
                   Every pineapple is bigger than every kumquat
                                                                                            (10.2)
                   Every non-pineapple is bigger than every unripe fruit
                   Every sweet fruit is bigger than every kumquat

To discuss this, we take the set P of unary atoms to be

                        P    =      {sweet, ripe, pineapple, kumquat}.

We also take R = {bigger} and K = ∅. Figure 10.5 contains a derivation showing (10.2),
done in the manner of Fitch [?]. The main way in which we have bent the English in
the direction of our formalism is to use the bar notation on the nouns. The main reason
for presenting the derivation as a Fitch diagram is that the derivation given as a tree



                                                                                              123
                       10 Logic Beyond the Aristotle Border


                                1       Every sweet fruit is bigger than every ripe fruit   hyp
                                2       Every pineapple is bigger than every kumquat        hyp
                                3       Every pineapple is bigger than every ripe fruit     hyp
                                4       x   x is a sweet fruit                              hyp
                                5           x is bigger than every ripe fruit               ∀E, 1, 4
                                6               x is a pineapple                            hyp
                                7               x is bigger than every kumquat              ∀E, 2, 6
                                8               x is a pineapple                            hyp
                                9               x is bigger than every ripe fruit           ∀E, 3, 8
                                10              y   y is a kumquat                          hyp
                                11                      y is a ripe fruit                   hyp
                                12                      x is bigger than y                  ∀E, 5, 11
                                13                      y is a ripe fruit                   hyp
                                14                      x is bigger than y                  ∀E, 9, 13
                                15                  x is bigger than y                      cases, 13–14, 11–12
                                16              x is bigger than every kumquat              ∀I, 10–15
                                17          x is bigger than every kumquat                  cases, 6–7, 8–16
                                18      Every sweet fruit is bigger than every kumquat      ∀I, 4–17


                                    Figure 10.5: A derivation corresponding to the argument in (10.2).




                       (as demanded by our definitions) would not fit on a page. This is because the cases rule
                       is not a first-class rule in the system, it is a derived rule (see Lemma 6.3.1). Our Fitch
                       diagram pretends that the system has a rule of cases. Another reason to present the
                       derivation as in Figure 10.5 is to make the point that the treatment in this chapter is a
                       beginning of a formalization of the work that Fitch was doing.


check all the refer-     In Figure 10.5, we see that Γ ` ∀(sweet, ∀(kq, bigger)). (The a derivation was presented
ences on this          using a format which could be converted to our official format of natural deduction trees.)
                       That work used R = {bigger}, but here we want R = ∅ and A = {bigger}. The same



                       124
                                                     10.8 L(adj) has the finite model property

derivation works, of course. Transitivity enables us to obtain a derivation for (10.1):
                                                                              ..
                                                                               ..
                                                          [sw(y)]2 ∀(sw, ∀(kq, bigger))
                                                                                        ∀E
                                              [kq(z)]1           ∀(kq, bigger)(y)
                                          2                                       ∀E
                             [bigger(x, y)]                bigger(y, z)
                                                                        trans
                                            bigger(x, z)
                                                           ∀I 1
        [∃(sw, bigger)(x)]3               ∀(kq, bigger)(x)
                                                           ∃E 2
                        ∀(kq, bigger)(x)
                                                     3
                                                  ∀I
                  ∀(∃(sw, bigger), ∀(kq, bigger))




  Adding the transitivity rule gives a sound and complete proof system for the semantic
consequence relation Γ |= ϕ. The soundness is easy, and so we only sketch the complete-
ness. We must show that a set Γ which is consistent in the new logic has a transitive
model. The canonical model M(Γ) as defined in Section 10.5 is automatically transitive;
this is immediate from the transitivity rule. And as we know, it satisfies Γ.


10.8 L(adj) has the finite model property
Our final result is that L(adj) has the finite model property. We extend the work in
Section 10.6. The inspiration for our definitions comes from the technique of filtration
in modal logic, but we shall not refer explicitly to this area.
   We again assume that Γ is consistent, and Γ∗ has the properties of Lemma 10.4.2.

Definition For a ∈ A, we say that j reaches k (by a chain of ≡ and a statements) if
there is a sequence

                      j = j0 ≡ k0 ,      j1 ≡ k1 ,       ...,   j n ≡ kn = k                 (10.3)

such that n ≥ 1, and Γ∗ contains a(k0 , j1 ), . . ., a(kn−1 , jn ).

Lemma 10.8.1 Assume that j reaches k by a chain of ≡ and a statements.

  (i) If c(k) ∈ Γ∗ , then Γ∗ contains ∃(c, a)(j).

 (ii) If j, k ∈ K(L), then Γ∗ contains a(j, k).


Proof By induction on n ≥ 1 in (10.3). For n = 1, we have essentially seen the
argument as a step in Lemma 10.6.1. Here it is again. Since c(k1 ) and j1 ≡ k1 , we see
that c(j1 ). Together with s(k0 , j1 ), we have ∃(c, a)(k0 ). And as j0 ≡ k0 , we see that
∃(c, a)(j0 ).



                                                                                               125
                     10 Logic Beyond the Aristotle Border

                       Assume our result for n, and now consider a chain as in (10.3) of length n + 1. The
                     induction hypothesis applies to

                                          j = j1 ≡ k1 ,         j2 ≡ k2 ,       ...,     jn+1 ≡ kn+1 = k

                     and so we have ∃(c, a)(j1 ). Since a(k0 , j1 ), we easily have ∃(c, a)(k0 ) by transitivity. And
                     as j0 ≡ k0 , we have ∃(c, a)(j0 ).
                       The second assertion is also proved by induction on n ≥ 1. For n = 1, we have
                     j = j0 ≡ k0 , Γ∗ contains a(k0 , j1 ); and j1 ≡ k1 = k. Then since the ≡ is the identity on
                     K(L), j = j0 = k0 , and j1 = k1 = k. Hence Γ∗ contains s(j, k). Assuming our result for
                     n, we again consider a chain as in (10.3) of length n + 1. Just as before, j = j0 = k0 , and
                     so Γ∗ contains a(j, j1 ). By induction hypothesis, Γ∗ contains a(j1 , k). By transitivity,
                     Γ∗ contains a(j, k).                                                                           a
Is ’itemize’ right     We endow N with an L-structure as follows:
for this?
                           [[p]] = {([j], Q) : p(j) ∈ Γ∗ and Q ∈ {∀, ∃}}.

                           [[s]](([j], Q), ([k], Q0 )) iff one of the following two conditions holds:
                            (i) There is a set term c such that Γ∗ contains c(k) and ∀(c, s)(j).
                            (ii) Q0 = ∃, and for some j∗ ≡ j and k∗ ≡ k, Γ∗ contains s(j∗ , k∗ ).

                           [[a]](([j], Q), ([k], Q0 )) iff
                            (i) If ∀(c, a)(k) ∈ Γ∗ , then also ∀(c, a)(j) ∈ Γ∗ .
                            (ii) In addition, either (a) or (b) below holds:
                                   a) There is a set term c such that Γ∗ contains c(k) and ∀(c, a)(j).
                                   b) Q0 = ∃, and j reaches k by a chain of ≡ and a statements.
                           (Notice that this definition is independent of the representatives in [j] and [k].)

                           For a constant j of L, [[j]] = ([j], ∃).
                       Once again, we suppress Γ and Γ∗ and simply write N for the resulting L-structure.

                     Lemma 10.8.2 For a ∈ A, each relation [[a]] is transitive in N.

???                  Proof In this proof and the next , we are going to use l to stand for a constant symbol,
                     even though earlier in the chapter we used it for a literal. Assume that

                                                        ([j], Q) [[a]] ([k], Q0 ) [[a]] ([l], Q00 ).          (10.4)

                     Clearly we have the first requirement concerning [[a]]: if ∀(c, a)(l) ∈ Γ∗ , then also
                     ∀(c, a)(j) ∈ Γ∗ .
                        We have four cases, depending on the reasons for the two assertions in (10.4).
                        Case 1 There is a set term b such that Γ∗ contains b(k) and ∀(b, a)(j), and there is
                     also a set term c such that Γ∗ contains c(l) and ∀(c, a)(k). By (1), Γ∗ contains c(l) and
                     ∀(c, a)(j). And so we have requirement (2a) concerning [[a]] for ([j], Q) and ([l], Q00 ).



                     126
                                                            10.8 L(adj) has the finite model property

   Case 2 There is a set term b such that Γ∗ contains b(k) and ∀(b, a)(j), and k reaches
l. Note that a(j, k). So j reaches l.
   Case 3 j reaches k by a chain of ≡ and a statements, and there is a set term c such
that Γ∗ contains c(l) and ∀(c, a)(k). Then a(k, l). And so j reaches l.
   Case 4 j reaches k, and k reaches l. Then concatenating the chains shows that j
reaches l.                                                                             a


Lemma 10.8.3 For all c ∈ Sub(Γ), [[c]] = {([j], Q) : c(j) ∈ Γ∗ and Q ∈ {∀, ∃}}.

Proof We argue by induction on c. Much of the proof is as in Lemma 10.6.1, For c
a unary atom, the result is obvious. Also, assuming that [[c]] = {([j], Q) : c(j) ∈ Γ∗ } we
easily have the same result for c using the maximal consistency of Γ∗ :

             ([j], Q) ∈ [[c]]   iff      ([j], Q) ∈
                                                  / [[c]]   iff        / Γ∗
                                                                  c(j) ∈      iff   c(j) ∈ Γ∗ .

  Assume about c that if c ∈ Sub(Γ), then [[c]] = {([j], Q) : c(j) ∈ Γ∗ }. In view of what
we just saw, we only need to check the same result for ∀(c, s), ∃(c, s), ∀(c, a), and ∃(c, a).


∀(c, s) Suppose that ∀(c, s) ∈ Sub(Γ), so that c ∈ Sub(Γ) as well. We prove that

                           [[∀(c, s)]]      =     {([j], Q) : ∀(c, s)(j) ∈ Γ∗ }.

Let ([j], Q) ∈ [[∀(c, s)]]. We shall show that ∀(c, s)(j) ∈ Γ∗ . If not, then by maximal
consistency, ∃(c, s)(j) ∈ Γ∗ . By the Henkin property, let k be such that Γ∗ contains c(k)
and s(j, k). By induction hypothesis, ([k], ∀) ∈ [[c]]. And so ([j], ∀)[[s]]([k], ∀). Thus there
is a set term b such that Γ∗ contains b(k) and ∀(b, s)(j). From these, Γ∗ contains s(j, k).
And thus Γ∗ is inconsistent. This contradiction shows that indeed ∀(c, s)(j) ∈ Γ∗ .
    In the other direction, suppose that ([j], Q) is such that ∀(c, s)(j) ∈ Γ∗ . Let ([k], Q0 ) ∈
[[c]], so by induction hypothesis, c(k) ∈ Γ∗ . By the way we interpret binary relations in
N, [[s]](([j], Q), ([k], Q0 )). This for all ([k], Q0 ) ∈ [[c]] shows that ([j], Q) ∈ [[∀(c, s)]].


∃(c, s) Suppose that ∃(c, s) ∈ Sub(Γ), so that c ∈ Sub(Γ) as well. Let ([j], Q) ∈
[[∃(c, s)]]. Let k and Q0 be such that [[c]]([k], Q0 ) and [[s]](([j], Q), ([k], Q0 )). By induction
hypothesis, c(k) ∈ Γ∗ . First, let us consider the case when Q0 = ∀. Let b be such that
Γ∗ contains b(k) and ∀(b, s)(j). Using (∀E), we have Γ∗ ` ∃(c, s)(j). And as Γ∗ is closed
under deduction, ∃(c, s)(j) ∈ Γ∗ as desired. The more interesting case is when Q0 = ∃,
so that for some j∗ ≡ j and k∗ ≡ k, Γ∗ contains s(j∗ , k∗ ). Since c(k) and k ≡ k∗ , we
have c(k∗ ) ∈ Γ∗ . Then using (∃I), we see that ∃(c, s)(j∗ ) ∈ Γ∗ . Since j ≡ j∗ , once again
we have ∃(c, s)(j) ∈ Γ∗ .
    Conversely, suppose that ∃(c, s)(j) ∈ Γ∗ . By the Henkin property, let k be such that
c(k) and s(j, k) belong to Γ∗ . Then [[s]](([j], Q), ([k], ∃)), and by induction hypothesis,
[[c]](k). Hence ([j], Q) ∈ [[∃(c, s)]].



                                                                                                  127
10 Logic Beyond the Aristotle Border

∀(c, a)   Suppose that ∀(c, a) ∈ Sub(Γ), so that c ∈ Sub(Γ) as well. We prove that

                          [[∀(c, a)]]   =   {([j], Q) : ∀(c, a)(j) ∈ Γ∗ }.

The first part argument is the left-to-right inclusion. It is exactly the same as what we
saw above for the sentences of the form ∀(c, s).
  In the other direction, suppose that ∀(c, a)(j) ∈ Γ∗ ; we show that ([j], Q) ∈ [[∀(c, a)]].
For this, let ([k], Q0 ) ∈ [[c]]. By induction hypothesis, c(k) ∈ Γ∗ . We must verify that if
∀(b, a)(k) ∈ Γ∗ , then also ∀(b, a)(j) ∈ Γ∗ . This is shown in the derivation below:

                         c(k)     ∀(c, a)(j)       [b(x)]1 ∀(b, a)(k)
                                             ∀E                         ∀E
                                a(j, k)                   a(k, x)
                                                                  trans
                                             a(j, x)
                                                       ∀I 1
                                           ∀(b, a)(j)

Since Γ∗ is closed under deduction, we see that indeed ∀(b, a)(j) ∈ Γ∗ . Going on, we see
from the structure of N that [[s]](([j], Q), ([k], Q0 )). This for all ([k], Q0 ) ∈ [[c]] shows that
([j], Q) ∈ [[∀(c, a)]].

∃(c, a) Suppose that ∃(c, a) ∈ Sub(Γ), so that c ∈ Sub(Γ) as well.
    Let ([j], Q) ∈ [[∃(c, a)]]. Let k and Q0 be such that the following two assertions hold:
[[a]](([k], Q0 ) and [[a]](([j], Q), ([k], Q0 )). By induction hypothesis, c(k) ∈ Γ∗ . There are
two cases depending on whether Q0 = ∀ or Q0 = ∃. The argument for Q0 = ∀ is the same
as the one we saw in our work on sentences ∃(c, s) above. The more interesting case is
when Q0 = ∃. This time, j reaches k. By Lemma 10.8.1, ∃(c, a)(j) ∈ Γ∗ .
    Conversely, suppose that ∃(c, a)(j) ∈ Γ∗ . By the Henkin property, let k be such that
c(k) and a(j, k) belong to Γ∗ . The derivation below shows that if ∀(d, a)(k) ∈ Γ∗ , then
∀(d, a)(j) ∈ Γ∗ as well:
                                               [d(x)]1 ∀(d, a)(k)
                                                                   ∀E
                                    a(j, k)          a(k, x)
                                                             trans
                                             a(j, x)
                                                       ∀I 1
                                           ∀(d, a)(j)
So [[a]](([j], Q), ([k], ∃)), and by induction hypothesis, [[c]](k). Hence ([j], Q) ∈ [[∃(c, a)]].
This completes the induction.                                                                     a

Lemma 10.8.4 N |= Γ.

Proof We check the sentence types in turn, using Lemma 10.8.3 without mention.
    First, let Γ contain the sentence ∀(b, c). Then b and c belong to Sub(Γ). Let ([j], Q) ∈
[[b]], so that b(j) ∈ Γ∗ . We have d(j) ∈ Γ∗ using (∀E). This for all ([j], Q) shows that
N |= ∀(b, c).
    Second, let ∃(c, d) ∈ Γ. By the Henkin property, let j be such that both c(j) and d(j)
belong to Γ∗ . The element ([j], ∀) shows that [[c]] ∩ [[d]] 6= ∅. That is, N |= ∃(c, d).



128
                                                10.8 L(adj) has the finite model property

   Continuing, consider a sentence b(j) ∈ Γ. As b ∈ Sub(Γ), we have ([j], ∃) ∈ [[b]], so
that N |= b(j).
   The work for sentences of the forms s(j, k) and s(j, k) was done in Lemma 10.6.2.
   The most intricate part of this proof concerns sentences a(j, k), a(j, k) ∈ Γ. Recall that
we are dealing in this result with sentences of L, and so j and k are constant symbols
of that language. Also recall that [[j]] = ([j], ∃), and similarly for k.
   Consider sentences in Γ of the form a(j, k). It is easy to see that if ∃(c, a)(k) belongs
to Γ, then so does ∃(c, a)(j). (See the ∃(c, a) case in Lemma 10.8.3.) From this it follows
easily that [[a]]([[j]], [[k]]). And so N |= a(j, k) in this case.
   We conclude with the consideration of a sentence in Γ of the form a(j, k). We wish
to show that N |= a(j, k). Suppose towards a contradiction that N |= a(j, k). Then we
have [[a]](([j], ∃), ([k], ∃)). There are two possibilities, corresponding to the alternatives
in the semantics of a. The first is when there is a set term c such that Γ∗ contains c(k)
and ∀(c, a)(j). Using (∀E), Γ∗ then contains a(j, k). But recall that Γ contains a(j, k).
So in this alternative, Γ∗ ⊇ Γ is inconsistent. In the second alternative, j reaches k by a
chain of ≡ and a statements. By Lemma 10.8.1, a(j, k) ∈ Γ∗ . So Γ∗ is inconsistent, and
we have our contradiction.                                                                   a
   Once again, this gives us the finite model property for L(adj). The result is not
interesting from a complexity-theoretic point of view, since we already could see from
Lutz and Sattler [?] that the logic had an ExpTime satisfiability problem.




                                                                                          129
11 Complexity Results
In this section, we study the computational complexity of the logical systems with which
we have been concerned. We are mainly interested in the complexity of the consequence
relation, that is
                           {(Γ, ϕ) : Γ is a finite set, and Γ ` ϕ}.
  Recall that we defined syllogistic proof systems in Section 9.1. Derivation relations
defined by direct proof-systems are easily seen to have polynomial-time complexity.

Lemma 11.0.5 Let F be a syllogistic fragment, and X a finite set of syllogistic rules in
F. The problem of determining whether Θ `X θ, for a given set of F-formulas Θ and
F-formula θ, is in PTime.

Proof Let Σ be the set of all atoms (unary or binary) occurring in Θ ∪ {θ}, together
with one additional binary atom r. We first observe that, if there is a derivation of
θ from Θ using the rules X, then there is such a derivation involving only the atoms
occurring in Σ. For, given any derivation of θ from Θ, uniformly replace any unary atom
that does not occur in Θ ∪ {θ} with one that does. Similarly, uniformly replace any
binary atom which does not occur in Θ ∪ {θ} with one which does (or with r in case
Θ ∪ {θ} contains no binary atoms). This process obviously leaves us with a derivation
of θ from Θ, using the rules X.
   To prove the lemma, let the the total number of symbols occurring in Θ ∪ {θ} be
n. Certainly, |Σ| ≤ n. Let X comprise k1 proof-rules, each of which contains at most
k2 atoms (unary or binary). The number of rule instances involving only atoms in Σ
is bounded by p(n) = k1 nk2 . Hence, we need never consider derivations with ‘depth’
greater than p(n). Let Θi be the set of formulas involving only the atoms in Σ, and
derivable from Θ using a derivation of depth i or less (0 ≤ i ≤ p(n)). Evidently,
|Θi | ≤ |Θ| + p(n). It is then straightforward to compute the successive Θi in total time
bounded by a polynomial function of n.                                                  a


Theorem 11.0.6 (McAllester and Givan [?]) The satisfiability problem for a se-
quent Γ in RC is NPTime-complete. (Thus the validity problem is co-NPTime-complete.)


Proof It follows from the proof of Theorem 6.3.4, that if Γ is a satisfiable theory in
RC, then Γ has a model whose size is at most 2n, where n is the number of positive set
terms in the language. (This bound is independent of Γ.) It follows that satisfiability is
in NPTime. The main work is in showing the NPTime-hardness.



                                                                                      131
11 Complexity Results

   Our proof is a small variation on the original argument. We use a reduction from the
monotone exactly-1 3SAT problem. This problem is defined as follows. We are given a
conjunction of 3-CNF clauses without negation, so each clause is of the form U ∨ V ∨ W .
The problem is to find a truth assignment f to the variables making one variable in each
clause T and the other two variables F. We call this a 1-valued assignment on S. This
problem was shown to be NPTime-complete in Schaefer [?].
   Consider a sentence S which is a conjunction of clauses, each of which is a disjunction
of three variables without negation. We define an RC-theory Γ = Γ(S) via two clauses
below. It uses unary atoms which correspond to the variables of S: we use u to correspond
with U , etc. Γ also uses a number of new unary and binary atoms. It is defined as follows:

  (i) For each clause of S, say c ≡ U ∨ V ∨ W , add to Γ the seven sentences

                                  ∀(xc , ∀(u, rc1 ))       ∀(zc , ∀(w, rc3 ))
                                  ∀(∃(u, rc1 ), yc )       ∀(∃(w, rc3 ), ac )
                                  ∀(yc , ∀(v, rc2 ))       ∃(xc , ac )
                                  ∀(∃(v, rc2 ), zc )

      Here xc , yc , zc and ac are new unary atoms, and r21 , rc2 , and rc3 are new binary
      atoms.

 (ii) Let P and Q be any two distinct variables which occur together in some clause c.
      Then add to Γ the sentence
                                                               0
                                          ∀(∀(p, rp,q ), ∃(q, rp,q ))
                     0
      Here rp,q and rp,q are new binary atoms.

So if S has k clauses, then the first point will add4k new unary atoms and 3k new binary
atoms. The second clause will add at most 2 · 3k                2
                                                   2 < 18k new binary atoms. We assume
that all of the atoms listed are distinct.
   The main claim is that S has a 1-valued assignment iff Γ is satisfiable. In one direction,
assume that M |= Γ. Define a truth assignment f by f (U ) = F iff [[u]] 6= ∅. Consider a
clause c ≡ U ∨ V ∨ W of S. If f (U ) = f (V ) = f (W ) = F, then [[u]], [[v]], and [[w]] are all
non-empty. By the first six points in (1), [[xc ]] ⊆ [[yc ]] ⊆ [[zc ]] ⊆ [[ac ]]. But this contradicts
the last point in (1). Thus we know that at least one variable in c is assigned the value
T by f . We claim that only one variable can be T. For suppose towards a contradiction
that (for example) f (U ) = f (V ) = T. Then [[u]] = [[v]] = ∅. So [[∀(u, rp,q )]] = M and
        0 )]] = ∅. By the sentence in (2), M is empty. But this is impossible, since as
[[∃(v, rp,q
soon as S has at least one clause, Γ has an existential assertion via (1). In this way, f is
1-valued on S.
   We conclude by checking the converse assertion. Suppose f is 1-valued on S. We must
find a model M |= Γ. Let M be the set of variables U such that f (U ) = F. For a variable
X, define [[x]] = ∅ if f (X) = T, and [[x]] = {x} if f (X) = F. We still need to define the
interpretations of all of the binary atoms, and all of the other unary atoms. Suppose
that P and Q are distinct variables which happen to belong to the same clause. We



132
know that either f (P ) = F or f (Q) = F (or both). In the first case, set [[rp,q ]] = ∅ so that
[[∀(p, rp,q )]] = ∅. (The interpretation of rp,q  0 is arbitrary in this case; we no longer mention

this point.) This makes M |= ∀(∀(p, rp,q ), ∃(q, rp,q        0 )). In the second case, [[r 0 ]] = M × M ,
                                                                                          p,q
so that [[∃(q, rp,q )]] = M . In this way, the sentence in (2) holds in M.
                     0

   Finally, we consider the sentences in (1). If f (U ) = T, f (V ) = F, and f (W ) = F,
then we already have [[u]] = ∅, [[v]] = {v}, and [[w]] = {w}. We set [[xc ]] = M , [[yc ]] = ∅,
[[zc ]] = ∅, [[ac ]] = {w}, [[rc1 ]] = M × M , [[rc2 ]] = ∅, and [[rc3 ]] = {(w, w)}.
   If f (U ) = F, f (V ) = T, and f (W ) = F, set [[xc ]] = M , [[yc ]] = M , [[zc ]] = {w},
[[ac ]] = {w}, [[rc1 ]] = M × M , [[rc2 ]] = ∅, and [[rc3 ]] = {(w, w)}.
   If f (U ) = F, f (V ) = F, and f (W ) = T, set [[xc ]] = M , [[yc ]] = M , [[zc ]] = M , [[ac ]] = ∅,
[[rc ]] = M × M , [[rc2 ]] = M × M , and [[rc3 ]] = ∅.
   1

   In all cases, the resulting model M satisfies all sentences in (1), hence all sentences in
Γ.                                                                                                     a


Lemma 11.0.7 (Pratt-Hartmann and Moss [?]) The problem of determining the
validity of a sequent in R† is ExpTime-hard.

Proof The logic K U is the basic modal logic K together with an additional modal-
ity U (for “universal”), whose semantics are given by the standard relational (Kripke)
semantics, plus

                         |=w U ϕ if and only if |=w0 ϕ for all worlds w0 .

The satisfiability problem for K U is ExpTime-hard. (The proof is an easy adaptation of
the corresponding result for propositional dynamic logic; see, e.g. Harel et al. [?]: 216 ff.)
It suffices, therefore, to reduce this problem to satisfiability in R† . Let ϕ be a formula
of K U .
   We first transform ϕ into an equisatisfiable set of formulas Tϕ ∪ Sϕ of first-order logic;
then we translate the formulas of Tϕ ∪ Sϕ into an equisatisfiable set of R† -formulas.
To simplify the notation, we shall take unary atoms (in R† ) to be unary predicates (in
first-order logic); similarly, we take binary atoms to do double duty as binary predicates.
Let r and e be binary atoms. For any K U -formula ψ, let pψ be a unary atom, and define
the set of first-order formulas Tψ inductively as follows:

               Tp = ∅ (where p is a proposition letter)
                         Tψ ∪ Tπ ∪ {∀x(pψ (x) ∧ pπ (x) → pψ∧π (x)),
            Tψ∧π =
                                 ∀x(pψ∧π (x) → pψ (x)), ∀x(pψ∧π (x) → pπ (x))}
             T¬ψ    = Tψ ∪ {∀x(p¬ψ (x) → ¬pψ (x)), ∀x(¬p¬ψ (x) → pψ (x))}
                         Tψ ∪ {∀x(p2ψ (x) → ∀y(¬pψ (y) → ¬r(x, y))),
             T2ψ =
                                 ∀x(¬p2ψ (x) → ∃y(¬pψ (y) ∧ r(x, y)))}
                         Tψ ∪ {∀x(pU ψ (x) → ∀y(¬pψ (y) → ¬e(x, y))),
             TU ψ =
                                 ∀x(¬pU ψ (x) → ∃y(¬pψ (y) ∧ e(x, y)))}.



                                                                                                    133
11 Complexity Results

Now let Sϕ be the collection of five first-order formulas

             ∃x(pϕ (x) ∧ pϕ (x)),       ∀x(±pϕ (x) → ∀y(±pϕ (y) → e(x, y))).

(Although the first formula looks like it has a redundant conjunct, we state it in this
way only to make our work below a little easier.) We claim that the modal formula ϕ is
satisfiable if and only if the set of first-order formulas Tϕ ∪ Sϕ is satisfiable. For let M
be any (Kripke) model of ϕ over a frame (W, R). Define the first-order structure M with
domain W , by setting rM = R, eM = A2 , and pM      ψ = {w | M |=w ψ}, for any subformula
ψ of ϕ. It is then easy to check that M |= Tϕ ∪ Sϕ . Conversely, suppose M |= Tϕ ∪ Sϕ .
We build a Kripke structure M over the frame (A, rM ) by setting, for any proposition
letter o mentioned in ϕ, M |=a o if and only if a ∈ pM     o . A straightforward structural
induction establishes that for any subformula ψ of ϕ, M |=a ψ if and only if a ∈ pM        ψ.
The formula ∃x(pϕ (x) ∧ pϕ (x)) ∈ Sϕ then ensures that ϕ is satisfied in M.
   Now, all of the formulas in Tϕ ∪ Sϕ are of one of the forms

       ∀x(±p(x) → ±q(x))                 ∀x(±p(x) → ∀y(±q(y) → ±r(x, y)))               (11.1)
       ∃x(p(x) ∧ p(x))                   ∀x(±p(x) → ∃y(±q(y) ∧ r(x, y)))                (11.2)
       ∀x(p(x) ∧ q(x) → o(x)).                                                          (11.3)

Notice that formulas of the forms (11.1) and (11.2) translate (in the obvious sense)
directly into the fragment R† ; those of form (11.3), by contrast, do not. The next step
is to eliminate formulas of this last type.
   Let o∗ be a new unary relation symbol. For θ ∈ Tϕ ∪ Sϕ of the form (11.3), let rθ be
a new binary atom, and define Rθ to be the set of formulas

                              ∀x(¬o(x) → ∃z(o∗ (z) ∧ rθ (x, z)))                        (11.4)
                            ∀x(p(x) → ∀z(¬p(z) → ¬rθ (x, z)))                           (11.5)
                             ∀x(q(x) → ∀z(p(z) → ¬rθ (x, z))),                          (11.6)

which are all of the forms in (11.1) or (11.2). It is easy to check that Rθ |= θ. For suppose
(for contradiction) that M |= Rθ and a satisfies p and q but not o in M. By (11.4), there
exists b such that M |= rθ [a, b]. If M 6|= p[b], then (11.5) is false in M; on the other hand,
if M |= p[b], then (11.6) is false in M. Thus, Rθ |= θ as claimed. Conversely, if M |= θ,
expand M to a structure M0 by interpreting o∗ and rθ as follows:

                              (o∗ )M = A
                                 rθM = {ha, ai | M 6|= o[a]}.

We check that M0 |= Rθ . Formula (11.4) is true, because M0 6|= o[a] implies M0 |= rθ [a, a].
Formula (11.5) is true, because M0 |= rθ [a, b] implies a = b. To see that Formula (11.6)
is true, suppose M0 |= q[a] and M0 |= p[b]. If a = b, then M |= o[a] (since M0 |= θ); that
is, either a 6= b or M |= o[a]. By construction, then, M0 6|= rθ [a, b].
   Now let Tϕ∗ be the result of replacing all formulas θ in Tϕ of form (11.3) with the
corresponding trio Rθ . (The binary atoms rθ for the various θ are assumed to be distinct;



134
however, the same unary atom o∗ can be used for all θ.) By the previous paragraph,
Tϕ∗ ∪ Sϕ is satisfiable if and only if Tϕ ∪ Sϕ is satisfiable, and hence if and only if ϕ is
satisfiable. But Tϕ∗ ∪ Sϕ is a set of formulas of the forms (11.1) and (11.2), and can
evidently be translated into a set of R† -formulas satisfied in exactly the same structures.
Moreover, this set can be computed in time bounded by a polynomial function of kϕk.
This completes the reduction.                                                             a
  We note the following fact. (We omit a detailed proof, since subsequent developments
do not hinge on this result.)

Lemma 11.0.8 The problem of determining the validity of a sequent in RC† is in Ex-
pTime.

Proof Trivial adaptation of Pratt-Hartmann [?], Theorem 3, which considers a frag-
ment obtained by adding relative clauses to the relational syllogistic.         a

Theorem 11.0.9 The validity problem for R† and RC† are ExpTime-complete.

Proof    Lemmas 11.0.7 and 11.0.8.                                                        a

Corollary 11.0.10 There exists no finite set X of syllogistic rules in either R† or RC†
such that `X is both sound and refutation-complete.

Proof It is a standard result that PTime6=ExpTime. The result is then immediate
by Lemmas 11.0.5 and 11.0.7.                                                  a
   Of course, Corollary 11.0.10 leaves open the possibility that there exist indirect syllo-
gistic systems that are sound and complete for R† and RC† . To show that there do not,
stronger methods are required.




                                                                                        135
12 Description Logic




                       137
13 Categorial Grammar
13.1 Categorial grammar as a syntactic system
Categorial Grammar (CG) is an old tradition in formal grammar and formal semantics.
In fact, it is the approach to grammar which is closest to the work that we’ll do in these
notes.

Basic syntactic categories A categorial grammar always begins with basic categories.
You should think of these as simple syntactic categories. In our linguistic applications,
we usually will take N, NP and S, standing for noun, noun phrase, and sentence, re-
spectively. But we could just as well take other basic categories besides these.

Slash categories If C and D are categories, so are C\D and C/D. It’s very important
to see the difference between the two slashes! I personally have names for these:

                                      \ look left
                                      / look right

But they have other names: backslash and slash, over and under. The overall idea is
that they are directional versions of the usual division notation for fractions:
                         X
                           corresponds to both Y \X and X/Y
                         Y
The difference is that
              Y \X looks for a Y on its left, and then the result is an X
              X/Y looks for a Y on its right, and then the result is an X

  We sometimes call the categories with slashes complex categories, to make it clear that
they are not basic categories.

Examples of Categories First, Figure 13.1 shows some categories when the basic ones
are S, N, and NP. The complex categories in the figure are going to play the role of
parts of speech in traditional grammar, such as noun, noun phrase, adjective, etc. So this
particular example will be important when we return to our overall topic of inference.
For a more artificial example, let the basic categories be S, T , U , V , W , X, and Y .
Then some of the categories would be S/(T \U ), and also

                                   (S/(T \U ))\(V /V ).




                                                                                      139
13 Categorial Grammar


                         syntactic category X   name
                         S                      sentence
                         N                      noun
                         NP                     noun phrase
                         N/N                    adjective
                         NP\S                   verb phrase
                         (NP\S)\(NP\S)          adverb
                         (NP\S)/NP              transitive verb
                         NP/N                   determiner

Figure 13.1: Syntactic categories starting from S, N and NP, together with their tradi-
             tional names.


Lexicons A lexicon is a set Lex whose elements are called lexical items, and with each
lexical item a non-empty set of categories. For example, here is a lexicon defined over
the basic categories S, T , U , X, and Y :

                             (a, T /X)            (a, U/Y )
                             (a, S/X)             (a, S/Y )
                                                                                   (13.1)
                             (b, X)               (c, Y )
                             (b, X/T )            (c, Y /U )

We have Lex = {a, b, c}. We say that a has categories T /X, S/X, U/Y and S/Y . Note
that in general a lexical item has more than one category.
  For a second example of a lexicon, here is one that uses the basic categories S, N and
NP. It also is connected to Figure 13.1 in the sense that the words are of the correct
categories. That is, men is a (plural) noun, some is a determiner, walk is a verb phrase,
etc.


 (men, N)                (some, NP/N)       (Dana, NP)                (teased, (NP\S)/NP)
 (women, N)              (no, NP/N)         (Kim, NP)                 (interviewed, (NP\S)/NP)
 (walk, NP\S)            (most, NP/N)       (smiled, NP\S)            (joyfully, (NP\S)\(NP\S))
 (who, (N\N)/(NP\S))     (J, NP)            (laughed, NP\S)           (carefully, (NP\S)\(NP\S))
 (sees, (NP\S)/NP))      (M, NP)            (cried, NP\S)             (excitedly, (NP\S)\(NP\S))
 (every, NP/N)           (is-a, (NP\S)/N)   (praised, (NP\S)/NP)
                                                                                   (13.2)


Parsing in CG Let Lex be a lexicon. Let Lex∗ be the set of finite sequences of lexical
items. We use letters like v and w for these sequences, and we call them words over the
lexicon. We write w : C, and we say that w is of category C if this assertion can be
derived from the rules in Figure 13.2.



140
                                        13.1 Categorial grammar as a syntactic system

  For example, let us return to the lexicon in (13.1) and show that abab : S. Here is a
derivation:
                                              a : T /X b : X
                                    b : X/T         ab : T
                          a : S/X          bab : X
                                  abab : S
The leaves are labeled with items from the lexicon, and this is perfectly fine. That is,
the leftmost rule in Figure 13.2 says that this is ok. The rest of the derivation above
comes from three applications of the / rule in Figure 13.2.
   You might try to show that ababab : S, but that there is no derivation which would
show that aa : S.
   Turning to our more English-like lexicon in (13.2), here are some derivations of words
in the lexicon (that is, sequences of lexical items) of category S:

                          smiled: NP\S joyfully: (NP\S)\(NP\S)
                Dana: NP            smiled joyfully: NP\S
                         Dana smiled joyfully: S



            criticized: (NP\S)/NP Dana: NP
                    criticized Dana: NP\S           carefully: (NP\S)\(NP\S)
    Kim: NP                       criticized Dana carefully: NP\S
                 Kim criticized Dana carefully: S



                                     and : (NP\NP)/NP C : NP
                             B : NP         and C : N P \NP
        and : (NP\NP)/NP             B and C : NP
 F : NP           and B and C : NP\NP
          F and B and C : NP                                     left : NP\S
                          Farid and Bettina and Cynthia left : S

Categorial grammars and their languages A categorial grammar is a pair G = (Lex, C),
where Lex is a lexicon and C is a category. The language of G is the set of words w
such that w : C.




                                                                                     141
13 Categorial Grammar




                             v : B w : B\C           v : B/C w : C
                                           \                       /
                   w:C            vw : C                  vw : C

Figure 13.2: Categorial parsing. The rule on the left is an axiom coming from the lexicon.
             The other two rules allow us to eliminate one of the slashes by juxtaposition.




142
14 Proof-theoretic Semantics




                               143
